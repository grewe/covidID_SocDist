{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"LSBDMTrainingEfficientnetD0.ipynb","provenance":[{"file_id":"1fcq7kBXCfyF1zIwYdkbNfORuy3dK_AXL","timestamp":1598891298751},{"file_id":"1dfev4NccX_QdKERVHsw3uvGS-b07ci2k","timestamp":1598852542790},{"file_id":"1zaLSNjYFiP1C439vEu3JsCxgk_e5-qI-","timestamp":1598830020586}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fVEmUjjkiAG2"},"source":["## STEP 1: Mount Google Drive \n","##### to get access to data set and for storage of created training files (checkpoints, models, etc)\n","\n","*  ***you must choose only Option A or B***\n","\n","\n","\n","\n","**Assumes following directory structure**\n","\n","*  ***important: the csv, and record files will be generated in cells below***\n","\n","\n","\n","```\n","project_directory/\n","        ├─ data/\n","        │    ├── images/\n","        │    │      ├── armas (1).jpg\n","        │    │      ├── armas (2).jpg\n","        │    │      └── ...\n","        │    ├── train_labels/\n","        │    │      ├── armas (1).xml\n","        │    │      ├── armas (2).xml\n","        │    │      └── ...\n","        │    ├── test_labels/\n","        │    │      ├── armas (10).xml\n","        │    │      ├── armas (20).xml\n","        │    │      └── ...\n","        │    ├── label_map.pbtxt\n","        │    ├── test_labels.csv\n","        │    ├── train_labels.csv\n","        │    ├── test_labels.record\n","        │    └── train_labels.record\n","        └─ models/\n","             ├─ research/\n","             │      ├── fine_tuned_model/\n","             │      │         ├── frozen_inference_graph.pb\n","             │      │         └── ...\n","             │      │         \n","             │      ├── pretrained_model/\n","             │      │         ├── frozen_inference_graph.pb\n","             │      │         └── ...\n","             │      │         \n","             │      ├── object_detection/\n","             │      │         ├── utils/\n","             │      │         ├── samples/\n","             │      │         │      ├── samples/ \n","             │      │         │      │       ├── configs/             \n","             │      │         │      │       │     ├── ssd_mobilenet_v2_coco.config\n","             │      │         │      │       │     ├── rfcn_resnet101_pets.config\n","             │      │         │      │       │     └── ...\n","             │      │         │      │       └── ... \n","             │      │         │      └── ...                                \n","             │      │         ├── export_inference_graph.py\n","             │      │         ├── model_main.py\n","             │      │         └── ...\n","             │      │         \n","             │      ├── training/\n","             │      │         ├── events.out.tfevents.xxxxx\n","             │      │         └── ...               \n","             │      └── ...\n","             └── ...\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"i2mmqVzzMhtH"},"source":["Checking if drive is mounted and can access folders"]},{"cell_type":"code","metadata":{"id":"RloSIDHYeZ6e","executionInfo":{"status":"ok","timestamp":1604597956059,"user_tz":480,"elapsed":28312,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"9d228fac-af0e-40f5-e2f4-82b9878f3fdc","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GVqi42k_KkTy","executionInfo":{"status":"ok","timestamp":1604597973536,"user_tz":480,"elapsed":3921,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"007eaad3-093e-49fb-8f6f-562883ed41d1","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/\n","%ls\n","\n","root_dir=\"/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/\"\n","print(\"root directory=\"+root_dir)\n","%ls {root_dir}\n","\n","base_dir=\"/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/\"\n","print(\"base directory=\"+base_dir)\n","%ls {base_dir}\n","\n","data_dir=\"/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/Data/\"\n","print(\"data directory=\"+data_dir)\n","%ls {data_dir}\n","\n","models_dir=\"/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/models/\"\n","print(\"models directory=\"+models_dir)\n","%ls {models_dir}\n","\n","models_research_dir=\"/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/models/research/\"\n","print(\"models directory=\"+models_research_dir)\n","%ls {models_research_dir}\n","\n","object_detect_dir = models_research_dir + \"/object_detection\"\n","object_detect_protos = object_detect_dir + \"/protos/*.protos\"\n","%ls {object_detect_dir}\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0\n"," \u001b[0m\u001b[01;34mData\u001b[0m/                               \u001b[01;34mRun2_copy\u001b[0m/\n"," eval_result.docx                    tf-nightly.ipynb\n"," \u001b[01;34mfine_tuned_model\u001b[0m/                   \u001b[01;34mtraining\u001b[0m/\n"," \u001b[01;34mfine_tuned_model_new\u001b[0m/               \u001b[01;34mtraining1\u001b[0m/\n"," LSBDMTrainingEfficientnetD0.ipynb   \u001b[01;34mtraining_copy\u001b[0m/\n"," \u001b[01;34mmodels\u001b[0m/                            'training steps.docx'\n","root directory=/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/\n"," \u001b[0m\u001b[01;34mData\u001b[0m/                               \u001b[01;34mRun2_copy\u001b[0m/\n"," eval_result.docx                    tf-nightly.ipynb\n"," \u001b[01;34mfine_tuned_model\u001b[0m/                   \u001b[01;34mtraining\u001b[0m/\n"," \u001b[01;34mfine_tuned_model_new\u001b[0m/               \u001b[01;34mtraining1\u001b[0m/\n"," LSBDMTrainingEfficientnetD0.ipynb   \u001b[01;34mtraining_copy\u001b[0m/\n"," \u001b[01;34mmodels\u001b[0m/                            'training steps.docx'\n","base directory=/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/\n"," \u001b[0m\u001b[01;34mData\u001b[0m/                               \u001b[01;34mRun2_copy\u001b[0m/\n"," eval_result.docx                    tf-nightly.ipynb\n"," \u001b[01;34mfine_tuned_model\u001b[0m/                   \u001b[01;34mtraining\u001b[0m/\n"," \u001b[01;34mfine_tuned_model_new\u001b[0m/               \u001b[01;34mtraining1\u001b[0m/\n"," LSBDMTrainingEfficientnetD0.ipynb   \u001b[01;34mtraining_copy\u001b[0m/\n"," \u001b[01;34mmodels\u001b[0m/                            'training steps.docx'\n","data directory=/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/Data/\n","\u001b[0m\u001b[01;34mannotations\u001b[0m/     TestData_LBSDMannotations.record  \u001b[01;34mtrain_labels\u001b[0m/\n","\u001b[01;34mimages\u001b[0m/          \u001b[01;34mtest_labels\u001b[0m/                      train_labels.csv\n","label_map.pbtxt  test_labels.csv                   train_labels.record\n","\u001b[01;34mTestData_LBSDM\u001b[0m/  test_labels.record\n","models directory=/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/models/\n","AUTHORS     \u001b[0m\u001b[01;34mcommunity\u001b[0m/       LICENSE    \u001b[01;34morbit\u001b[0m/     \u001b[01;34mresearch\u001b[0m/\n","CODEOWNERS  CONTRIBUTING.md  \u001b[01;34mofficial\u001b[0m/  README.md\n","models directory=/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/models/research/\n","\u001b[0m\u001b[01;34ma3c_blogpost\u001b[0m/        \u001b[01;34mdeep_speech\u001b[0m/            \u001b[01;34mobject_detection.egg-info\u001b[0m/\n","\u001b[01;34madversarial_text\u001b[0m/    \u001b[01;34mdelf\u001b[0m/                   \u001b[01;34mpcl_rl\u001b[0m/\n","\u001b[01;34mattention_ocr\u001b[0m/       \u001b[01;34mdeploy\u001b[0m/                 README.md\n","\u001b[01;34maudioset\u001b[0m/            \u001b[01;34mefficient-hrl\u001b[0m/          \u001b[01;34mrebar\u001b[0m/\n","\u001b[01;34mautoaugment\u001b[0m/         \u001b[01;34mlfads\u001b[0m/                  \u001b[01;34msequence_projection\u001b[0m/\n","\u001b[01;34mbuild\u001b[0m/               \u001b[01;34mlstm_object_detection\u001b[0m/  setup.py\n","\u001b[01;34mcognitive_planning\u001b[0m/  \u001b[01;34mmarco\u001b[0m/                  \u001b[01;34mslim\u001b[0m/\n","\u001b[01;34mcvt_text\u001b[0m/            \u001b[01;34mnst_blogpost\u001b[0m/           \u001b[01;34mvid2depth\u001b[0m/\n","\u001b[01;34mdeeplab\u001b[0m/             \u001b[01;34mobject_detection\u001b[0m/\n","\u001b[0m\u001b[01;34manchor_generators\u001b[0m/                       __init__.py\n","\u001b[01;34mbox_coders\u001b[0m/                              inputs.py\n","\u001b[01;34mbuilders\u001b[0m/                                \u001b[01;34mlegacy\u001b[0m/\n","\u001b[01;34mcolab_tutorials\u001b[0m/                         \u001b[01;34mmatchers\u001b[0m/\n","\u001b[01;34mconfigs\u001b[0m/                                 \u001b[01;34mmeta_architectures\u001b[0m/\n","CONTRIBUTING.md                          \u001b[01;34mmetrics\u001b[0m/\n","\u001b[01;34mcore\u001b[0m/                                    model_lib.py\n","\u001b[01;34mdata\u001b[0m/                                    model_lib_tf1_test.py\n","\u001b[01;34mdata_decoders\u001b[0m/                           model_lib_tf2_test.py\n","\u001b[01;34mdataset_tools\u001b[0m/                           model_lib_v2.py\n","\u001b[01;34mdockerfiles\u001b[0m/                             model_main.py\n","eval_util_test.py                        model_main_tf2.py\n","exporter_lib_tf2_test.py                 \u001b[01;34mmodels\u001b[0m/\n","exporter_lib_v2.py                       model_tpu_main.py\n","exporter_main_v2.py                      \u001b[01;34mpackages\u001b[0m/\n","exporter_tf1_test.py                     \u001b[01;34mpredictors\u001b[0m/\n","export_inference_graph.py                \u001b[01;34mprotos\u001b[0m/\n","export_tflite_graph_lib_tf2.py           \u001b[01;34m__pycache__\u001b[0m/\n","export_tflite_graph_lib_tf2_test.py      README.md\n","export_tflite_graph_tf2.py               \u001b[01;34msamples\u001b[0m/\n","export_tflite_ssd_graph_lib.py           \u001b[01;34mtest_data\u001b[0m/\n","export_tflite_ssd_graph_lib_tf1_test.py  \u001b[01;34mtest_images\u001b[0m/\n","export_tflite_ssd_graph.py               \u001b[01;34mtpu_exporters\u001b[0m/\n","\u001b[01;34mg3doc\u001b[0m/                                   \u001b[01;34mutils\u001b[0m/\n","\u001b[01;34minference\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A9FJYNSOjHhy"},"source":["## STEP 3: Install Required Packages for Colab environment\n","##### colab has install basic packages like Tensorflow,etc. but anything additional you will need to install next\n","\n","***you can run !pip list to see what is currently installed***"]},{"cell_type":"code","metadata":{"id":"XtrEdblF6jX8","executionInfo":{"status":"ok","timestamp":1604597995462,"user_tz":480,"elapsed":18220,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"8e2baee2-e926-4e1c-fc1b-eb209ae97c61","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(\"Currently Installed\")\n","!pip list\n","\n","print(\"\\n\\n\")\n","!sudo apt-get update   #update the location of packages in case they have moved\n","print(\"installing protobuf-compiler python-pil python-lxml and python-tk\")\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","print(\"\\n\\n\")\n","\n","print(\"installing Cython contextlib2 pillow lxml matplotlib\")\n","\n","!pip install -qq Cython contextlib2 pillow lxml matplotlib\n","\n","\n","\n","print(\"\\n\\n\")\n","print(\"installing pycocotools\")\n","\n","!pip install -qq pycocotools"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Currently Installed\n","Package                       Version        \n","----------------------------- ---------------\n","absl-py                       0.10.0         \n","alabaster                     0.7.12         \n","albumentations                0.1.12         \n","altair                        4.1.0          \n","argon2-cffi                   20.1.0         \n","asgiref                       3.3.0          \n","astor                         0.8.1          \n","astropy                       4.1            \n","astunparse                    1.6.3          \n","async-generator               1.10           \n","atari-py                      0.2.6          \n","atomicwrites                  1.4.0          \n","attrs                         20.2.0         \n","audioread                     2.1.9          \n","autograd                      1.3            \n","Babel                         2.8.0          \n","backcall                      0.2.0          \n","beautifulsoup4                4.6.3          \n","bleach                        3.2.1          \n","blis                          0.4.1          \n","bokeh                         2.1.1          \n","Bottleneck                    1.3.2          \n","branca                        0.4.1          \n","bs4                           0.0.1          \n","CacheControl                  0.12.6         \n","cachetools                    4.1.1          \n","catalogue                     1.0.0          \n","certifi                       2020.6.20      \n","cffi                          1.14.3         \n","chainer                       7.4.0          \n","chardet                       3.0.4          \n","click                         7.1.2          \n","cloudpickle                   1.3.0          \n","cmake                         3.12.0         \n","cmdstanpy                     0.9.5          \n","colorlover                    0.3.0          \n","community                     1.0.0b1        \n","contextlib2                   0.5.5          \n","convertdate                   2.2.2          \n","coverage                      3.7.1          \n","coveralls                     0.5            \n","crcmod                        1.7            \n","cufflinks                     0.17.3         \n","cupy-cuda101                  7.4.0          \n","cvxopt                        1.2.5          \n","cvxpy                         1.0.31         \n","cycler                        0.10.0         \n","cymem                         2.0.4          \n","Cython                        0.29.21        \n","daft                          0.0.4          \n","dask                          2.12.0         \n","dataclasses                   0.7            \n","datascience                   0.10.6         \n","debugpy                       1.0.0          \n","decorator                     4.4.2          \n","defusedxml                    0.6.0          \n","descartes                     1.1.0          \n","dill                          0.3.3          \n","distributed                   1.25.3         \n","Django                        3.1.3          \n","dlib                          19.18.0        \n","dm-tree                       0.1.5          \n","docopt                        0.6.2          \n","docutils                      0.16           \n","dopamine-rl                   1.0.5          \n","earthengine-api               0.1.238        \n","easydict                      1.9            \n","ecos                          2.0.7.post1    \n","editdistance                  0.5.3          \n","en-core-web-sm                2.2.5          \n","entrypoints                   0.3            \n","ephem                         3.7.7.1        \n","et-xmlfile                    1.0.1          \n","fa2                           0.3.5          \n","fancyimpute                   0.4.3          \n","fastai                        1.0.61         \n","fastdtw                       0.3.4          \n","fastprogress                  1.0.0          \n","fastrlock                     0.5            \n","fbprophet                     0.7.1          \n","feather-format                0.4.1          \n","filelock                      3.0.12         \n","firebase-admin                4.4.0          \n","fix-yahoo-finance             0.0.22         \n","Flask                         1.1.2          \n","folium                        0.8.3          \n","future                        0.16.0         \n","gast                          0.3.3          \n","GDAL                          2.2.2          \n","gdown                         3.6.4          \n","gensim                        3.6.0          \n","geographiclib                 1.50           \n","geopy                         1.17.0         \n","gin-config                    0.3.0          \n","glob2                         0.7            \n","google                        2.0.3          \n","google-api-core               1.16.0         \n","google-api-python-client      1.7.12         \n","google-auth                   1.17.2         \n","google-auth-httplib2          0.0.4          \n","google-auth-oauthlib          0.4.2          \n","google-cloud-bigquery         1.21.0         \n","google-cloud-bigquery-storage 1.1.0          \n","google-cloud-core             1.0.3          \n","google-cloud-datastore        1.8.0          \n","google-cloud-firestore        1.7.0          \n","google-cloud-language         1.2.0          \n","google-cloud-storage          1.18.1         \n","google-cloud-translate        1.5.0          \n","google-colab                  1.0.0          \n","google-pasta                  0.2.0          \n","google-resumable-media        0.4.1          \n","googleapis-common-protos      1.52.0         \n","googledrivedownloader         0.4            \n","graphviz                      0.10.1         \n","grpcio                        1.33.2         \n","gspread                       3.0.1          \n","gspread-dataframe             3.0.8          \n","gym                           0.17.3         \n","h5py                          2.10.0         \n","HeapDict                      1.0.1          \n","holidays                      0.10.3         \n","holoviews                     1.13.5         \n","html5lib                      1.0.1          \n","httpimport                    0.5.18         \n","httplib2                      0.17.4         \n","httplib2shim                  0.0.3          \n","humanize                      0.5.1          \n","hyperopt                      0.1.2          \n","ideep4py                      2.0.0.post3    \n","idna                          2.10           \n","image                         1.5.33         \n","imageio                       2.4.1          \n","imagesize                     1.2.0          \n","imbalanced-learn              0.4.3          \n","imblearn                      0.0            \n","imgaug                        0.2.9          \n","importlib-metadata            2.0.0          \n","importlib-resources           3.3.0          \n","imutils                       0.5.3          \n","inflect                       2.1.0          \n","iniconfig                     1.1.1          \n","intel-openmp                  2020.0.133     \n","intervaltree                  2.1.0          \n","ipykernel                     4.10.1         \n","ipython                       5.5.0          \n","ipython-genutils              0.2.0          \n","ipython-sql                   0.3.9          \n","ipywidgets                    7.5.1          \n","itsdangerous                  1.1.0          \n","jax                           0.2.4          \n","jaxlib                        0.1.56+cuda101 \n","jdcal                         1.4.1          \n","jedi                          0.17.2         \n","jieba                         0.42.1         \n","Jinja2                        2.11.2         \n","joblib                        0.17.0         \n","jpeg4py                       0.1.4          \n","jsonschema                    2.6.0          \n","jupyter                       1.0.0          \n","jupyter-client                5.3.5          \n","jupyter-console               5.2.0          \n","jupyter-core                  4.6.3          \n","jupyterlab-pygments           0.1.2          \n","kaggle                        1.5.9          \n","kapre                         0.1.3.1        \n","Keras                         2.4.3          \n","Keras-Preprocessing           1.1.2          \n","keras-vis                     0.4.1          \n","kiwisolver                    1.3.1          \n","knnimpute                     0.1.0          \n","korean-lunar-calendar         0.2.1          \n","librosa                       0.6.3          \n","lightgbm                      2.2.3          \n","llvmlite                      0.31.0         \n","lmdb                          0.99           \n","lucid                         0.3.8          \n","LunarCalendar                 0.0.9          \n","lxml                          4.2.6          \n","Markdown                      3.3.3          \n","MarkupSafe                    1.1.1          \n","matplotlib                    3.2.2          \n","matplotlib-venn               0.11.6         \n","missingno                     0.4.2          \n","mistune                       0.8.4          \n","mizani                        0.6.0          \n","mkl                           2019.0         \n","mlxtend                       0.14.0         \n","more-itertools                8.6.0          \n","moviepy                       0.2.3.5        \n","mpmath                        1.1.0          \n","msgpack                       1.0.0          \n","multiprocess                  0.70.10        \n","multitasking                  0.0.9          \n","murmurhash                    1.0.3          \n","music21                       5.5.0          \n","natsort                       5.5.0          \n","nbclient                      0.5.1          \n","nbconvert                     5.6.1          \n","nbformat                      5.0.8          \n","nest-asyncio                  1.4.2          \n","networkx                      2.5            \n","nibabel                       3.0.2          \n","nltk                          3.2.5          \n","notebook                      5.3.1          \n","np-utils                      0.5.12.1       \n","numba                         0.48.0         \n","numexpr                       2.7.1          \n","numpy                         1.18.5         \n","nvidia-ml-py3                 7.352.0        \n","oauth2client                  4.1.3          \n","oauthlib                      3.1.0          \n","okgrade                       0.4.3          \n","opencv-contrib-python         4.1.2.30       \n","opencv-python                 4.1.2.30       \n","openpyxl                      2.5.9          \n","opt-einsum                    3.3.0          \n","osqp                          0.6.1          \n","packaging                     20.4           \n","palettable                    3.3.0          \n","pandas                        1.1.4          \n","pandas-datareader             0.9.0          \n","pandas-gbq                    0.13.3         \n","pandas-profiling              1.4.1          \n","pandocfilters                 1.4.3          \n","panel                         0.9.7          \n","param                         1.10.0         \n","parso                         0.7.1          \n","pathlib                       1.0.1          \n","patsy                         0.5.1          \n","pexpect                       4.8.0          \n","pickleshare                   0.7.5          \n","Pillow                        7.0.0          \n","pip                           19.3.1         \n","pip-tools                     4.5.1          \n","plac                          1.1.3          \n","plotly                        4.4.1          \n","plotnine                      0.6.0          \n","pluggy                        0.7.1          \n","portpicker                    1.3.1          \n","prefetch-generator            1.0.1          \n","preshed                       3.0.2          \n","prettytable                   1.0.1          \n","progressbar2                  3.38.0         \n","prometheus-client             0.8.0          \n","promise                       2.3            \n","prompt-toolkit                1.0.18         \n","protobuf                      3.12.4         \n","psutil                        5.4.8          \n","psycopg2                      2.7.6.1        \n","ptyprocess                    0.6.0          \n","py                            1.9.0          \n","pyarrow                       0.14.1         \n","pyasn1                        0.4.8          \n","pyasn1-modules                0.2.8          \n","pycocotools                   2.0.2          \n","pycparser                     2.20           \n","pyct                          0.4.8          \n","pydata-google-auth            1.1.0          \n","pydot                         1.3.0          \n","pydot-ng                      2.0.0          \n","pydotplus                     2.0.2          \n","PyDrive                       1.3.1          \n","pyemd                         0.5.1          \n","pyglet                        1.5.0          \n","Pygments                      2.6.1          \n","pygobject                     3.26.1         \n","pymc3                         3.7            \n","PyMeeus                       0.3.7          \n","pymongo                       3.11.0         \n","pymystem3                     0.2.0          \n","PyOpenGL                      3.1.5          \n","pyparsing                     2.4.7          \n","pyrsistent                    0.17.3         \n","pysndfile                     1.3.8          \n","PySocks                       1.7.1          \n","pystan                        2.19.1.1       \n","pytest                        3.6.4          \n","python-apt                    1.6.5+ubuntu0.3\n","python-chess                  0.23.11        \n","python-dateutil               2.8.1          \n","python-louvain                0.14           \n","python-slugify                4.0.1          \n","python-utils                  2.4.0          \n","pytz                          2018.9         \n","pyviz-comms                   0.7.6          \n","PyWavelets                    1.1.1          \n","PyYAML                        3.13           \n","pyzmq                         19.0.2         \n","qtconsole                     4.7.7          \n","QtPy                          1.9.0          \n","regex                         2019.12.20     \n","requests                      2.23.0         \n","requests-oauthlib             1.3.0          \n","resampy                       0.2.2          \n","retrying                      1.3.3          \n","rpy2                          3.2.7          \n","rsa                           4.6            \n","scikit-image                  0.16.2         \n","scikit-learn                  0.22.2.post1   \n","scipy                         1.4.1          \n","screen-resolution-extra       0.0.0          \n","scs                           2.1.2          \n","seaborn                       0.11.0         \n","Send2Trash                    1.5.0          \n","setuptools                    50.3.2         \n","setuptools-git                1.2            \n","Shapely                       1.7.1          \n","simplegeneric                 0.8.1          \n","six                           1.15.0         \n","sklearn                       0.0            \n","sklearn-pandas                1.8.0          \n","slugify                       0.0.1          \n","smart-open                    3.0.0          \n","snowballstemmer               2.0.0          \n","sortedcontainers              2.2.2          \n","spacy                         2.2.4          \n","Sphinx                        1.8.5          \n","sphinxcontrib-serializinghtml 1.1.4          \n","sphinxcontrib-websupport      1.2.4          \n","SQLAlchemy                    1.3.20         \n","sqlparse                      0.4.1          \n","srsly                         1.0.2          \n","statsmodels                   0.10.2         \n","sympy                         1.1.1          \n","tables                        3.4.4          \n","tabulate                      0.8.7          \n","tblib                         1.7.0          \n","tensorboard                   2.3.0          \n","tensorboard-plugin-wit        1.7.0          \n","tensorboardcolab              0.0.22         \n","tensorflow                    2.3.0          \n","tensorflow-addons             0.8.3          \n","tensorflow-datasets           4.0.1          \n","tensorflow-estimator          2.3.0          \n","tensorflow-gcs-config         2.3.0          \n","tensorflow-hub                0.10.0         \n","tensorflow-metadata           0.24.0         \n","tensorflow-privacy            0.2.2          \n","tensorflow-probability        0.11.0         \n","termcolor                     1.1.0          \n","terminado                     0.9.1          \n","testpath                      0.4.4          \n","text-unidecode                1.3            \n","textblob                      0.15.3         \n","textgenrnn                    1.4.1          \n","Theano                        1.0.5          \n","thinc                         7.4.0          \n","tifffile                      2020.9.3       \n","toml                          0.10.2         \n","toolz                         0.11.1         \n","torch                         1.7.0+cu101    \n","torchsummary                  1.5.1          \n","torchtext                     0.3.1          \n","torchvision                   0.8.1+cu101    \n","tornado                       5.1.1          \n","tqdm                          4.41.1         \n","traitlets                     4.3.3          \n","tweepy                        3.6.0          \n","typeguard                     2.7.1          \n","typing-extensions             3.7.4.3        \n","tzlocal                       1.5.1          \n","umap-learn                    0.4.6          \n","uritemplate                   3.0.1          \n","urllib3                       1.24.3         \n","vega-datasets                 0.8.0          \n","wasabi                        0.8.0          \n","wcwidth                       0.2.5          \n","webencodings                  0.5.1          \n","Werkzeug                      1.0.1          \n","wheel                         0.35.1         \n","widgetsnbextension            3.5.1          \n","wordcloud                     1.5.0          \n","wrapt                         1.12.1         \n","xarray                        0.15.1         \n","xgboost                       0.90           \n","xkit                          0.0.0          \n","xlrd                          1.1.0          \n","xlwt                          1.3.0          \n","yellowbrick                   0.9.1          \n","zict                          2.0.0          \n","zipp                          3.4.0          \n","\n","\n","\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [40.1 kB]\n","Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n","Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Get:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Ign:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n","Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,687 kB]\n","Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [405 kB]\n","Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,750 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,118 kB]\n","Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,353 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,167 kB]\n","Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [864 kB]\n","Get:22 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [48.9 kB]\n","Fetched 10.7 MB in 2s (5,064 kB/s)\n","Reading package lists... Done\n","installing protobuf-compiler python-pil python-lxml and python-tk\n","Selecting previously unselected package python-bs4.\n","(Reading database ... 144628 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.3_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1ubuntu0.3) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1ubuntu0.3) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","\n","\n","\n","installing Cython contextlib2 pillow lxml matplotlib\n","\n","\n","\n","installing pycocotools\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DHSoWF3YJze4"},"source":["**Training testing split**"]},{"cell_type":"code","metadata":{"id":"t9UnFGQBOy3F","executionInfo":{"elapsed":7598,"status":"ok","timestamp":1603311582838,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"},"user_tz":420},"outputId":"3db46e97-3c31-48f4-decf-f34f74d28425","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","%cd {data_dir}\n","!ls annotations/* | sort -R | head -195 | xargs -I{} mv {} test_labels/\n","\n","\n","# Moves the rest of labels '2687' i.e 80 % labels to the training dir: `train_labels`\n","!ls annotations/* | xargs -I{} mv {} train_labels/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xLXcM2JDKCGm"},"source":["**Checking training testing labels directory**"]},{"cell_type":"code","metadata":{"id":"2hKlbksrVr3e","executionInfo":{"status":"ok","timestamp":1604598119261,"user_tz":480,"elapsed":1175,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"a638e958-c957-4bb4-a5ee-6d9f5cefd9a0","colab":{"base_uri":"https://localhost:8080/"}},"source":["train_labels_dir=\"/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/Data/train_labels\"\n","print(\"train label directory=\"+train_labels_dir)\n","#%ls {train_label_dir}\n","\n","test_labels_dir=\"/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/Data/test_labels\"\n","print(\"test label directory=\"+test_labels_dir)\n","#%ls {test_label_dir}\n","\n","print(\"data  directory=\"+ data_dir)\n","\n","%ls -1 {train_labels_dir} | wc -l\n","\n","\n","%ls -1 {test_labels_dir} | wc -l\n","\n","\n","images_dir = \"/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/Data/images\"\n","print(\"images  directory=\"+ images_dir)\n","\n","\n","%ls -1 {images_dir} | wc -l"],"execution_count":5,"outputs":[{"output_type":"stream","text":["train label directory=/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/Data/train_labels\n","test label directory=/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/Data/test_labels\n","data  directory=/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/Data/\n","623\n","167\n","images  directory=/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/Data/images\n","671\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cjrlNIfpoROz"},"source":["# STEP 4: Import modules you will use  AND install Object Detection API for colab"]},{"cell_type":"code","metadata":{"id":"_WMI8lU6MxlS","executionInfo":{"status":"ok","timestamp":1604598151685,"user_tz":480,"elapsed":2330,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"57c9ef0a-da83-4090-f79e-40dc99c21f47","colab":{"base_uri":"https://localhost:8080/"}},"source":["from __future__ import division, print_function, absolute_import\n","\n","import pandas as pd\n","import numpy as np\n","import csv\n","import re\n","import cv2 \n","\n","\n","import glob\n","import xml.etree.ElementTree as ET\n","\n","import io\n","import tensorflow.compat.v1 as tf\n","\n","from PIL import Image\n","from collections import namedtuple, OrderedDict\n","\n","import shutil\n","import urllib.request\n","import tarfile\n","\n","from google.colab import files\n","#print out version of tf\n","print(tf.__version__)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["2.3.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fBTAbxAivNap"},"source":["## Install Object Detection API  AND put model/research/slim directory in the colab's path environment variables \n","#### *(note it assume that you have the Object Detection API code on the Google Drive already ---see file structure at top)*"]},{"cell_type":"code","metadata":{"id":"n8nej4i07M-b","executionInfo":{"status":"ok","timestamp":1604598818702,"user_tz":480,"elapsed":53801,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"532fbe44-45b4-4ceb-f30d-5e4ab8b71305","colab":{"base_uri":"https://localhost:8080/"}},"source":["# downloads the models\n","%cd {base_dir}\n","!git clone --q https://github.com/tensorflow/models.git"],"execution_count":55,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TEZ9Wkm77ds6","executionInfo":{"status":"ok","timestamp":1604598155140,"user_tz":480,"elapsed":3241,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"7c940196-1f07-456d-fe7b-7b63822670f0","colab":{"base_uri":"https://localhost:8080/"}},"source":["# MUST do each time restart colab kernel\n","# INSTALL Object Detection API inside the Colab, as sits above TF2\n","# this will take several minutes as it will copy over all of the object_detection files\n","# you have mounted in project_folder/models/research/object_detection\n","# as you can see by the output of this cell it copies them into the colab\n","# environment at build/lib/object_detection\n","\n","#this this is what I need to make the object_detection get installed\n","\n","print(models_research_dir)\n","%cd {models_research_dir}\n","#%ls\n","#!python setup.py install   # from the models/reasearch\n","\n","\n","#install tf_slim\n","!pip install tf_slim"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/models/research/\n","/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research\n","Collecting tf_slim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n","\u001b[K     |████████████████████████████████| 358kB 13.4MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lhz-TDm_7mkO","executionInfo":{"status":"ok","timestamp":1604598855567,"user_tz":480,"elapsed":713,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"c52751a8-6d66-4ac0-9399-79f57d9a62ce","colab":{"base_uri":"https://localhost:8080/"}},"source":["# compiles the proto buffers\n","%cd {models_research_dir}\n","!protoc object_detection/protos/*.proto --python_out=."],"execution_count":56,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ke-lamSdKVpC","executionInfo":{"status":"ok","timestamp":1604598859063,"user_tz":480,"elapsed":358,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"fe9902c4-34e3-4d41-da35-a387a10659b1","colab":{"base_uri":"https://localhost:8080/"}},"source":["import os\n","%cd {models_research_dir}\n","os.environ['PYTHONPATH'] += ':./:./slim/'\n","print(os.environ['PYTHONPATH'])\n","os.environ['PYTHONPATH'] += ':../official/:../../models'\n","print(os.environ['PYTHONPATH'])"],"execution_count":57,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research\n","/env/python:./:./slim/:../official/:../../models:./:./slim/\n","/env/python:./:./slim/:../official/:../../models:./:./slim/:../official/:../../models\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"81BL0Gu1hofR","executionInfo":{"status":"ok","timestamp":1603739116182,"user_tz":420,"elapsed":897,"user":{"displayName":"Subhi asati","photoUrl":"","userId":"12937930425121675107"}},"outputId":"93b8ec6c-ee44-40f3-cd9c-51f375af9e92","colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["%cd {models_research_dir}\n","%ls \n","%cd ..\n","%ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research\n","\u001b[0m\u001b[01;34ma3c_blogpost\u001b[0m/        \u001b[01;34mdeep_speech\u001b[0m/            \u001b[01;34mobject_detection\u001b[0m/\n","\u001b[01;34madversarial_text\u001b[0m/    \u001b[01;34mdelf\u001b[0m/                   \u001b[01;34mobject_detection.egg-info\u001b[0m/\n","\u001b[01;34mattention_ocr\u001b[0m/       \u001b[01;34mdeploy\u001b[0m/                 \u001b[01;34mpcl_rl\u001b[0m/\n","\u001b[01;34maudioset\u001b[0m/            \u001b[01;34mdist\u001b[0m/                   README.md\n","\u001b[01;34mautoaugment\u001b[0m/         \u001b[01;34mefficient-hrl\u001b[0m/          \u001b[01;34mrebar\u001b[0m/\n","\u001b[01;34mbuild\u001b[0m/               \u001b[01;34mlfads\u001b[0m/                  \u001b[01;34msequence_projection\u001b[0m/\n","\u001b[01;34mcognitive_planning\u001b[0m/  \u001b[01;34mlstm_object_detection\u001b[0m/  setup.py\n","\u001b[01;34mcvt_text\u001b[0m/            \u001b[01;34mmarco\u001b[0m/                  \u001b[01;34mslim\u001b[0m/\n","\u001b[01;34mdeeplab\u001b[0m/             \u001b[01;34mnst_blogpost\u001b[0m/           \u001b[01;34mvid2depth\u001b[0m/\n","/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models\n","AUTHORS     \u001b[0m\u001b[01;34mcommunity\u001b[0m/       ISSUES.md  \u001b[01;34mofficial\u001b[0m/  README.md\n","CODEOWNERS  CONTRIBUTING.md  LICENSE    \u001b[01;34morbit\u001b[0m/     \u001b[01;34mresearch\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wiUOuFcG7teM","executionInfo":{"status":"ok","timestamp":1604598871143,"user_tz":480,"elapsed":6254,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"e1d9ba0b-978f-42e3-ce5c-cf06ccf02ffc","colab":{"base_uri":"https://localhost:8080/"}},"source":["# optional test to see if install and compile went well\n","# testing the model builder\n","\n","%cd {models_research_dir}\n","!python3 object_detection/builders/model_builder_test.py"],"execution_count":58,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research\n","2020-11-05 17:54:25.812712: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z5OnY8BNO9jM"},"source":["XML to CSV"]},{"cell_type":"code","metadata":{"id":"87PQmmHxsF9R","executionInfo":{"elapsed":238449,"status":"ok","timestamp":1603311854933,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"},"user_tz":420},"outputId":"4bdf0def-3f91-408d-d9fd-5347a5b85dac","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["%cd {data_dir}\n","#%pwd\n","# %ls {data_dir}\n","\n","#%cd /content/drive/Shared drives/RetrainTF2DataAndModels/DetectionWeaponsExample_CodeLabBased/data\n","\n","# images extension\n","images_extension = 'jpg'\n","\n","# takes the path of a directory that contains xml files and converts\n","#  them to one csv file.\n","\n","# returns a csv file that contains: image name, width, height, class, xmin, ymin, xmax, ymax.\n","# note: if the xml file contains more than one box/label, it will create more than one row for \n","#the same image. each row contains the info for an individual box. \n","def xml_to_csv(path):\n","  classes_names = []\n","  xml_list = []\n","\n","  for xml_file in glob.glob(path + '/*.xml'):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    for member in root.findall('object'):\n","      classes_names.append(member[0].text)\n","      value = (root.find('filename').text ,\n","               int(root.find('size')[0].text),\n","               int(root.find('size')[1].text),\n","               member[0].text,\n","               int(member[4][0].text),\n","               int(member[4][1].text),\n","               int(member[4][2].text),\n","               int(member[4][3].text))\n","      xml_list.append(value)\n","  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","  xml_df = pd.DataFrame(xml_list, columns=column_name) \n","  classes_names = list(set(classes_names))\n","  classes_names.sort()\n","  return xml_df, classes_names\n","\n","# for both the train_labels and test_labels csv files, it runs the xml_to_csv() above.\n","for label_path in ['train_labels', 'test_labels']:\n","  image_path = os.path.join(os.getcwd(), label_path)\n","  xml_df, classes = xml_to_csv(label_path)\n","  xml_df.to_csv(f'{label_path}.csv', index=None)\n","  print(f'Successfully converted {label_path} xml to csv.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data\n","Successfully converted train_labels xml to csv.\n","Successfully converted test_labels xml to csv.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v1AjF5p1eOz_","executionInfo":{"status":"error","timestamp":1603739465531,"user_tz":420,"elapsed":54915,"user":{"displayName":"Subhi asati","photoUrl":"","userId":"12937930425121675107"}},"outputId":"e2a4ac82-afca-4860-be57-b929bbbbaae3","colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["'''\n","checks if the images box position is placed within the image.\n","note: while this doesn't checks if the boxes/annotations are correctly\n"," placed around the object, Tensorflow will throw an error if this occured.\n"," path to images\n","'''\n","\n","\n","%cd {data_dir}\n","images_path = 'images'\n","for CSV_FILE in ['train_labels.csv', 'test_labels.csv']:\n","  with open(CSV_FILE, 'r') as fid:  \n","      print('[*] Checking file:', CSV_FILE) \n","      file = csv.reader(fid, delimiter=',')\n","      first = True \n","      cnt = 0\n","      error_cnt = 0\n","      error = False\n","      for row in file:\n","          if error == True:\n","              error_cnt += 1\n","              error = False         \n","          if first == True:\n","              first = False\n","              continue     \n","          cnt += 1      \n","          name, width, height, xmin, ymin, xmax, ymax = row[0], int(row[1]), int(row[2]), int(row[4]), int(row[5]), int(row[6]), int(row[7])     \n","          path = os.path.join(images_path, name)\n","          img = cv2.imread(path)         \n","          if type(img) == type(None):\n","              error = True\n","              print('Could not read image', img)\n","              continue     \n","          org_height, org_width = img.shape[:2]     \n","          if org_width != width:\n","              error = True\n","              print('Width mismatch for image: ', name, width, '!=', org_width)     \n","          if org_height != height:\n","              error = True\n","              print('Height mismatch for image: ', name, height, '!=', org_height) \n","          if xmin > org_width:\n","              error = True\n","              print('XMIN > org_width for file', name)  \n","          if xmax > org_width:\n","              error = True\n","              print('XMAX > org_width for file', name)\n","          if ymin > org_height:\n","              error = True\n","              print('YMIN > org_height for file', name)\n","          if ymax > org_height:\n","              error = True\n","              print('YMAX > org_height for file', name)\n","          if error == True:\n","              print('Error for file: %s' % name)\n","              print()\n","      print()\n","      print('Checked %d files and realized %d errors' % (cnt, error_cnt))\n","      print(\"-----\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data\n","[*] Checking file: train_labels.csv\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-1cf3565adade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m           \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m               \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"xGmc_fVOGyEK","executionInfo":{"elapsed":35784,"status":"error","timestamp":1603343945735,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"},"user_tz":420},"outputId":"c71f32ad-1786-42b8-8b48-eaaa54f82c8c","colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["# Creating the `label_map.pbtxt` file\n","label_map_path = os.path.join(\"label_map.pbtxt\")\n","\n","pbtxt_content = \"\"\n","\n","\n","#creats a pbtxt file the has the class names.\n","for i, class_name in enumerate(classes):\n","    # display_name is optional.\n","    pbtxt_content = (\n","        pbtxt_content\n","        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n  }}\\n\\n\".format(i + 1, class_name)\n","    )\n","    \n","    \n","pbtxt_content = pbtxt_content.strip()\n","with open(label_map_path, \"w\") as f:\n","    f.write(pbtxt_content)\n","    \n","\n","print(len(classes))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-ad04a212609b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#creats a pbtxt file the has the class names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# display_name is optional.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     pbtxt_content = (\n","\u001b[0;31mNameError\u001b[0m: name 'classes' is not defined"]}]},{"cell_type":"code","metadata":{"id":"QgENwrctJeLt","executionInfo":{"status":"ok","timestamp":1604598173526,"user_tz":480,"elapsed":527,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"e14181d0-4ce1-4882-c971-1d305049cef1","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd {data_dir}\n","%cat label_map.pbtxt"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data\n","item {\n","    id: 1\n","    name: 'Bad'\n","  }\n","\n","item {\n","    id: 2\n","    name: 'Caution'\n","  }\n","\n","item {\n","    id: 3\n","    name: 'Good'\n","  }"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dFQwpGYs717k","executionInfo":{"status":"ok","timestamp":1604598915648,"user_tz":480,"elapsed":37796,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"6a253a27-bda7-439e-d0ea-260afaa5dc07","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd {models_research_dir}\n","#!pip install tensorflow-object-detection-api\n","!python setup.py install   # from the models/reasearch"],"execution_count":59,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research\n","running install\n","running bdist_egg\n","running egg_info\n","creating object_detection.egg-info\n","writing object_detection.egg-info/PKG-INFO\n","writing dependency_links to object_detection.egg-info/dependency_links.txt\n","writing requirements to object_detection.egg-info/requires.txt\n","writing top-level names to object_detection.egg-info/top_level.txt\n","writing manifest file 'object_detection.egg-info/SOURCES.txt'\n","writing manifest file 'object_detection.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build\n","creating build/lib\n","creating build/lib/object_detection\n","copying object_detection/__init__.py -> build/lib/object_detection\n","copying object_detection/eval_util.py -> build/lib/object_detection\n","copying object_detection/eval_util_test.py -> build/lib/object_detection\n","copying object_detection/export_inference_graph.py -> build/lib/object_detection\n","copying object_detection/export_tflite_graph_lib_tf2.py -> build/lib/object_detection\n","copying object_detection/export_tflite_graph_lib_tf2_test.py -> build/lib/object_detection\n","copying object_detection/export_tflite_graph_tf2.py -> build/lib/object_detection\n","copying object_detection/export_tflite_ssd_graph.py -> build/lib/object_detection\n","copying object_detection/export_tflite_ssd_graph_lib.py -> build/lib/object_detection\n","copying object_detection/export_tflite_ssd_graph_lib_tf1_test.py -> build/lib/object_detection\n","copying object_detection/exporter.py -> build/lib/object_detection\n","copying object_detection/exporter_lib_tf2_test.py -> build/lib/object_detection\n","copying object_detection/exporter_lib_v2.py -> build/lib/object_detection\n","copying object_detection/exporter_main_v2.py -> build/lib/object_detection\n","copying object_detection/exporter_tf1_test.py -> build/lib/object_detection\n","copying object_detection/inputs.py -> build/lib/object_detection\n","copying object_detection/inputs_test.py -> build/lib/object_detection\n","copying object_detection/model_hparams.py -> build/lib/object_detection\n","copying object_detection/model_lib.py -> build/lib/object_detection\n","copying object_detection/model_lib_tf1_test.py -> build/lib/object_detection\n","copying object_detection/model_lib_tf2_test.py -> build/lib/object_detection\n","copying object_detection/model_lib_v2.py -> build/lib/object_detection\n","copying object_detection/model_main.py -> build/lib/object_detection\n","copying object_detection/model_main_tf2.py -> build/lib/object_detection\n","copying object_detection/model_tpu_main.py -> build/lib/object_detection\n","creating build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/__init__.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/flexible_grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/flexible_grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/multiple_grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/multiple_grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/multiscale_grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n","creating build/lib/object_detection/box_coders\n","copying object_detection/box_coders/__init__.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/faster_rcnn_box_coder.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/faster_rcnn_box_coder_test.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/keypoint_box_coder.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/keypoint_box_coder_test.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/mean_stddev_box_coder.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/mean_stddev_box_coder_test.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/square_box_coder.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/square_box_coder_test.py -> build/lib/object_detection/box_coders\n","creating build/lib/object_detection/builders\n","copying object_detection/builders/__init__.py -> build/lib/object_detection/builders\n","copying object_detection/builders/anchor_generator_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/anchor_generator_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/box_coder_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/box_coder_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/box_predictor_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/box_predictor_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/calibration_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/calibration_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/dataset_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/dataset_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/decoder_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/decoder_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/graph_rewriter_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/graph_rewriter_builder_tf1_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/hyperparams_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/hyperparams_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/image_resizer_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/image_resizer_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/input_reader_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/input_reader_builder_tf1_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/losses_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/losses_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/matcher_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/matcher_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/model_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/model_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/model_builder_tf1_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/model_builder_tf2_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/optimizer_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/optimizer_builder_tf1_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/optimizer_builder_tf2_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/post_processing_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/post_processing_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/preprocessor_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/preprocessor_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/region_similarity_calculator_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/region_similarity_calculator_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/target_assigner_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/target_assigner_builder_test.py -> build/lib/object_detection/builders\n","creating build/lib/object_detection/core\n","copying object_detection/core/__init__.py -> build/lib/object_detection/core\n","copying object_detection/core/anchor_generator.py -> build/lib/object_detection/core\n","copying object_detection/core/balanced_positive_negative_sampler.py -> build/lib/object_detection/core\n","copying object_detection/core/balanced_positive_negative_sampler_test.py -> build/lib/object_detection/core\n","copying object_detection/core/batch_multiclass_nms_test.py -> build/lib/object_detection/core\n","copying object_detection/core/batcher.py -> build/lib/object_detection/core\n","copying object_detection/core/batcher_tf1_test.py -> build/lib/object_detection/core\n","copying object_detection/core/box_coder.py -> build/lib/object_detection/core\n","copying object_detection/core/box_coder_test.py -> build/lib/object_detection/core\n","copying object_detection/core/box_list.py -> build/lib/object_detection/core\n","copying object_detection/core/box_list_ops.py -> build/lib/object_detection/core\n","copying object_detection/core/box_list_ops_test.py -> build/lib/object_detection/core\n","copying object_detection/core/box_list_test.py -> build/lib/object_detection/core\n","copying object_detection/core/box_predictor.py -> build/lib/object_detection/core\n","copying object_detection/core/class_agnostic_nms_test.py -> build/lib/object_detection/core\n","copying object_detection/core/data_decoder.py -> build/lib/object_detection/core\n","copying object_detection/core/data_parser.py -> build/lib/object_detection/core\n","copying object_detection/core/densepose_ops.py -> build/lib/object_detection/core\n","copying object_detection/core/densepose_ops_test.py -> build/lib/object_detection/core\n","copying object_detection/core/freezable_batch_norm.py -> build/lib/object_detection/core\n","copying object_detection/core/freezable_batch_norm_tf2_test.py -> build/lib/object_detection/core\n","copying object_detection/core/keypoint_ops.py -> build/lib/object_detection/core\n","copying object_detection/core/keypoint_ops_test.py -> build/lib/object_detection/core\n","copying object_detection/core/losses.py -> build/lib/object_detection/core\n","copying object_detection/core/losses_test.py -> build/lib/object_detection/core\n","copying object_detection/core/matcher.py -> build/lib/object_detection/core\n","copying object_detection/core/matcher_test.py -> build/lib/object_detection/core\n","copying object_detection/core/minibatch_sampler.py -> build/lib/object_detection/core\n","copying object_detection/core/minibatch_sampler_test.py -> build/lib/object_detection/core\n","copying object_detection/core/model.py -> build/lib/object_detection/core\n","copying object_detection/core/model_test.py -> build/lib/object_detection/core\n","copying object_detection/core/multiclass_nms_test.py -> build/lib/object_detection/core\n","copying object_detection/core/post_processing.py -> build/lib/object_detection/core\n","copying object_detection/core/prefetcher.py -> build/lib/object_detection/core\n","copying object_detection/core/prefetcher_tf1_test.py -> build/lib/object_detection/core\n","copying object_detection/core/preprocessor.py -> build/lib/object_detection/core\n","copying object_detection/core/preprocessor_cache.py -> build/lib/object_detection/core\n","copying object_detection/core/preprocessor_test.py -> build/lib/object_detection/core\n","copying object_detection/core/region_similarity_calculator.py -> build/lib/object_detection/core\n","copying object_detection/core/region_similarity_calculator_test.py -> build/lib/object_detection/core\n","copying object_detection/core/standard_fields.py -> build/lib/object_detection/core\n","copying object_detection/core/target_assigner.py -> build/lib/object_detection/core\n","copying object_detection/core/target_assigner_test.py -> build/lib/object_detection/core\n","creating build/lib/object_detection/data_decoders\n","copying object_detection/data_decoders/__init__.py -> build/lib/object_detection/data_decoders\n","copying object_detection/data_decoders/tf_example_decoder.py -> build/lib/object_detection/data_decoders\n","copying object_detection/data_decoders/tf_example_decoder_test.py -> build/lib/object_detection/data_decoders\n","copying object_detection/data_decoders/tf_sequence_example_decoder.py -> build/lib/object_detection/data_decoders\n","copying object_detection/data_decoders/tf_sequence_example_decoder_test.py -> build/lib/object_detection/data_decoders\n","creating build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/__init__.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_ava_actions_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_coco_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_coco_tf_record_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_kitti_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_kitti_tf_record_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_oid_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_pascal_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_pascal_tf_record_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_pet_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/oid_hierarchical_labels_expansion.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/oid_tfrecord_creation.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/oid_tfrecord_creation_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/seq_example_util.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/seq_example_util_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/tf_record_creation_util.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/tf_record_creation_util_test.py -> build/lib/object_detection/dataset_tools\n","creating build/lib/object_detection/inference\n","copying object_detection/inference/__init__.py -> build/lib/object_detection/inference\n","copying object_detection/inference/detection_inference.py -> build/lib/object_detection/inference\n","copying object_detection/inference/detection_inference_tf1_test.py -> build/lib/object_detection/inference\n","copying object_detection/inference/infer_detections.py -> build/lib/object_detection/inference\n","creating build/lib/object_detection/legacy\n","copying object_detection/legacy/__init__.py -> build/lib/object_detection/legacy\n","copying object_detection/legacy/eval.py -> build/lib/object_detection/legacy\n","copying object_detection/legacy/evaluator.py -> build/lib/object_detection/legacy\n","copying object_detection/legacy/train.py -> build/lib/object_detection/legacy\n","copying object_detection/legacy/trainer.py -> build/lib/object_detection/legacy\n","copying object_detection/legacy/trainer_tf1_test.py -> build/lib/object_detection/legacy\n","creating build/lib/object_detection/matchers\n","copying object_detection/matchers/__init__.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/argmax_matcher.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/argmax_matcher_test.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/bipartite_matcher.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/bipartite_matcher_tf1_test.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/hungarian_matcher.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/hungarian_matcher_tf2_test.py -> build/lib/object_detection/matchers\n","creating build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/__init__.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/center_net_meta_arch.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/center_net_meta_arch_tf2_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/context_rcnn_lib.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/context_rcnn_lib_tf1_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/context_rcnn_lib_tf2.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/context_rcnn_lib_tf2_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/context_rcnn_meta_arch.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/context_rcnn_meta_arch_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/faster_rcnn_meta_arch.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/faster_rcnn_meta_arch_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/rfcn_meta_arch.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/rfcn_meta_arch_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/ssd_meta_arch.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/ssd_meta_arch_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/ssd_meta_arch_test_lib.py -> build/lib/object_detection/meta_architectures\n","creating build/lib/object_detection/metrics\n","copying object_detection/metrics/__init__.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/calibration_evaluation.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/calibration_evaluation_tf1_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/calibration_metrics.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/calibration_metrics_tf1_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/coco_evaluation.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/coco_evaluation_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/coco_tools.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/coco_tools_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/io_utils.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/lvis_evaluation.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/lvis_evaluation_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/lvis_tools.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/lvis_tools_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/offline_eval_map_corloc.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/offline_eval_map_corloc_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_challenge_evaluation.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_challenge_evaluation_utils.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_challenge_evaluation_utils_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_vrd_challenge_evaluation.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_vrd_challenge_evaluation_utils.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/tf_example_parser.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/tf_example_parser_test.py -> build/lib/object_detection/metrics\n","creating build/lib/object_detection/models\n","copying object_detection/models/__init__.py -> build/lib/object_detection/models\n","copying object_detection/models/bidirectional_feature_pyramid_generators.py -> build/lib/object_detection/models\n","copying object_detection/models/bidirectional_feature_pyramid_generators_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_hourglass_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_hourglass_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_mobilenet_v2_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_mobilenet_v2_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_resnet_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_resnet_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_resnet_v1_fpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_resnet_v1_fpn_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_v2_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_v2_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_nas_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_nas_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_pnas_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_pnas_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_resnet_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_resnet_keras_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_resnet_v1_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/feature_map_generators.py -> build/lib/object_detection/models\n","copying object_detection/models/feature_map_generators_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_efficientnet_bifpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_efficientnet_bifpn_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_inception_v2_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_inception_v2_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_inception_v3_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_inception_v3_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobiledet_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobiledet_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v3_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v3_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_pnasnet_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_pnasnet_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_ppn_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","creating build/lib/object_detection/predictors\n","copying object_detection/predictors/__init__.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/convolutional_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/convolutional_box_predictor_tf1_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/convolutional_keras_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/convolutional_keras_box_predictor_tf2_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/mask_rcnn_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/mask_rcnn_box_predictor_tf1_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/mask_rcnn_keras_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/mask_rcnn_keras_box_predictor_tf2_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/rfcn_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/rfcn_box_predictor_tf1_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/rfcn_keras_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/rfcn_keras_box_predictor_tf2_test.py -> build/lib/object_detection/predictors\n","creating build/lib/object_detection/protos\n","copying object_detection/protos/__init__.py -> build/lib/object_detection/protos\n","copying object_detection/protos/anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/argmax_matcher_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/bipartite_matcher_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/box_predictor_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/calibration_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/center_net_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/eval_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/faster_rcnn_box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/faster_rcnn_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/flexible_grid_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/fpn_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/graph_rewriter_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/grid_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/hyperparams_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/image_resizer_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/input_reader_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/keypoint_box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/losses_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/matcher_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/mean_stddev_box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/model_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/multiscale_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/optimizer_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/pipeline_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/post_processing_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/preprocessor_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/region_similarity_calculator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/square_box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/ssd_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/ssd_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/string_int_label_map_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/target_assigner_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/train_pb2.py -> build/lib/object_detection/protos\n","creating build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/__init__.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/export_saved_model_tpu.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/export_saved_model_tpu_lib.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/export_saved_model_tpu_lib_tf1_test.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/faster_rcnn.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/ssd.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/utils.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/utils_test.py -> build/lib/object_detection/tpu_exporters\n","creating build/lib/object_detection/utils\n","copying object_detection/utils/__init__.py -> build/lib/object_detection/utils\n","copying object_detection/utils/autoaugment_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/bifpn_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/category_util.py -> build/lib/object_detection/utils\n","copying object_detection/utils/category_util_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/colab_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/config_util.py -> build/lib/object_detection/utils\n","copying object_detection/utils/config_util_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/context_manager.py -> build/lib/object_detection/utils\n","copying object_detection/utils/context_manager_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/dataset_util.py -> build/lib/object_detection/utils\n","copying object_detection/utils/dataset_util_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/json_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/json_utils_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/label_map_util.py -> build/lib/object_detection/utils\n","copying object_detection/utils/label_map_util_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/learning_schedules.py -> build/lib/object_detection/utils\n","copying object_detection/utils/learning_schedules_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/metrics.py -> build/lib/object_detection/utils\n","copying object_detection/utils/metrics_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/model_util.py -> build/lib/object_detection/utils\n","copying object_detection/utils/model_util_tf2_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_list.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_list_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_list_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_list_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_mask_list.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_mask_list_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_mask_list_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_mask_list_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_mask_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_mask_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/object_detection_evaluation.py -> build/lib/object_detection/utils\n","copying object_detection/utils/object_detection_evaluation_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/patch_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/patch_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/per_image_evaluation.py -> build/lib/object_detection/utils\n","copying object_detection/utils/per_image_evaluation_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/per_image_vrd_evaluation.py -> build/lib/object_detection/utils\n","copying object_detection/utils/per_image_vrd_evaluation_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/shape_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/shape_utils_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/spatial_transform_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/spatial_transform_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/static_shape.py -> build/lib/object_detection/utils\n","copying object_detection/utils/static_shape_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/target_assigner_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/target_assigner_utils_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/test_case.py -> build/lib/object_detection/utils\n","copying object_detection/utils/test_case_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/test_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/test_utils_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/tf_version.py -> build/lib/object_detection/utils\n","copying object_detection/utils/variables_helper.py -> build/lib/object_detection/utils\n","copying object_detection/utils/variables_helper_tf1_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/visualization_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/visualization_utils_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/vrd_evaluation.py -> build/lib/object_detection/utils\n","copying object_detection/utils/vrd_evaluation_test.py -> build/lib/object_detection/utils\n","creating build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/__init__.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/add_context_to_examples.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_tf2_test.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/generate_detection_data.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/generate_embedding_data.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","creating build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/__init__.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/convert_keras_models.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/hourglass_network.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/hourglass_network_tf2_test.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/inception_resnet_v2.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/inception_resnet_v2_tf2_test.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/mobilenet_v1.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/mobilenet_v1_tf2_test.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/mobilenet_v2.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/mobilenet_v2_tf2_test.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/model_utils.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/resnet_v1.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/resnet_v1_tf2_test.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/test_utils.py -> build/lib/object_detection/models/keras_models\n","creating build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/__init__.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/box_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/box_head_tf1_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/class_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/class_head_tf1_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_box_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_box_head_tf2_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_class_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_class_head_tf2_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_mask_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_mask_head_tf2_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keypoint_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keypoint_head_tf1_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/mask_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/mask_head_tf1_test.py -> build/lib/object_detection/predictors/heads\n","creating build/lib/object_detection/tpu_exporters/testdata\n","copying object_detection/tpu_exporters/testdata/__init__.py -> build/lib/object_detection/tpu_exporters/testdata\n","copying object_detection/CONTRIBUTING.md -> build/lib/object_detection\n","copying object_detection/README.md -> build/lib/object_detection\n","creating build/lib/object_detection/colab_tutorials\n","copying object_detection/colab_tutorials/context_rcnn_tutorial.ipynb -> build/lib/object_detection/colab_tutorials\n","copying object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb -> build/lib/object_detection/colab_tutorials\n","copying object_detection/colab_tutorials/eager_few_shot_od_training_tflite.ipynb -> build/lib/object_detection/colab_tutorials\n","copying object_detection/colab_tutorials/inference_from_saved_model_tf2_colab.ipynb -> build/lib/object_detection/colab_tutorials\n","copying object_detection/colab_tutorials/inference_tf2_colab.ipynb -> build/lib/object_detection/colab_tutorials\n","copying object_detection/colab_tutorials/object_detection_tutorial.ipynb -> build/lib/object_detection/colab_tutorials\n","creating build/lib/object_detection/configs\n","creating build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/centernet_hourglass104_1024x1024_coco17_tpu-32.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/centernet_hourglass104_1024x1024_kpts_coco17_tpu-32.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/centernet_hourglass104_512x512_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/centernet_hourglass104_512x512_kpts_coco17_tpu-32.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/centernet_resnet101_v1_fpn_512x512_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/centernet_resnet50_v1_fpn_512x512_kpts_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/centernet_resnet50_v2_512x512_kpts_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/faster_rcnn_resnet101_v1_800x1333_coco17_gpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/faster_rcnn_resnet152_v1_800x1333_coco17_gpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/faster_rcnn_resnet50_v1_fpn_640x640_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_efficientdet_d1_640x640_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_efficientdet_d2_768x768_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_efficientdet_d3_896x896_coco17_tpu-32.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_efficientdet_d4_1024x1024_coco17_tpu-32.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_efficientdet_d5_1280x1280_coco17_tpu-32.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_efficientdet_d6_1408x1408_coco17_tpu-32.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_efficientdet_d7_1536x1536_coco17_tpu-32.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_mobilenet_v2_320x320_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_resnet101_v1_fpn_1024x1024_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_resnet152_v1_fpn_640x640_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","copying object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config -> build/lib/object_detection/configs/tf2\n","creating build/lib/object_detection/data\n","copying object_detection/data/ava_label_map_v2.1.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/face_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/face_person_with_keypoints_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/fgvc_2854_classes_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/kitti_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/mscoco_complete_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/mscoco_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/mscoco_minival_ids.txt -> build/lib/object_detection/data\n","copying object_detection/data/oid_bbox_trainable_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/oid_object_detection_challenge_500_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/oid_v4_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/pascal_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/pet_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/snapshot_serengeti_label_map.pbtxt -> build/lib/object_detection/data\n","creating build/lib/object_detection/dockerfiles\n","creating build/lib/object_detection/dockerfiles/android\n","copying object_detection/dockerfiles/android/Dockerfile -> build/lib/object_detection/dockerfiles/android\n","copying object_detection/dockerfiles/android/README.md -> build/lib/object_detection/dockerfiles/android\n","creating build/lib/object_detection/dockerfiles/tf1\n","copying object_detection/dockerfiles/tf1/Dockerfile -> build/lib/object_detection/dockerfiles/tf1\n","copying object_detection/dockerfiles/tf1/README.md -> build/lib/object_detection/dockerfiles/tf1\n","creating build/lib/object_detection/dockerfiles/tf2\n","copying object_detection/dockerfiles/tf2/Dockerfile -> build/lib/object_detection/dockerfiles/tf2\n","copying object_detection/dockerfiles/tf2/README.md -> build/lib/object_detection/dockerfiles/tf2\n","creating build/lib/object_detection/g3doc\n","copying object_detection/g3doc/challenge_evaluation.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/configuring_jobs.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/context_rcnn.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/defining_your_own_model.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/evaluation_protocols.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/exporting_models.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/faq.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/instance_segmentation.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/oid_inference_and_evaluation.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/preparing_inputs.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/release_notes.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/running_notebook.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/running_on_mobile_tensorflowlite.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/running_on_mobile_tf2.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/running_pets.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/tf1.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/tf1_detection_zoo.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/tf1_training_and_evaluation.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/tf2.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/tf2_classification_zoo.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/tf2_detection_zoo.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/tf2_training_and_evaluation.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/tpu_compatibility.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/tpu_exporters.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/using_your_own_dataset.md -> build/lib/object_detection/g3doc\n","creating build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/dogs_detections_output.jpg -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/example_cat.jpg -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/groupof_case_eval.png -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/kites_detections_output.jpg -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/kites_with_segment_overlay.png -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/nongroupof_case_eval.png -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/oid_bus_72e19c28aac34ed8.jpg -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/oid_monkey_3b4168c89cecbc5b.jpg -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/oxford_pet.png -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/tensorboard.png -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/tensorboard2.png -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/tf-od-api-logo.png -> build/lib/object_detection/g3doc/img\n","creating build/lib/object_detection/packages\n","creating build/lib/object_detection/packages/tf1\n","copying object_detection/packages/tf1/setup.py -> build/lib/object_detection/packages/tf1\n","creating build/lib/object_detection/packages/tf2\n","copying object_detection/packages/tf2/setup.py -> build/lib/object_detection/packages/tf2\n","creating build/lib/object_detection/samples\n","creating build/lib/object_detection/samples/cloud\n","copying object_detection/samples/cloud/cloud.yml -> build/lib/object_detection/samples/cloud\n","creating build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/context_rcnn_resnet101_snapshot_serengeti.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/context_rcnn_resnet101_snapshot_serengeti_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/embedded_ssd_mobilenet_v1_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/facessd_mobilenet_v2_quantized_320x320_open_image_v4.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_cosine_lr_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid_v4.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_inception_v2_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_inception_v2_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_nas_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet101_atrous_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet101_ava_v2.1.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet101_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet101_fgvc.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet101_kitti.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet101_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet101_voc07.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet152_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet152_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet50_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet50_fgvc.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet50_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/mask_rcnn_inception_resnet_v2_atrous_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/mask_rcnn_inception_v2_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/mask_rcnn_resnet101_atrous_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/mask_rcnn_resnet101_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/mask_rcnn_resnet50_atrous_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/rfcn_resnet101_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/rfcn_resnet101_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_inception_v2_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_inception_v2_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_inception_v3_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_300x300_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets_inference.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v2_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v2_fpnlite_quantized_shared_box_predictor_256x256_depthmultiplier_75_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v2_fullyconv_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v2_mnasfpn_shared_box_predictor_320x320_coco_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v2_oid_v4.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v2_pets_keras.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v2_quantized_300x300_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_resnet101_v1_fpn_shared_box_predictor_oid_512x512_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobiledet_cpu_320x320_coco_sync_4x4.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobiledet_dsp_320x320_coco_sync_4x4.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobiledet_edgetpu_320x320_coco_sync_4x4.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobiledet_gpu_320x320_coco_sync_4x4.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco_quant.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobilenet_v1_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobilenet_v2_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobilenet_v3_large_320x320_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobilenet_v3_small_320x320_coco.config -> build/lib/object_detection/samples/configs\n","creating build/lib/object_detection/test_data\n","copying object_detection/test_data/context_rcnn_camera_trap.config -> build/lib/object_detection/test_data\n","copying object_detection/test_data/pets_examples.record -> build/lib/object_detection/test_data\n","copying object_detection/test_data/snapshot_serengeti_sequence_examples.record -> build/lib/object_detection/test_data\n","copying object_detection/test_data/ssd_mobilenet_v1_fpp.config -> build/lib/object_detection/test_data\n","creating build/lib/object_detection/test_images\n","copying object_detection/test_images/image1.jpg -> build/lib/object_detection/test_images\n","copying object_detection/test_images/image2.jpg -> build/lib/object_detection/test_images\n","copying object_detection/test_images/image_info.txt -> build/lib/object_detection/test_images\n","creating build/lib/object_detection/test_images/ducky\n","creating build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out1.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out10.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out11.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out12.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out13.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out14.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out15.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out16.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out17.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out18.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out19.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out2.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out20.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out21.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out22.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out23.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out24.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out25.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out26.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out27.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out28.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out29.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out3.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out30.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out31.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out32.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out33.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out34.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out35.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out36.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out37.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out38.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out39.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out4.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out40.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out41.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out42.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out43.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out44.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out45.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out46.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out47.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out48.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out49.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out5.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out6.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out7.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out8.jpg -> build/lib/object_detection/test_images/ducky/test\n","copying object_detection/test_images/ducky/test/out9.jpg -> build/lib/object_detection/test_images/ducky/test\n","creating build/lib/object_detection/test_images/ducky/train\n","copying object_detection/test_images/ducky/train/robertducky1.jpg -> build/lib/object_detection/test_images/ducky/train\n","copying object_detection/test_images/ducky/train/robertducky2.jpg -> build/lib/object_detection/test_images/ducky/train\n","copying object_detection/test_images/ducky/train/robertducky3.jpg -> build/lib/object_detection/test_images/ducky/train\n","copying object_detection/test_images/ducky/train/robertducky4.jpg -> build/lib/object_detection/test_images/ducky/train\n","copying object_detection/test_images/ducky/train/robertducky5.jpg -> build/lib/object_detection/test_images/ducky/train\n","creating build/lib/object_detection/test_images/snapshot_serengeti\n","copying object_detection/test_images/snapshot_serengeti/README.md -> build/lib/object_detection/test_images/snapshot_serengeti\n","copying object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0038.jpeg -> build/lib/object_detection/test_images/snapshot_serengeti\n","copying object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0039.jpeg -> build/lib/object_detection/test_images/snapshot_serengeti\n","copying object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0040.jpeg -> build/lib/object_detection/test_images/snapshot_serengeti\n","copying object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0041.jpeg -> build/lib/object_detection/test_images/snapshot_serengeti\n","copying object_detection/test_images/snapshot_serengeti/context_rcnn_demo_metadata.json -> build/lib/object_detection/test_images/snapshot_serengeti\n","copying object_detection/dataset_tools/create_pycocotools_package.sh -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/download_and_preprocess_ava.sh -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/download_and_preprocess_mscoco.sh -> build/lib/object_detection/dataset_tools\n","creating build/lib/object_detection/dataset_tools/densepose\n","copying object_detection/dataset_tools/densepose/UV_symmetry_transforms.mat -> build/lib/object_detection/dataset_tools/densepose\n","copying object_detection/protos/anchor_generator.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/argmax_matcher.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/bipartite_matcher.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/box_coder.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/box_predictor.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/calibration.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/center_net.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/eval.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/faster_rcnn.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/faster_rcnn_box_coder.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/flexible_grid_anchor_generator.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/fpn.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/graph_rewriter.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/grid_anchor_generator.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/hyperparams.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/image_resizer.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/input_reader.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/keypoint_box_coder.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/losses.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/matcher.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/mean_stddev_box_coder.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/model.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/multiscale_anchor_generator.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/optimizer.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/pipeline.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/post_processing.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/preprocessor.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/region_similarity_calculator.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/square_box_coder.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/ssd.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/ssd_anchor_generator.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/string_int_label_map.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/target_assigner.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/train.proto -> build/lib/object_detection/protos\n","creating build/lib/object_detection/models/keras_models/base_models\n","copying object_detection/models/keras_models/base_models/original_mobilenet_v2.py -> build/lib/object_detection/models/keras_models/base_models\n","creating build/lib/object_detection/tpu_exporters/testdata/faster_rcnn\n","copying object_detection/tpu_exporters/testdata/faster_rcnn/faster_rcnn_resnet101_atrous_coco.config -> build/lib/object_detection/tpu_exporters/testdata/faster_rcnn\n","creating build/lib/object_detection/tpu_exporters/testdata/ssd\n","copying object_detection/tpu_exporters/testdata/ssd/ssd_pipeline.config -> build/lib/object_detection/tpu_exporters/testdata/ssd\n","creating build/bdist.linux-x86_64\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/__init__.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/eval_util.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/eval_util_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/export_inference_graph.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/export_tflite_graph_lib_tf2.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/export_tflite_graph_lib_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/export_tflite_graph_tf2.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/export_tflite_ssd_graph.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/export_tflite_ssd_graph_lib.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/export_tflite_ssd_graph_lib_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/exporter.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/exporter_lib_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/exporter_lib_v2.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/exporter_main_v2.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/exporter_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/inputs.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/inputs_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_hparams.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_lib.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_lib_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_lib_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_lib_v2.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_main.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_main_tf2.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_tpu_main.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","creating build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/faster_rcnn_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/faster_rcnn_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/keypoint_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/keypoint_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/mean_stddev_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/mean_stddev_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/square_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/square_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","creating build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/anchor_generator_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/anchor_generator_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_coder_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_coder_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_predictor_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_predictor_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/calibration_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/calibration_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/dataset_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/dataset_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/decoder_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/decoder_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/graph_rewriter_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/graph_rewriter_builder_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/hyperparams_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/hyperparams_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/image_resizer_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/image_resizer_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/input_reader_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/input_reader_builder_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/losses_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/losses_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/matcher_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/matcher_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/model_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/model_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/model_builder_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/model_builder_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/optimizer_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/optimizer_builder_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/optimizer_builder_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/post_processing_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/post_processing_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/preprocessor_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/preprocessor_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/region_similarity_calculator_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/region_similarity_calculator_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/target_assigner_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/target_assigner_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","creating build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/balanced_positive_negative_sampler.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/balanced_positive_negative_sampler_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/batch_multiclass_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/batcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/batcher_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/class_agnostic_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/data_decoder.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/data_parser.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/densepose_ops.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/densepose_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/freezable_batch_norm.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/freezable_batch_norm_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/keypoint_ops.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/keypoint_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/losses.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/losses_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/matcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/minibatch_sampler.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/minibatch_sampler_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/model.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/model_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/multiclass_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/post_processing.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/prefetcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/prefetcher_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/preprocessor.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/preprocessor_cache.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/preprocessor_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/region_similarity_calculator.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/region_similarity_calculator_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/standard_fields.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/target_assigner.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/target_assigner_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","creating build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/tf_example_decoder.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/tf_example_decoder_test.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/tf_sequence_example_decoder.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/tf_sequence_example_decoder_test.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","creating build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_ava_actions_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_coco_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_coco_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_kitti_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_kitti_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_oid_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_pascal_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_pascal_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_pet_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_tfrecord_creation.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_tfrecord_creation_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/seq_example_util.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/seq_example_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/tf_record_creation_util.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/tf_record_creation_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","creating build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/add_context_to_examples.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/generate_detection_data.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/generate_embedding_data.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/create_pycocotools_package.sh -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/download_and_preprocess_ava.sh -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/download_and_preprocess_mscoco.sh -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","creating build/bdist.linux-x86_64/egg/object_detection/dataset_tools/densepose\n","copying build/lib/object_detection/dataset_tools/densepose/UV_symmetry_transforms.mat -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/densepose\n","creating build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/detection_inference.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/detection_inference_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/infer_detections.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","creating build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/eval.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/evaluator.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/train.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/trainer.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/trainer_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","creating build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/argmax_matcher.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/argmax_matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/bipartite_matcher.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/bipartite_matcher_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/hungarian_matcher.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/hungarian_matcher_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","creating build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/center_net_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/center_net_meta_arch_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/context_rcnn_lib.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/context_rcnn_lib_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/context_rcnn_lib_tf2.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/context_rcnn_lib_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/context_rcnn_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/context_rcnn_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/rfcn_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/rfcn_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/ssd_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/ssd_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/ssd_meta_arch_test_lib.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","creating build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_evaluation_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_metrics.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_metrics_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_tools.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_tools_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/io_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/lvis_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/lvis_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/lvis_tools.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/lvis_tools_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/offline_eval_map_corloc.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/offline_eval_map_corloc_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_challenge_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_challenge_evaluation_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_challenge_evaluation_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/tf_example_parser.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/tf_example_parser_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","creating build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/bidirectional_feature_pyramid_generators.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/bidirectional_feature_pyramid_generators_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_hourglass_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_hourglass_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_mobilenet_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_mobilenet_v2_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_resnet_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_resnet_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_resnet_v1_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_resnet_v1_fpn_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_nas_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_nas_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_keras_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/feature_map_generators.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/feature_map_generators_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_efficientnet_bifpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_efficientnet_bifpn_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v2_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v3_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v3_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobiledet_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobiledet_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_pnasnet_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_pnasnet_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","creating build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/convert_keras_models.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/hourglass_network.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/hourglass_network_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/inception_resnet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/inception_resnet_v2_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v1.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v1_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v2_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/model_utils.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/resnet_v1.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/resnet_v1_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/test_utils.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","creating build/bdist.linux-x86_64/egg/object_detection/models/keras_models/base_models\n","copying build/lib/object_detection/models/keras_models/base_models/original_mobilenet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models/base_models\n","creating build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/convolutional_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/convolutional_box_predictor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/convolutional_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/convolutional_keras_box_predictor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/mask_rcnn_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/mask_rcnn_box_predictor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_box_predictor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_keras_box_predictor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","creating build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/box_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/box_head_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/class_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/class_head_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_box_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_box_head_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_class_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_class_head_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_mask_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_mask_head_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keypoint_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keypoint_head_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/mask_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/mask_head_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","creating build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/argmax_matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/bipartite_matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/box_predictor_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/calibration_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/center_net_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/eval_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/faster_rcnn_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/faster_rcnn_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/flexible_grid_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/fpn_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/graph_rewriter_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/grid_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/hyperparams_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/image_resizer_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/input_reader_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/keypoint_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/losses_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/mean_stddev_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/model_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/multiscale_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/optimizer_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/pipeline_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/post_processing_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/preprocessor_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/region_similarity_calculator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/square_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/ssd_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/ssd_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/string_int_label_map_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/target_assigner_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/train_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/argmax_matcher.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/bipartite_matcher.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/box_predictor.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/calibration.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/center_net.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/eval.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/faster_rcnn.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/faster_rcnn_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/flexible_grid_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/fpn.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/graph_rewriter.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/grid_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/hyperparams.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/image_resizer.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/input_reader.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/keypoint_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/losses.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/matcher.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/mean_stddev_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/model.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/multiscale_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/optimizer.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/pipeline.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/post_processing.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/preprocessor.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/region_similarity_calculator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/square_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/ssd.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/ssd_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/string_int_label_map.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/target_assigner.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/train.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/faster_rcnn.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/ssd.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/utils.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata\n","copying build/lib/object_detection/tpu_exporters/testdata/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata\n","creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/faster_rcnn\n","copying build/lib/object_detection/tpu_exporters/testdata/faster_rcnn/faster_rcnn_resnet101_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/faster_rcnn\n","creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/ssd\n","copying build/lib/object_detection/tpu_exporters/testdata/ssd/ssd_pipeline.config -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/ssd\n","creating build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/autoaugment_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/bifpn_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/category_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/category_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/colab_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/config_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/config_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/context_manager.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/context_manager_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/dataset_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/dataset_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/json_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/json_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/label_map_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/label_map_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/learning_schedules.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/learning_schedules_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/metrics.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/metrics_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/model_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/model_util_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_mask_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_mask_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/object_detection_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/object_detection_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/patch_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/patch_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_vrd_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_vrd_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/shape_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/shape_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/spatial_transform_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/spatial_transform_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/static_shape.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/static_shape_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/target_assigner_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/target_assigner_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/test_case.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/test_case_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/test_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/test_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/tf_version.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/variables_helper.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/variables_helper_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/visualization_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/visualization_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/vrd_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/vrd_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/CONTRIBUTING.md -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/README.md -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/colab_tutorials\n","copying build/lib/object_detection/colab_tutorials/context_rcnn_tutorial.ipynb -> build/bdist.linux-x86_64/egg/object_detection/colab_tutorials\n","copying build/lib/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb -> build/bdist.linux-x86_64/egg/object_detection/colab_tutorials\n","copying build/lib/object_detection/colab_tutorials/eager_few_shot_od_training_tflite.ipynb -> build/bdist.linux-x86_64/egg/object_detection/colab_tutorials\n","copying build/lib/object_detection/colab_tutorials/inference_from_saved_model_tf2_colab.ipynb -> build/bdist.linux-x86_64/egg/object_detection/colab_tutorials\n","copying build/lib/object_detection/colab_tutorials/inference_tf2_colab.ipynb -> build/bdist.linux-x86_64/egg/object_detection/colab_tutorials\n","copying build/lib/object_detection/colab_tutorials/object_detection_tutorial.ipynb -> build/bdist.linux-x86_64/egg/object_detection/colab_tutorials\n","creating build/bdist.linux-x86_64/egg/object_detection/configs\n","creating build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/centernet_hourglass104_1024x1024_coco17_tpu-32.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/centernet_hourglass104_1024x1024_kpts_coco17_tpu-32.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/centernet_hourglass104_512x512_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/centernet_hourglass104_512x512_kpts_coco17_tpu-32.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/centernet_resnet101_v1_fpn_512x512_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/centernet_resnet50_v1_fpn_512x512_kpts_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/centernet_resnet50_v2_512x512_kpts_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/faster_rcnn_resnet101_v1_800x1333_coco17_gpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/faster_rcnn_resnet152_v1_800x1333_coco17_gpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/faster_rcnn_resnet50_v1_fpn_640x640_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_efficientdet_d1_640x640_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_efficientdet_d2_768x768_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_efficientdet_d3_896x896_coco17_tpu-32.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_efficientdet_d4_1024x1024_coco17_tpu-32.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_efficientdet_d5_1280x1280_coco17_tpu-32.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_efficientdet_d6_1408x1408_coco17_tpu-32.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_efficientdet_d7_1536x1536_coco17_tpu-32.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_mobilenet_v2_320x320_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_resnet101_v1_fpn_1024x1024_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_resnet152_v1_fpn_640x640_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","copying build/lib/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config -> build/bdist.linux-x86_64/egg/object_detection/configs/tf2\n","creating build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/ava_label_map_v2.1.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/face_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/face_person_with_keypoints_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/fgvc_2854_classes_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/kitti_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/mscoco_complete_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/mscoco_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/mscoco_minival_ids.txt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/oid_bbox_trainable_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/oid_object_detection_challenge_500_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/oid_v4_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/pascal_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/pet_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/snapshot_serengeti_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","creating build/bdist.linux-x86_64/egg/object_detection/dockerfiles\n","creating build/bdist.linux-x86_64/egg/object_detection/dockerfiles/android\n","copying build/lib/object_detection/dockerfiles/android/Dockerfile -> build/bdist.linux-x86_64/egg/object_detection/dockerfiles/android\n","copying build/lib/object_detection/dockerfiles/android/README.md -> build/bdist.linux-x86_64/egg/object_detection/dockerfiles/android\n","creating build/bdist.linux-x86_64/egg/object_detection/dockerfiles/tf1\n","copying build/lib/object_detection/dockerfiles/tf1/Dockerfile -> build/bdist.linux-x86_64/egg/object_detection/dockerfiles/tf1\n","copying build/lib/object_detection/dockerfiles/tf1/README.md -> build/bdist.linux-x86_64/egg/object_detection/dockerfiles/tf1\n","creating build/bdist.linux-x86_64/egg/object_detection/dockerfiles/tf2\n","copying build/lib/object_detection/dockerfiles/tf2/Dockerfile -> build/bdist.linux-x86_64/egg/object_detection/dockerfiles/tf2\n","copying build/lib/object_detection/dockerfiles/tf2/README.md -> build/bdist.linux-x86_64/egg/object_detection/dockerfiles/tf2\n","creating build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/challenge_evaluation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/configuring_jobs.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/context_rcnn.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/defining_your_own_model.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/evaluation_protocols.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/exporting_models.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/faq.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/instance_segmentation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/oid_inference_and_evaluation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/preparing_inputs.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/release_notes.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/running_notebook.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/running_on_mobile_tensorflowlite.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/running_on_mobile_tf2.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/running_pets.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/tf1.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/tf1_detection_zoo.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/tf1_training_and_evaluation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/tf2.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/tf2_classification_zoo.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/tf2_detection_zoo.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/tf2_training_and_evaluation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/tpu_compatibility.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/tpu_exporters.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/using_your_own_dataset.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","creating build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/dogs_detections_output.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/example_cat.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/groupof_case_eval.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/kites_detections_output.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/kites_with_segment_overlay.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/nongroupof_case_eval.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/oid_bus_72e19c28aac34ed8.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/oid_monkey_3b4168c89cecbc5b.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/oxford_pet.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/tensorboard.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/tensorboard2.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/tf-od-api-logo.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","creating build/bdist.linux-x86_64/egg/object_detection/packages\n","creating build/bdist.linux-x86_64/egg/object_detection/packages/tf1\n","copying build/lib/object_detection/packages/tf1/setup.py -> build/bdist.linux-x86_64/egg/object_detection/packages/tf1\n","creating build/bdist.linux-x86_64/egg/object_detection/packages/tf2\n","copying build/lib/object_detection/packages/tf2/setup.py -> build/bdist.linux-x86_64/egg/object_detection/packages/tf2\n","creating build/bdist.linux-x86_64/egg/object_detection/samples\n","creating build/bdist.linux-x86_64/egg/object_detection/samples/cloud\n","copying build/lib/object_detection/samples/cloud/cloud.yml -> build/bdist.linux-x86_64/egg/object_detection/samples/cloud\n","creating build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/context_rcnn_resnet101_snapshot_serengeti.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/context_rcnn_resnet101_snapshot_serengeti_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/embedded_ssd_mobilenet_v1_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/facessd_mobilenet_v2_quantized_320x320_open_image_v4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_cosine_lr_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid_v4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_inception_v2_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_nas_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_ava_v2.1.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_fgvc.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_kitti.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_voc07.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet152_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet152_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet50_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet50_fgvc.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet50_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/mask_rcnn_inception_resnet_v2_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/mask_rcnn_inception_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/mask_rcnn_resnet101_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/mask_rcnn_resnet101_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/mask_rcnn_resnet50_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/rfcn_resnet101_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/rfcn_resnet101_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_inception_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_inception_v2_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_inception_v3_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets_inference.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_fpnlite_quantized_shared_box_predictor_256x256_depthmultiplier_75_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_fullyconv_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_mnasfpn_shared_box_predictor_320x320_coco_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_oid_v4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_pets_keras.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_quantized_300x300_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_resnet101_v1_fpn_shared_box_predictor_oid_512x512_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobiledet_cpu_320x320_coco_sync_4x4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobiledet_dsp_320x320_coco_sync_4x4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobiledet_edgetpu_320x320_coco_sync_4x4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobiledet_gpu_320x320_coco_sync_4x4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco_quant.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_v1_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_v3_large_320x320_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_v3_small_320x320_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","creating build/bdist.linux-x86_64/egg/object_detection/test_data\n","copying build/lib/object_detection/test_data/context_rcnn_camera_trap.config -> build/bdist.linux-x86_64/egg/object_detection/test_data\n","copying build/lib/object_detection/test_data/pets_examples.record -> build/bdist.linux-x86_64/egg/object_detection/test_data\n","copying build/lib/object_detection/test_data/snapshot_serengeti_sequence_examples.record -> build/bdist.linux-x86_64/egg/object_detection/test_data\n","copying build/lib/object_detection/test_data/ssd_mobilenet_v1_fpp.config -> build/bdist.linux-x86_64/egg/object_detection/test_data\n","creating build/bdist.linux-x86_64/egg/object_detection/test_images\n","copying build/lib/object_detection/test_images/image1.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images\n","copying build/lib/object_detection/test_images/image2.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images\n","copying build/lib/object_detection/test_images/image_info.txt -> build/bdist.linux-x86_64/egg/object_detection/test_images\n","creating build/bdist.linux-x86_64/egg/object_detection/test_images/ducky\n","creating build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out1.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out10.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out11.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out12.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out13.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out14.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out15.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out16.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out17.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out18.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out19.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out2.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out20.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out21.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out22.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out23.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out24.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out25.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out26.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out27.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out28.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out29.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out3.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out30.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out31.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out32.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out33.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out34.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out35.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out36.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out37.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out38.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out39.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out4.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out40.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out41.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out42.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out43.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out44.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out45.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out46.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out47.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out48.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out49.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out5.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out6.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out7.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out8.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","copying build/lib/object_detection/test_images/ducky/test/out9.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/test\n","creating build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/train\n","copying build/lib/object_detection/test_images/ducky/train/robertducky1.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/train\n","copying build/lib/object_detection/test_images/ducky/train/robertducky2.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/train\n","copying build/lib/object_detection/test_images/ducky/train/robertducky3.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/train\n","copying build/lib/object_detection/test_images/ducky/train/robertducky4.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/train\n","copying build/lib/object_detection/test_images/ducky/train/robertducky5.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images/ducky/train\n","creating build/bdist.linux-x86_64/egg/object_detection/test_images/snapshot_serengeti\n","copying build/lib/object_detection/test_images/snapshot_serengeti/README.md -> build/bdist.linux-x86_64/egg/object_detection/test_images/snapshot_serengeti\n","copying build/lib/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0038.jpeg -> build/bdist.linux-x86_64/egg/object_detection/test_images/snapshot_serengeti\n","copying build/lib/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0039.jpeg -> build/bdist.linux-x86_64/egg/object_detection/test_images/snapshot_serengeti\n","copying build/lib/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0040.jpeg -> build/bdist.linux-x86_64/egg/object_detection/test_images/snapshot_serengeti\n","copying build/lib/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0041.jpeg -> build/bdist.linux-x86_64/egg/object_detection/test_images/snapshot_serengeti\n","copying build/lib/object_detection/test_images/snapshot_serengeti/context_rcnn_demo_metadata.json -> build/bdist.linux-x86_64/egg/object_detection/test_images/snapshot_serengeti\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/eval_util.py to eval_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/eval_util_test.py to eval_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_inference_graph.py to export_inference_graph.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_graph_lib_tf2.py to export_tflite_graph_lib_tf2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_graph_lib_tf2_test.py to export_tflite_graph_lib_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_graph_tf2.py to export_tflite_graph_tf2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph.py to export_tflite_ssd_graph.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph_lib.py to export_tflite_ssd_graph_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph_lib_tf1_test.py to export_tflite_ssd_graph_lib_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter.py to exporter.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter_lib_tf2_test.py to exporter_lib_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter_lib_v2.py to exporter_lib_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter_main_v2.py to exporter_main_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter_tf1_test.py to exporter_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inputs.py to inputs.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inputs_test.py to inputs_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_hparams.py to model_hparams.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib.py to model_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_tf1_test.py to model_lib_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_tf2_test.py to model_lib_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_v2.py to model_lib_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_main.py to model_main.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_main_tf2.py to model_main_tf2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_tpu_main.py to model_tpu_main.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/flexible_grid_anchor_generator.py to flexible_grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py to flexible_grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/grid_anchor_generator.py to grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/grid_anchor_generator_test.py to grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiple_grid_anchor_generator.py to multiple_grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py to multiple_grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiscale_grid_anchor_generator.py to multiscale_grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py to multiscale_grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/faster_rcnn_box_coder.py to faster_rcnn_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/faster_rcnn_box_coder_test.py to faster_rcnn_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/keypoint_box_coder.py to keypoint_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/keypoint_box_coder_test.py to keypoint_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/mean_stddev_box_coder.py to mean_stddev_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/mean_stddev_box_coder_test.py to mean_stddev_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/square_box_coder.py to square_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/square_box_coder_test.py to square_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/anchor_generator_builder.py to anchor_generator_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/anchor_generator_builder_test.py to anchor_generator_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_coder_builder.py to box_coder_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_coder_builder_test.py to box_coder_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_predictor_builder.py to box_predictor_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_predictor_builder_test.py to box_predictor_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/calibration_builder.py to calibration_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/calibration_builder_test.py to calibration_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/dataset_builder.py to dataset_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/dataset_builder_test.py to dataset_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/decoder_builder.py to decoder_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/decoder_builder_test.py to decoder_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/graph_rewriter_builder.py to graph_rewriter_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/graph_rewriter_builder_tf1_test.py to graph_rewriter_builder_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/hyperparams_builder.py to hyperparams_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/hyperparams_builder_test.py to hyperparams_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/image_resizer_builder.py to image_resizer_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/image_resizer_builder_test.py to image_resizer_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/input_reader_builder.py to input_reader_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/input_reader_builder_tf1_test.py to input_reader_builder_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/losses_builder.py to losses_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/losses_builder_test.py to losses_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/matcher_builder.py to matcher_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/matcher_builder_test.py to matcher_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder.py to model_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder_test.py to model_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder_tf1_test.py to model_builder_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder_tf2_test.py to model_builder_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/optimizer_builder.py to optimizer_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/optimizer_builder_tf1_test.py to optimizer_builder_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/optimizer_builder_tf2_test.py to optimizer_builder_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/post_processing_builder.py to post_processing_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/post_processing_builder_test.py to post_processing_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/preprocessor_builder.py to preprocessor_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/preprocessor_builder_test.py to preprocessor_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/region_similarity_calculator_builder.py to region_similarity_calculator_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/region_similarity_calculator_builder_test.py to region_similarity_calculator_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/target_assigner_builder.py to target_assigner_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/target_assigner_builder_test.py to target_assigner_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/anchor_generator.py to anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/balanced_positive_negative_sampler.py to balanced_positive_negative_sampler.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/balanced_positive_negative_sampler_test.py to balanced_positive_negative_sampler_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batch_multiclass_nms_test.py to batch_multiclass_nms_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batcher.py to batcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batcher_tf1_test.py to batcher_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_coder.py to box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_coder_test.py to box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list.py to box_list.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_ops.py to box_list_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_ops_test.py to box_list_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_test.py to box_list_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_predictor.py to box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/class_agnostic_nms_test.py to class_agnostic_nms_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/data_decoder.py to data_decoder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/data_parser.py to data_parser.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/densepose_ops.py to densepose_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/densepose_ops_test.py to densepose_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/freezable_batch_norm.py to freezable_batch_norm.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/freezable_batch_norm_tf2_test.py to freezable_batch_norm_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/keypoint_ops.py to keypoint_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/keypoint_ops_test.py to keypoint_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/losses.py to losses.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/losses_test.py to losses_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/matcher.py to matcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/matcher_test.py to matcher_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/minibatch_sampler.py to minibatch_sampler.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/minibatch_sampler_test.py to minibatch_sampler_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/model.py to model.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/model_test.py to model_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/multiclass_nms_test.py to multiclass_nms_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/post_processing.py to post_processing.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/prefetcher.py to prefetcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/prefetcher_tf1_test.py to prefetcher_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor.py to preprocessor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor_cache.py to preprocessor_cache.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor_test.py to preprocessor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/region_similarity_calculator.py to region_similarity_calculator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/region_similarity_calculator_test.py to region_similarity_calculator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/standard_fields.py to standard_fields.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/target_assigner.py to target_assigner.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/target_assigner_test.py to target_assigner_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_example_decoder.py to tf_example_decoder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_example_decoder_test.py to tf_example_decoder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_sequence_example_decoder.py to tf_sequence_example_decoder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_sequence_example_decoder_test.py to tf_sequence_example_decoder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_ava_actions_tf_record.py to create_ava_actions_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_coco_tf_record.py to create_coco_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_coco_tf_record_test.py to create_coco_tf_record_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_kitti_tf_record.py to create_kitti_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_kitti_tf_record_test.py to create_kitti_tf_record_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_oid_tf_record.py to create_oid_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pascal_tf_record.py to create_pascal_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pascal_tf_record_test.py to create_pascal_tf_record_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pet_tf_record.py to create_pet_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py to oid_hierarchical_labels_expansion.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py to oid_hierarchical_labels_expansion_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_tfrecord_creation.py to oid_tfrecord_creation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_tfrecord_creation_test.py to oid_tfrecord_creation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/seq_example_util.py to seq_example_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/seq_example_util_test.py to seq_example_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/tf_record_creation_util.py to tf_record_creation_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/tf_record_creation_util_test.py to tf_record_creation_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/add_context_to_examples.py to add_context_to_examples.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py to add_context_to_examples_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py to create_cococameratraps_tfexample_main.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_tf2_test.py to create_cococameratraps_tfexample_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/generate_detection_data.py to generate_detection_data.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py to generate_detection_data_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/generate_embedding_data.py to generate_embedding_data.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py to generate_embedding_data_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/detection_inference.py to detection_inference.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/detection_inference_tf1_test.py to detection_inference_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/infer_detections.py to infer_detections.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/eval.py to eval.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/evaluator.py to evaluator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/train.py to train.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/trainer.py to trainer.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/trainer_tf1_test.py to trainer_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/argmax_matcher.py to argmax_matcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/argmax_matcher_test.py to argmax_matcher_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/bipartite_matcher.py to bipartite_matcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/bipartite_matcher_tf1_test.py to bipartite_matcher_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/hungarian_matcher.py to hungarian_matcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/hungarian_matcher_tf2_test.py to hungarian_matcher_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/center_net_meta_arch.py to center_net_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/center_net_meta_arch_tf2_test.py to center_net_meta_arch_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/context_rcnn_lib.py to context_rcnn_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/context_rcnn_lib_tf1_test.py to context_rcnn_lib_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/context_rcnn_lib_tf2.py to context_rcnn_lib_tf2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/context_rcnn_lib_tf2_test.py to context_rcnn_lib_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/context_rcnn_meta_arch.py to context_rcnn_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/context_rcnn_meta_arch_test.py to context_rcnn_meta_arch_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch.py to faster_rcnn_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py to faster_rcnn_meta_arch_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py to faster_rcnn_meta_arch_test_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/rfcn_meta_arch.py to rfcn_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/rfcn_meta_arch_test.py to rfcn_meta_arch_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch.py to ssd_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch_test.py to ssd_meta_arch_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch_test_lib.py to ssd_meta_arch_test_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_evaluation.py to calibration_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_evaluation_tf1_test.py to calibration_evaluation_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_metrics.py to calibration_metrics.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_metrics_tf1_test.py to calibration_metrics_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_evaluation.py to coco_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_evaluation_test.py to coco_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_tools.py to coco_tools.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_tools_test.py to coco_tools_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/io_utils.py to io_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/lvis_evaluation.py to lvis_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/lvis_evaluation_test.py to lvis_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/lvis_tools.py to lvis_tools.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/lvis_tools_test.py to lvis_tools_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/offline_eval_map_corloc.py to offline_eval_map_corloc.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/offline_eval_map_corloc_test.py to offline_eval_map_corloc_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation.py to oid_challenge_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation_utils.py to oid_challenge_evaluation_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation_utils_test.py to oid_challenge_evaluation_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation.py to oid_vrd_challenge_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py to oid_vrd_challenge_evaluation_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py to oid_vrd_challenge_evaluation_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/tf_example_parser.py to tf_example_parser.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/tf_example_parser_test.py to tf_example_parser_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/bidirectional_feature_pyramid_generators.py to bidirectional_feature_pyramid_generators.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/bidirectional_feature_pyramid_generators_tf2_test.py to bidirectional_feature_pyramid_generators_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_hourglass_feature_extractor.py to center_net_hourglass_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_hourglass_feature_extractor_tf2_test.py to center_net_hourglass_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_mobilenet_v2_feature_extractor.py to center_net_mobilenet_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_mobilenet_v2_feature_extractor_tf2_test.py to center_net_mobilenet_v2_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor.py to center_net_mobilenet_v2_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor_tf2_test.py to center_net_mobilenet_v2_fpn_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_resnet_feature_extractor.py to center_net_resnet_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_resnet_feature_extractor_tf2_test.py to center_net_resnet_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_resnet_v1_fpn_feature_extractor.py to center_net_resnet_v1_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_resnet_v1_fpn_feature_extractor_tf2_test.py to center_net_resnet_v1_fpn_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py to embedded_ssd_mobilenet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_tf1_test.py to embedded_ssd_mobilenet_v1_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py to faster_rcnn_inception_resnet_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_tf1_test.py to faster_rcnn_inception_resnet_v2_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py to faster_rcnn_inception_resnet_v2_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_tf2_test.py to faster_rcnn_inception_resnet_v2_keras_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py to faster_rcnn_inception_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_v2_feature_extractor_tf1_test.py to faster_rcnn_inception_v2_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py to faster_rcnn_mobilenet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_tf1_test.py to faster_rcnn_mobilenet_v1_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_nas_feature_extractor.py to faster_rcnn_nas_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_nas_feature_extractor_tf1_test.py to faster_rcnn_nas_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_pnas_feature_extractor.py to faster_rcnn_pnas_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_pnas_feature_extractor_tf1_test.py to faster_rcnn_pnas_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_keras_feature_extractor.py to faster_rcnn_resnet_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_keras_feature_extractor_tf2_test.py to faster_rcnn_resnet_keras_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py to faster_rcnn_resnet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_tf1_test.py to faster_rcnn_resnet_v1_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor.py to faster_rcnn_resnet_v1_fpn_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor_tf2_test.py to faster_rcnn_resnet_v1_fpn_keras_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/feature_map_generators.py to feature_map_generators.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/feature_map_generators_test.py to feature_map_generators_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_efficientnet_bifpn_feature_extractor.py to ssd_efficientnet_bifpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_efficientnet_bifpn_feature_extractor_tf2_test.py to ssd_efficientnet_bifpn_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_feature_extractor_test.py to ssd_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v2_feature_extractor.py to ssd_inception_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v2_feature_extractor_tf1_test.py to ssd_inception_v2_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v3_feature_extractor.py to ssd_inception_v3_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v3_feature_extractor_tf1_test.py to ssd_inception_v3_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobiledet_feature_extractor.py to ssd_mobiledet_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobiledet_feature_extractor_tf1_test.py to ssd_mobiledet_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py to ssd_mobilenet_edgetpu_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py to ssd_mobilenet_edgetpu_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_tf1_test.py to ssd_mobilenet_edgetpu_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_feature_extractor.py to ssd_mobilenet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf1_test.py to ssd_mobilenet_v1_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf2_test.py to ssd_mobilenet_v1_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py to ssd_mobilenet_v1_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf1_test.py to ssd_mobilenet_v1_fpn_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf2_test.py to ssd_mobilenet_v1_fpn_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py to ssd_mobilenet_v1_fpn_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py to ssd_mobilenet_v1_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py to ssd_mobilenet_v1_ppn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_tf1_test.py to ssd_mobilenet_v1_ppn_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_feature_extractor.py to ssd_mobilenet_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf1_test.py to ssd_mobilenet_v2_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf2_test.py to ssd_mobilenet_v2_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py to ssd_mobilenet_v2_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf1_test.py to ssd_mobilenet_v2_fpn_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf2_test.py to ssd_mobilenet_v2_fpn_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py to ssd_mobilenet_v2_fpn_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py to ssd_mobilenet_v2_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor.py to ssd_mobilenet_v2_mnasfpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor_tf1_test.py to ssd_mobilenet_v2_mnasfpn_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v3_feature_extractor.py to ssd_mobilenet_v3_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py to ssd_mobilenet_v3_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v3_feature_extractor_tf1_test.py to ssd_mobilenet_v3_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_pnasnet_feature_extractor.py to ssd_pnasnet_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_pnasnet_feature_extractor_tf1_test.py to ssd_pnasnet_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py to ssd_resnet_v1_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py to ssd_resnet_v1_fpn_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf1_test.py to ssd_resnet_v1_fpn_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf2_test.py to ssd_resnet_v1_fpn_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py to ssd_resnet_v1_fpn_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py to ssd_resnet_v1_ppn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py to ssd_resnet_v1_ppn_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_tf1_test.py to ssd_resnet_v1_ppn_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/convert_keras_models.py to convert_keras_models.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/hourglass_network.py to hourglass_network.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/hourglass_network_tf2_test.py to hourglass_network_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/inception_resnet_v2.py to inception_resnet_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/inception_resnet_v2_tf2_test.py to inception_resnet_v2_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v1.py to mobilenet_v1.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v1_tf2_test.py to mobilenet_v1_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v2.py to mobilenet_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v2_tf2_test.py to mobilenet_v2_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/model_utils.py to model_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/resnet_v1.py to resnet_v1.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/resnet_v1_tf2_test.py to resnet_v1_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/test_utils.py to test_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/base_models/original_mobilenet_v2.py to original_mobilenet_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_box_predictor.py to convolutional_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_box_predictor_tf1_test.py to convolutional_box_predictor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_keras_box_predictor.py to convolutional_keras_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_keras_box_predictor_tf2_test.py to convolutional_keras_box_predictor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_box_predictor.py to mask_rcnn_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_box_predictor_tf1_test.py to mask_rcnn_box_predictor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_keras_box_predictor.py to mask_rcnn_keras_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_keras_box_predictor_tf2_test.py to mask_rcnn_keras_box_predictor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_box_predictor.py to rfcn_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_box_predictor_tf1_test.py to rfcn_box_predictor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_keras_box_predictor.py to rfcn_keras_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_keras_box_predictor_tf2_test.py to rfcn_keras_box_predictor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/box_head.py to box_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/box_head_tf1_test.py to box_head_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/class_head.py to class_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/class_head_tf1_test.py to class_head_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/head.py to head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_box_head.py to keras_box_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_box_head_tf2_test.py to keras_box_head_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_class_head.py to keras_class_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_class_head_tf2_test.py to keras_class_head_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_mask_head.py to keras_mask_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_mask_head_tf2_test.py to keras_mask_head_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keypoint_head.py to keypoint_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keypoint_head_tf1_test.py to keypoint_head_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/mask_head.py to mask_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/mask_head_tf1_test.py to mask_head_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/anchor_generator_pb2.py to anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/argmax_matcher_pb2.py to argmax_matcher_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/bipartite_matcher_pb2.py to bipartite_matcher_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/box_coder_pb2.py to box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/box_predictor_pb2.py to box_predictor_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/calibration_pb2.py to calibration_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/center_net_pb2.py to center_net_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/eval_pb2.py to eval_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/faster_rcnn_box_coder_pb2.py to faster_rcnn_box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/faster_rcnn_pb2.py to faster_rcnn_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/flexible_grid_anchor_generator_pb2.py to flexible_grid_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/fpn_pb2.py to fpn_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/graph_rewriter_pb2.py to graph_rewriter_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/grid_anchor_generator_pb2.py to grid_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/hyperparams_pb2.py to hyperparams_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/image_resizer_pb2.py to image_resizer_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/input_reader_pb2.py to input_reader_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/keypoint_box_coder_pb2.py to keypoint_box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/losses_pb2.py to losses_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/matcher_pb2.py to matcher_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/mean_stddev_box_coder_pb2.py to mean_stddev_box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/model_pb2.py to model_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/multiscale_anchor_generator_pb2.py to multiscale_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/optimizer_pb2.py to optimizer_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/pipeline_pb2.py to pipeline_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/post_processing_pb2.py to post_processing_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/preprocessor_pb2.py to preprocessor_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/region_similarity_calculator_pb2.py to region_similarity_calculator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/square_box_coder_pb2.py to square_box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/ssd_anchor_generator_pb2.py to ssd_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/ssd_pb2.py to ssd_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/string_int_label_map_pb2.py to string_int_label_map_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/target_assigner_pb2.py to target_assigner_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/train_pb2.py to train_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu.py to export_saved_model_tpu.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu_lib.py to export_saved_model_tpu_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu_lib_tf1_test.py to export_saved_model_tpu_lib_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/faster_rcnn.py to faster_rcnn.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/ssd.py to ssd.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/utils.py to utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/utils_test.py to utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/autoaugment_utils.py to autoaugment_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/bifpn_utils.py to bifpn_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/category_util.py to category_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/category_util_test.py to category_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/colab_utils.py to colab_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/config_util.py to config_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/config_util_test.py to config_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/context_manager.py to context_manager.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/context_manager_test.py to context_manager_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/dataset_util.py to dataset_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/dataset_util_test.py to dataset_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/json_utils.py to json_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/json_utils_test.py to json_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/label_map_util.py to label_map_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/label_map_util_test.py to label_map_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/learning_schedules.py to learning_schedules.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/learning_schedules_test.py to learning_schedules_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/metrics.py to metrics.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/metrics_test.py to metrics_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/model_util.py to model_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/model_util_tf2_test.py to model_util_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list.py to np_box_list.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_ops.py to np_box_list_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_ops_test.py to np_box_list_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_test.py to np_box_list_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list.py to np_box_mask_list.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_ops.py to np_box_mask_list_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_ops_test.py to np_box_mask_list_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_test.py to np_box_mask_list_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_ops.py to np_box_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_ops_test.py to np_box_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_mask_ops.py to np_mask_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_mask_ops_test.py to np_mask_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/object_detection_evaluation.py to object_detection_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/object_detection_evaluation_test.py to object_detection_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/ops.py to ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/ops_test.py to ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/patch_ops.py to patch_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/patch_ops_test.py to patch_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_evaluation.py to per_image_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_evaluation_test.py to per_image_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_vrd_evaluation.py to per_image_vrd_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_vrd_evaluation_test.py to per_image_vrd_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/shape_utils.py to shape_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/shape_utils_test.py to shape_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/spatial_transform_ops.py to spatial_transform_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/spatial_transform_ops_test.py to spatial_transform_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/static_shape.py to static_shape.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/static_shape_test.py to static_shape_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/target_assigner_utils.py to target_assigner_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/target_assigner_utils_test.py to target_assigner_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_case.py to test_case.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_case_test.py to test_case_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_utils.py to test_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_utils_test.py to test_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/tf_version.py to tf_version.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/variables_helper.py to variables_helper.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/variables_helper_tf1_test.py to variables_helper_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/visualization_utils.py to visualization_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/visualization_utils_test.py to visualization_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/vrd_evaluation.py to vrd_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/vrd_evaluation_test.py to vrd_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/packages/tf1/setup.py to setup.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/packages/tf2/setup.py to setup.cpython-36.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","object_detection.core.__pycache__.densepose_ops.cpython-36: module references __file__\n","object_detection.core.__pycache__.preprocessor.cpython-36: module MAY be using inspect.stack\n","object_detection.utils.__pycache__.autoaugment_utils.cpython-36: module MAY be using inspect.stack\n","creating dist\n","creating 'dist/object_detection-0.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing object_detection-0.1-py3.6.egg\n","creating /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n","Extracting object_detection-0.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n","Adding object-detection 0.1 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n","Processing dependencies for object-detection==0.1\n","Searching for Cython==0.29.21\n","Best match: Cython 0.29.21\n","Adding Cython 0.29.21 to easy-install.pth file\n","Installing cygdb script to /usr/local/bin\n","Installing cython script to /usr/local/bin\n","Installing cythonize script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for matplotlib==3.2.2\n","Best match: matplotlib 3.2.2\n","Adding matplotlib 3.2.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for Pillow==7.0.0\n","Best match: Pillow 7.0.0\n","Adding Pillow 7.0.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for python-dateutil==2.8.1\n","Best match: python-dateutil 2.8.1\n","Adding python-dateutil 2.8.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for pyparsing==2.4.7\n","Best match: pyparsing 2.4.7\n","Adding pyparsing 2.4.7 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for kiwisolver==1.3.1\n","Best match: kiwisolver 1.3.1\n","Adding kiwisolver 1.3.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for cycler==0.10.0\n","Best match: cycler 0.10.0\n","Adding cycler 0.10.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for numpy==1.18.5\n","Best match: numpy 1.18.5\n","Adding numpy 1.18.5 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.6 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for six==1.15.0\n","Best match: six 1.15.0\n","Adding six 1.15.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Finished processing dependencies for object-detection==0.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s8PrDV-NKl2R"},"source":["***HARD CODED MUST FIX: * The following hard codes for the class pistol to convert to the class number 1. Need to read in the label_map.pbtxt file instead and parse it for multiple classes and create a map so can look up the id for the passed row_label ---see code below**"]},{"cell_type":"code","metadata":{"id":"bALJxtLqPCHi","executionInfo":{"status":"ok","timestamp":1603397379817,"user_tz":420,"elapsed":268198,"user":{"displayName":"Subhi asati","photoUrl":"","userId":"12937930425121675107"}},"outputId":"98bd4c27-471c-45a6-9897-2ea9a42d4b94","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%cd /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research\n","\n","from object_detection.utils import dataset_util\n","\n","\n","#DATA_BASE_PATH = '/content/drive/My Drive/DetectionWeaponsExample_CodeLabBased/data/'\n","#images_dir = '/content/drive/My Drive/DetectionWeaponsExample_CodeLabBased/data/images/'\n","DATA_BASE_PATH = '/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/'\n","images_dir = '/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/images/'\n","# problem with the data_dir not evaluating the 'My Drive' into My Drive\n","#DATA_BASE_PATH = data_dir + '/'\n","#image_dir = data_dir +'/images/'\n","# DATA_BASE_PATH = \"/content/drive/Shared drives/RetrainTF2DataAndModels/DetectionWeaponsExample_CodeLabBased/data\"\n","# images_dir = \"/content/drive/Shared drives/RetrainTF2DataAndModels/DetectionWeaponsExample_CodeLabBased/data/images\"\n","# print(\"Data base path \" + DATA_BASE_PATH)\n","\n","print(\"Images path \" + images_dir)\n","\n","#do a list to see if the record file already exists\n","#this will falue when no 'My Drive' and using only My Drive\n","#%ls {DATA_BASE_PATH}\n","\n","#FIX- THIS IS HARDCODED method for converting the class label to its id instead!!!\n","def class_text_to_int(row_label):\n","    if row_label == 'Good':\n","        return 1\n","    elif row_label == 'Caution':\n","        return 2\n","    elif row_label == 'Bad':\n","        return 3\n","    else:\n","        None\n","\n","#some kind of parsing function that create a special DataSet for parsing each image in a loop\n","def split(df, group):\n","\t\tdata = namedtuple('data', ['filename', 'object'])\n","\t\tgb = df.groupby(group)\n","\t\treturn [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n","\n","#This is a function that reads in image from a file (using tf.io package) and its bounding box information and creates\n","# and instance of tf.train.Example that can be used to add to a TFRecord\n","def create_tf_example(group, path):\n","\t\twith tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n","\t\t\t\tencoded_jpg = fid.read()\n","    #open up io stream to file containing image\n","\t\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n","    #open up Image file pointer using the stream previously opened\n","\t\timage = Image.open(encoded_jpg_io)\n","    #retrieve size of image from the data in the Image file pointer (stored in the jpg file)\n","\t\twidth, height = image.size\n","    \n","    \n","\t\tfilename = group.filename.encode('utf8')\n","\t\timage_format = b'jpg'\n","    #setup array to represent all the bounding boxes for this image\n","    # bounding box i upper left point = (xmins[i],ymins[i])  lower right point =(xmaxs[i], ymaxs[i])\n","    # class label of ith' box stored in classes_text[i]\n","    # also as building out this array add to classes[] any unique new classes found\n","\t\txmins = []\n","\t\txmaxs = []\n","\t\tymins = []\n","\t\tymaxs = []\n","\t\tclasses_text = []\n","\t\tclasses = []\n","\n","    #cycle through the rows in the label csv file pased and add in the bounding box info into arrays\n","    #    and corresponding class label.\n","\t\tfor index, row in group.object.iterrows():\n","\t\t\t\txmins.append(row['xmin'] / width)\n","\t\t\t\txmaxs.append(row['xmax'] / width)\n","\t\t\t\tymins.append(row['ymin'] / height)\n","\t\t\t\tymaxs.append(row['ymax'] / height)\n","\t\t\t\tclasses_text.append(row['class'].encode('utf8'))\n","\t\t\t\tclasses.append(class_text_to_int(row['class']))\n","\n","    #build out a tf.train.Example using all the read in information for this image and its bounding boxes\n","    # this will be used later to create a TFRecord\n","    # see https://www.tensorflow.org/tutorials/load_data/tfrecord  for information about tf.train.Example and TFRecord format\n","    # as you can see includes for each image: \n","    #              height, width, filename, the actual image pixel values, image format, \n","    #              and bounding boxes (as arrays of xmin,ymin and xmax,ymax representing the lower-left and upper-right points) \n","\t\ttf_example = tf.train.Example(features=tf.train.Features(feature={\n","\t\t\t\t'image/height': dataset_util.int64_feature(height),\n","\t\t\t\t'image/width': dataset_util.int64_feature(width),\n","\t\t\t\t'image/filename': dataset_util.bytes_feature(filename),\n","\t\t\t\t'image/source_id': dataset_util.bytes_feature(filename),\n","\t\t\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","\t\t\t\t'image/format': dataset_util.bytes_feature(image_format),\n","\t\t\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","\t\t\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","\t\t\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","\t\t\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","\t\t\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","\t\t\t\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n","\t\t}))\n","\t\treturn tf_example\n","\n","#go through the train_labels.csv and afterwards test_lables.csv and create TFRecord files for each\n","#  pd is associated with loaded python Pandas module imported and used to read csv files\n","for csv in ['train_labels', 'test_labels']:\n","  #use TFrecordWriter to write records to a TFRecord file as specified in path\n","  #see https://www.tensorflow.org/api_docs/python/tf/io/TFRecordWriter\n","  label_file = DATA_BASE_PATH + csv + '.record'\n","  print(\".........going to save TFRecord to \" + label_file)\n"," # label_file = \"/\"\n","  \n","  writer = tf.io.TFRecordWriter(DATA_BASE_PATH + csv + '.record')\n","  #writer = tf.io.TFRecordWriter(dummy2)\n","  path = os.path.join(images_dir)\n","\n","  #read in all the rows in the csv file using pandas module into a pandas DataFrame datastructure\n","  #see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n","  #see https://pandas.pydata.org/pandas-docs/stable/reference/frame.html \n","  # need file to open = \"/gdrive/My Drive/iLab/Covid_ID/Retraining/DetectionWeaponsExample/data/\" + csv + \".csv\"\n","  print(DATA_BASE_PATH + csv + '.csv')\n","  examples = pd.read_csv(DATA_BASE_PATH + csv + '.csv')\n","  \n","\n","  #For each image group it with its bounding boxes\n","  grouped = split(examples, 'filename')\n","\n","  #for each image and its bounding boxes create an instance of tf.train.Example that is\n","  #  written out into a file that is the created TFRecord file\n","  # see https://www.tensorflow.org/tutorials/load_data/tfrecord \n","  # for information about tf.train.Example and TFRecord format\n","  for group in grouped:\n","      print(\" group in loop \")\n","      print(group)\n","      tf_example = create_tf_example(group, path)\n","      writer.write(tf_example.SerializeToString())\n","    \n","  writer.close()\n","  output_path = os.path.join(os.getcwd(), DATA_BASE_PATH + csv + '.record')\n","  print('Successfully created the TFRecords: {}'.format(DATA_BASE_PATH +csv + '.record'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research\n","Images path /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/images/\n",".........going to save TFRecord to /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/train_labels.record\n","/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/train_labels.csv\n"," group in loop \n","data(filename='Bad1.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","537  Bad1.jpg    300     168   Bad     1    10   300   168)\n"," group in loop \n","data(filename='Bad10.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","1050  Bad10.jpg    300     168   Bad     1     5   289   168)\n"," group in loop \n","data(filename='Bad100.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","797  Bad100.jpg    201     251   Bad    17     1   160   250)\n"," group in loop \n","data(filename='Bad101.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","791  Bad101.jpg    273     169   Bad     6     1   260   169)\n"," group in loop \n","data(filename='Bad102.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","934  Bad102.jpg    155     258   Bad     1    14   141   258)\n"," group in loop \n","data(filename='Bad103.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","921  Bad103.jpg    238     212   Bad     6     5   229   211)\n"," group in loop \n","data(filename='Bad104.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","711  Bad104.jpg    209     241   Bad     4     1   181   241)\n"," group in loop \n","data(filename='Bad106.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","775  Bad106.jpg    259     194   Bad     1     6   175   194\n","776  Bad106.jpg    259     194   Bad    77     7   259   194)\n"," group in loop \n","data(filename='Bad107.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","771  Bad107.jpg    191     263   Bad     8     5   183   263)\n"," group in loop \n","data(filename='Bad108.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","586  Bad108.jpg    238     212   Bad    32    32   214   189)\n"," group in loop \n","data(filename='Bad109.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","440  Bad109.jpg    231     219   Bad     3     3   231   219)\n"," group in loop \n","data(filename='Bad11.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","990  Bad11.jpg    264     191   Bad    36    30   223   191)\n"," group in loop \n","data(filename='Bad110.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","724  Bad110.jpg    275     183   Bad    65    74   168   183\n","725  Bad110.jpg    275     183   Bad   115    74   206   183)\n"," group in loop \n","data(filename='Bad112.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","774  Bad112.jpg    299     168   Bad    42    14   140   167)\n"," group in loop \n","data(filename='Bad114.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","790  Bad114.jpg    259     195   Bad    43    11   225   195)\n"," group in loop \n","data(filename='Bad115.JPG', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","795  Bad115.JPG    886     484   Bad     1    30   445   426\n","796  Bad115.JPG    886     484   Bad   265     1   886   338)\n"," group in loop \n","data(filename='Bad116.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","927  Bad116.jpg    174     199   Bad     2    71    47   199\n","928  Bad116.jpg    174     199   Bad    54    73   134   150\n","929  Bad116.jpg    174     199   Bad   106    72   174   151)\n"," group in loop \n","data(filename='Bad117.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","920  Bad117.jpg    266     189   Bad    28    17   266   116)\n"," group in loop \n","data(filename='Bad118.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","510  Bad118.jpg    300     168   Bad   118    20   254   168)\n"," group in loop \n","data(filename='Bad119.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","503  Bad119.jpg    259     194   Bad     1    16   162   117\n","504  Bad119.jpg    259     194   Bad   111    32   259   194)\n"," group in loop \n","data(filename='Bad12.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","1041  Bad12.jpg    149     185   Bad     1    26    56    84\n","1042  Bad12.jpg    149     185   Bad    25    39    82   102\n","1043  Bad12.jpg    149     185   Bad    55    47   145   138)\n"," group in loop \n","data(filename='Bad120.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","584  Bad120.jpg   2560    1439   Bad   495    96  1587  1380\n","585  Bad120.jpg   2560    1439   Bad  1122    56  2071  1400)\n"," group in loop \n","data(filename='Bad121.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","439  Bad121.jpg   1200     800   Bad   190   105   591   771)\n"," group in loop \n","data(filename='Bad122.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","683  Bad122.jpg   2122    1415   Bad   365   240   939  1415\n","684  Bad122.jpg   2122    1415   Bad   634   237  1317   634\n","685  Bad122.jpg   2122    1415   Bad   932   194  1808  1414)\n"," group in loop \n","data(filename='Bad127.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","408  Bad127.jpg    275     183   Bad    81    30   173   169\n","409  Bad127.jpg    275     183   Bad   130    31   224   169)\n"," group in loop \n","data(filename='Bad129.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","793  Bad129.jpg   1080    1349   Bad   113    74  1011  1329)\n"," group in loop \n","data(filename='Bad130.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","509  Bad130.jpg    750     500   Bad   129     1   750   495)\n"," group in loop \n","data(filename='Bad131.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","511  Bad131.jpg    302     167   Bad    99    38   181   134)\n"," group in loop \n","data(filename='Bad132.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","421  Bad132.jpg    189     183   Bad     1    50    80   161\n","422  Bad132.jpg    189     183   Bad    51    41   117   171\n","423  Bad132.jpg    189     183   Bad    76    42   186   172)\n"," group in loop \n","data(filename='Bad133.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","407  Bad133.jpg   1200     800   Bad   415    81   993   800)\n"," group in loop \n","data(filename='Bad135.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","592  Bad135.jpg    685     402   Bad    69    34   366   402\n","593  Bad135.jpg    685     402   Bad   240     5   668   397)\n"," group in loop \n","data(filename='Bad137.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","688  Bad137.jpg    353     450   Bad    59    19   233   372\n","689  Bad137.jpg    353     450   Bad   150    42   343   373)\n"," group in loop \n","data(filename='Bad139.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","708  Bad139.jpg    225     225   Bad    14    14   198   225)\n"," group in loop \n","data(filename='Bad140.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","314  Bad140.jpg    271     118   Bad    52     6   230   115)\n"," group in loop \n","data(filename='Bad141.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","301  Bad141.jpg    210     193   Bad     1     2   210   193)\n"," group in loop \n","data(filename='Bad142.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","178  Bad142.jpg    318     159   Bad     1     7   292   159)\n"," group in loop \n","data(filename='Bad144.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","103  Bad144.jpg    259     194   Bad    55     5   215   193)\n"," group in loop \n","data(filename='Bad145.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","94  Bad145.jpg    190     211   Bad     1     1   189   211)\n"," group in loop \n","data(filename='Bad146.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","30  Bad146.jpg    276     182   Bad    43     1   276   182)\n"," group in loop \n","data(filename='Bad147.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","32  Bad147.jpg    263     162   Bad     1     1   255   162)\n"," group in loop \n","data(filename='Bad148.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1105  Bad148.jpg    300     168   Bad    34    10   266   168)\n"," group in loop \n","data(filename='Bad149.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1104  Bad149.jpg    299     168   Bad    32     7   278   168)\n"," group in loop \n","data(filename='Bad15.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","988  Bad15.jpg    275     183   Bad     8     6   263   183)\n"," group in loop \n","data(filename='Bad150.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","92  Bad150.jpg    247     193   Bad    12     1   241   193)\n"," group in loop \n","data(filename='Bad151.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","104  Bad151.jpg    275     183   Bad     1     1   227   183)\n"," group in loop \n","data(filename='Bad152.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","28  Bad152.jpg    233     176   Bad     6     1   230   176)\n"," group in loop \n","data(filename='Bad153.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","29  Bad153.jpg    259     194   Bad    14     1   244   194)\n"," group in loop \n","data(filename='Bad154.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","315  Bad154.jpg    265     147   Bad    45     3   245   123)\n"," group in loop \n","data(filename='Bad155.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","316  Bad155.jpg    225     225   Bad     2    56   148   138\n","317  Bad155.jpg    225     225   Bad    70    33   225   223)\n"," group in loop \n","data(filename='Bad157.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","201  Bad157.jpg    272     185   Bad     8    15   260   184)\n"," group in loop \n","data(filename='Bad158.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","850  Bad158.jpg    300     168   Bad    46     1   245   168)\n"," group in loop \n","data(filename='Bad159.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","849  Bad159.jpg    297     169   Bad    97     2   290   168)\n"," group in loop \n","data(filename='Bad160.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1102  Bad160.jpg    264     191   Bad    38     2   228   191)\n"," group in loop \n","data(filename='Bad162.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1154  Bad162.jpg    225     225   Bad     1     1   225   225)\n"," group in loop \n","data(filename='Bad163.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1153  Bad163.jpg    283     178   Bad     1     1   283   178)\n"," group in loop \n","data(filename='Bad164.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","862  Bad164.jpg    259     194   Bad    40    17   248   194)\n"," group in loop \n","data(filename='Bad165.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","845  Bad165.jpg    299     168   Bad    19     4   137   167\n","846  Bad165.jpg    299     168   Bad    83     5   210   168\n","847  Bad165.jpg    299     168   Bad   138    10   285   168)\n"," group in loop \n","data(filename='Bad167.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1008  Bad167.jpg    279     181   Bad     6     7   275   181)\n"," group in loop \n","data(filename='Bad169.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","312  Bad169.jpg    802     597   Bad     1    47   372   597\n","313  Bad169.jpg    802     597   Bad   174    38   612   224)\n"," group in loop \n","data(filename='Bad17.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","1064  Bad17.jpg    273     185   Bad    67    16   235   185\n","1065  Bad17.jpg    273     185   Bad    44    33   143   185)\n"," group in loop \n","data(filename='Bad171.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","861  Bad171.jpg    259     194   Bad     2     2   257   192)\n"," group in loop \n","data(filename='Bad172.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1000  Bad172.jpg    259     194   Bad    42    32   224   194)\n"," group in loop \n","data(filename='Bad173.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1007  Bad173.jpg    273     185   Bad     9     2   249   185)\n"," group in loop \n","data(filename='Bad175.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1103  Bad175.jpg    300     168   Bad     1     1   299   168)\n"," group in loop \n","data(filename='Bad176.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1152  Bad176.jpg    681     383   Bad   161     6   492   383)\n"," group in loop \n","data(filename='Bad177.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1141  Bad177.jpg    291     173   Bad     1     1   122   173\n","1142  Bad177.jpg    291     173   Bad    81    13   184    81\n","1143  Bad177.jpg    291     173   Bad   123    24   239   173\n","1144  Bad177.jpg    291     173   Bad   176     2   290   173)\n"," group in loop \n","data(filename='Bad179.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","93  Bad179.jpg    259     194   Bad     1     1   259   194)\n"," group in loop \n","data(filename='Bad18.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","234  Bad18.jpg    262     192   Bad    38    24   159   192\n","235  Bad18.jpg    262     192   Bad   116    24   202   192)\n"," group in loop \n","data(filename='Bad180.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","202  Bad180.jpg    275     183   Bad   110    13   274   182)\n"," group in loop \n","data(filename='Bad181.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","179  Bad181.jpg    296     170   Bad     1     3   296   168)\n"," group in loop \n","data(filename='Bad182.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","296  Bad182.jpg    256     197   Bad     1     1   256   197)\n"," group in loop \n","data(filename='Bad183.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","318  Bad183.jpg    264     191   Bad     1     1   264   189)\n"," group in loop \n","data(filename='Bad184.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","31  Bad184.jpg    335     150   Bad    55     9   300   137)\n"," group in loop \n","data(filename='Bad185.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","33  Bad185.jpg    275     183   Bad     1    16   175   183\n","34  Bad185.jpg    275     183   Bad    94    19   275   183)\n"," group in loop \n","data(filename='Bad186.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","99  Bad186.jpg    259     194   Bad     1    18   259   194)\n"," group in loop \n","data(filename='Bad187.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","100  Bad187.jpg    275     183   Bad    41     3   260   182)\n"," group in loop \n","data(filename='Bad19.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","51  Bad19.jpg    275     183   Bad    65    11   194   183\n","52  Bad19.jpg    275     183   Bad    28    19   124   107)\n"," group in loop \n","data(filename='Bad191.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","27  Bad191.jpg    288     175   Bad    19    12   270   175)\n"," group in loop \n","data(filename='Bad192.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","91  Bad192.jpg    275     183   Bad     1     6   218   183)\n"," group in loop \n","data(filename='Bad193.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","101  Bad193.jpg    264     191   Bad     4     1   226   191)\n"," group in loop \n","data(filename='Bad195.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","189  Bad195.jpg    299     168   Bad     1     1   200   168\n","190  Bad195.jpg    299     168   Bad   100     1   299   168)\n"," group in loop \n","data(filename='Bad196.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","293  Bad196.jpg    276     183   Bad     4     1   270   182)\n"," group in loop \n","data(filename='Bad197.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","319  Bad197.jpg    275     183   Bad    30     2   201   183)\n"," group in loop \n","data(filename='Bad198.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1029  Bad198.jpg    297     170   Bad    29     1   297   170)\n"," group in loop \n","data(filename='Bad2.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","455  Bad2.jpg    800     533   Bad   131    27   704   533)\n"," group in loop \n","data(filename='Bad20.jpg', object=    filename  width  height class  xmin  ymin  xmax  ymax\n","0  Bad20.jpg    225     225   Bad    68     9   163   218)\n"," group in loop \n","data(filename='Bad200.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1163  Bad200.jpg    284     166   Bad    18     7   268   166)\n"," group in loop \n","data(filename='Bad202.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1081  Bad202.jpg    268     188   Bad     1    13   125   188\n","1082  Bad202.jpg    268     188   Bad    77     7   207   188\n","1083  Bad202.jpg    268     188   Bad   126     7   268   188)\n"," group in loop \n","data(filename='Bad203.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1107  Bad203.jpg    260     194   Bad    40     2   260   194)\n"," group in loop \n","data(filename='Bad204.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","991  Bad204.jpg    297     156   Bad    31     1   255   156)\n"," group in loop \n","data(filename='Bad206.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","880  Bad206.jpg    232     218   Bad     1    24   232   218)\n"," group in loop \n","data(filename='Bad207.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1061  Bad207.jpg    239     193   Bad     2     7   235   182)\n"," group in loop \n","data(filename='Bad208.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","166  Bad208.jpg    275     183   Bad    54     7   227   183)\n"," group in loop \n","data(filename='Bad209.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","225  Bad209.jpg    259     194   Bad     1     4   246   191)\n"," group in loop \n","data(filename='Bad21.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","145  Bad21.jpg    275     183   Bad    17    27   118   183\n","146  Bad21.jpg    275     183   Bad   117    31   252   182)\n"," group in loop \n","data(filename='Bad210.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","992  Bad210.jpg    301     167   Bad    35     5   283   167)\n"," group in loop \n","data(filename='Bad213.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1054  Bad213.jpg    193     183   Bad    30     3   189   158)\n"," group in loop \n","data(filename='Bad214.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1162  Bad214.jpg    259     194   Bad    18     1   256   193)\n"," group in loop \n","data(filename='Bad215.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1123  Bad215.jpg    275     183   Bad    27     5   236   183)\n"," group in loop \n","data(filename='Bad216.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1080  Bad216.jpg    223     121   Bad    23     1   214   120)\n"," group in loop \n","data(filename='Bad217.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1108  Bad217.jpg    300     168   Bad     1    24   143   168\n","1109  Bad217.jpg    300     168   Bad    90    19   202   168\n","1110  Bad217.jpg    300     168   Bad   144    18   300   168)\n"," group in loop \n","data(filename='Bad218.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","50  Bad218.jpg    259     194   Bad    24     1   243   193)\n"," group in loop \n","data(filename='Bad22.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","267  Bad22.jpg    268     188   Bad    11    10   171   186\n","268  Bad22.jpg    268     188   Bad    97    10   268   187)\n"," group in loop \n","data(filename='Bad220.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","160  Bad220.jpg    300     168   Bad     1     1   215   168\n","161  Bad220.jpg    300     168   Bad    96     1   300   168)\n"," group in loop \n","data(filename='Bad221.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","219  Bad221.jpg    300     168   Bad     1     7   199   168\n","220  Bad221.jpg    300     168   Bad   109    13   300   168)\n"," group in loop \n","data(filename='Bad222.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","330  Bad222.jpg    275     183   Bad     1     6   134   182\n","331  Bad222.jpg    275     183   Bad   135     3   275   183)\n"," group in loop \n","data(filename='Bad224.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","45  Bad224.jpg    275     183   Bad    21    15   248   182)\n"," group in loop \n","data(filename='Bad225.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","13  Bad225.jpg    259     194   Bad     1     1   253   194)\n"," group in loop \n","data(filename='Bad226.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","87  Bad226.jpg    237     165   Bad    90    18   236   165)\n"," group in loop \n","data(filename='Bad227.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","121  Bad227.jpg    275     183   Bad    73     8   205   183)\n"," group in loop \n","data(filename='Bad229.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1130  Bad229.jpg    259     194   Bad    17     1   259   194)\n"," group in loop \n","data(filename='Bad23.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","144  Bad23.jpg    225     225   Bad     1     8   205   225)\n"," group in loop \n","data(filename='Bad230.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","42  Bad230.jpg    300     168   Bad     1     1   300   168)\n"," group in loop \n","data(filename='Bad231.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","16  Bad231.jpg    259     194   Bad     1    12   259   192)\n"," group in loop \n","data(filename='Bad232.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","74  Bad232.jpg    259     194   Bad     1     1   244   193)\n"," group in loop \n","data(filename='Bad233.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","115  Bad233.jpg    300     168   Bad    50     4   277   168)\n"," group in loop \n","data(filename='Bad234.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","162  Bad234.jpg    260     157   Bad    33     3   260   157)\n"," group in loop \n","data(filename='Bad235.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","224  Bad235.jpg    188     190   Bad     6     4   187   190)\n"," group in loop \n","data(filename='Bad236.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","142  Bad236.jpg    301     168   Bad    53     1   236   168)\n"," group in loop \n","data(filename='Bad237.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","273  Bad237.jpg    290     174   Bad    27    22   266   173)\n"," group in loop \n","data(filename='Bad24.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","237  Bad24.jpg    275     183   Bad    57    15   167   182)\n"," group in loop \n","data(filename='Bad240.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","661  Bad240.jpg    259     194   Bad    12     8   245   193)\n"," group in loop \n","data(filename='Bad241.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","538  Bad241.jpg    284     177   Bad    51     4   267   177)\n"," group in loop \n","data(filename='Bad243.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","577  Bad243.jpg    264     191   Bad     7    11   264   191)\n"," group in loop \n","data(filename='Bad244.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","438  Bad244.jpg    301     167   Bad    55     2   258   166)\n"," group in loop \n","data(filename='Bad245.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","384  Bad245.jpg    300     168   Bad     1     9   300   168)\n"," group in loop \n","data(filename='Bad246.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","487  Bad246.jpg    284     177   Bad     1    20   284   177)\n"," group in loop \n","data(filename='Bad250.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","242  Bad250.jpg    300     168   Bad    25     2   184   168\n","243  Bad250.jpg    300     168   Bad   112    21   270   168)\n"," group in loop \n","data(filename='Bad253.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","353  Bad253.jpg    297     170   Bad     1     1   297   170)\n"," group in loop \n","data(filename='Bad254.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","660  Bad254.jpg    225     225   Bad     1     6   225   225)\n"," group in loop \n","data(filename='Bad255.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","535  Bad255.jpg    272     145   Bad     1    24   150   144\n","536  Bad255.jpg    272     145   Bad   102     9   262   145)\n"," group in loop \n","data(filename='Bad256.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","454  Bad256.jpg    299     168   Bad    21     1   278   168)\n"," group in loop \n","data(filename='Bad257.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","573  Bad257.jpg    265     190   Bad     1     1   265   189)\n"," group in loop \n","data(filename='Bad258.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","750  Bad258.jpg    225     225   Bad    53     1   216   224)\n"," group in loop \n","data(filename='Bad259.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","615  Bad259.jpg    193     188   Bad    76    56   185   179)\n"," group in loop \n","data(filename='Bad26.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","132  Bad26.jpg    300     168   Bad    60    15   149    65\n","133  Bad26.jpg    300     168   Bad   120     8   192    76\n","134  Bad26.jpg    300     168   Bad   149     9   211    77\n","135  Bad26.jpg    300     168   Bad   189    23   241    61)\n"," group in loop \n","data(filename='Bad260.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","948  Bad260.jpg    259     194   Bad     6    35   135   194\n","949  Bad260.jpg    259     194   Bad    76    36   188   194\n","950  Bad260.jpg    259     194   Bad   134    32   257   194)\n"," group in loop \n","data(filename='Bad261.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","898  Bad261.jpg    300     168   Bad    66     5   209    96)\n"," group in loop \n","data(filename='Bad262.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","967  Bad262.jpg    267     189   Bad    48    11   204   115)\n"," group in loop \n","data(filename='Bad263.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","810  Bad263.jpg    275     183   Bad    25     7   147   163)\n"," group in loop \n","data(filename='Bad264.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","751  Bad264.jpg    275     183   Bad    82    30   151   162\n","752  Bad264.jpg    275     183   Bad   117    30   217   164)\n"," group in loop \n","data(filename='Bad265.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","605  Bad265.jpg    259     194   Bad   117    28   191   188)\n"," group in loop \n","data(filename='Bad268.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","673  Bad268.jpg    311     162   Bad   100     9   194   159)\n"," group in loop \n","data(filename='Bad269.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","532  Bad269.jpg    275     183   Bad    25    46   120   118\n","533  Bad269.jpg    275     183   Bad    81    35   175   118\n","534  Bad269.jpg    275     183   Bad   120    31   224   118)\n"," group in loop \n","data(filename='Bad27.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","72  Bad27.jpg    261     193   Bad    59     1   234   190)\n"," group in loop \n","data(filename='Bad270.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","754  Bad270.jpg    225     225   Bad     1    62    50   199\n","755  Bad270.jpg    225     225   Bad    22    63    83   194\n","756  Bad270.jpg    225     225   Bad    50    57   127   193\n","757  Bad270.jpg    225     225   Bad   127    40   225   191)\n"," group in loop \n","data(filename='Bad271.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","600  Bad271.jpg    299     168   Bad    15    46   111   167\n","601  Bad271.jpg    299     168   Bad    64    53   169   168\n","602  Bad271.jpg    299     168   Bad   133    53   239   168\n","603  Bad271.jpg    299     168   Bad   189    42   285   168)\n"," group in loop \n","data(filename='Bad272.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","715  Bad272.jpg    278     182   Bad     1    20   118   182\n","716  Bad272.jpg    278     182   Bad    63    18   180   182\n","717  Bad272.jpg    278     182   Bad   118    19   225   182\n","718  Bad272.jpg    278     182   Bad   181    28   278   182)\n"," group in loop \n","data(filename='Bad273.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","836  Bad273.jpg    275     183   Bad    33    31   130   183\n","837  Bad273.jpg    275     183   Bad    92    23   185   183\n","838  Bad273.jpg    275     183   Bad   138    23   253   183)\n"," group in loop \n","data(filename='Bad274.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","945  Bad274.jpg    275     183   Bad    68    23   152   180\n","946  Bad274.jpg    275     183   Bad   113    24   189   179\n","947  Bad274.jpg    275     183   Bad   152    19   243   176)\n"," group in loop \n","data(filename='Bad275.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","894  Bad275.jpg    300     168   Bad     1    23   162   117\n","895  Bad275.jpg    300     168   Bad    82    32   229   120\n","896  Bad275.jpg    300     168   Bad   180    26   290   121)\n"," group in loop \n","data(filename='Bad276.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","977  Bad276.jpg    275     183   Bad    56    14   187   183\n","978  Bad276.jpg    275     183   Bad   117    25   255   183)\n"," group in loop \n","data(filename='Bad277.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","813  Bad277.jpg    275     183   Bad    70    49   129   160\n","814  Bad277.jpg    275     183   Bad   102    42   168   157\n","815  Bad277.jpg    275     183   Bad   128    41   206   159)\n"," group in loop \n","data(filename='Bad278.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","434  Bad278.jpg    300     168   Bad    15    14   261   147)\n"," group in loop \n","data(filename='Bad28.JPG', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","1119  Bad28.JPG    282     362   Bad    38   124   257   340)\n"," group in loop \n","data(filename='Bad280.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","568  Bad280.jpg    259     194   Bad    18    16   160   189\n","569  Bad280.jpg    259     194   Bad   105    27   248   190)\n"," group in loop \n","data(filename='Bad283.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","655  Bad283.jpg    275     183   Bad    54    40   114    76\n","656  Bad283.jpg    275     183   Bad    85    40   137    83\n","657  Bad283.jpg    275     183   Bad   111    40   155    77\n","658  Bad283.jpg    275     183   Bad   133    40   192    71\n","659  Bad283.jpg    275     183   Bad   156    39   228    75)\n"," group in loop \n","data(filename='Bad285.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","479  Bad285.jpg    246     205   Bad     1    17   160   205\n","480  Bad285.jpg    246     205   Bad    74    14   246   205)\n"," group in loop \n","data(filename='Bad29.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","980  Bad29.JPG    331     422   Bad   161   135   259   381)\n"," group in loop \n","data(filename='Bad290.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","359  Bad290.jpg    275     183   Bad    22     3   251   183)\n"," group in loop \n","data(filename='Bad291.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","485  Bad291.jpg    269     187   Bad    32     4   165   185\n","486  Bad291.jpg    269     187   Bad    91     4   236   187)\n"," group in loop \n","data(filename='Bad292.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","387  Bad292.jpg    282     161   Bad     2    34   254   161)\n"," group in loop \n","data(filename='Bad293.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","246  Bad293.jpg    275     183   Bad     6    13    96   179\n","247  Bad293.jpg    275     183   Bad    52     6   139   179\n","248  Bad293.jpg    275     183   Bad    95     6   189   182\n","249  Bad293.jpg    275     183   Bad   142    10   223   183\n","250  Bad293.jpg    275     183   Bad   187    10   269   180)\n"," group in loop \n","data(filename='Bad294.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","575  Bad294.jpg    275     183   Bad    36    32   167   182\n","576  Bad294.jpg    275     183   Bad   107    32   248   183)\n"," group in loop \n","data(filename='Bad296.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","544  Bad296.jpg    256     116   Bad    52     9   155    76\n","545  Bad296.jpg    256     116   Bad   108    10   229    77)\n"," group in loop \n","data(filename='Bad298.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","835  Bad298.jpg    275     183   Bad     2    17   190   183)\n"," group in loop \n","data(filename='Bad299.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","737  Bad299.jpg    381     132   Bad    21     7   259   131\n","738  Bad299.jpg    381     132   Bad   143     8   363   132)\n"," group in loop \n","data(filename='Bad30.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","232  Bad30.JPG    282     354   Bad    73    87   206   329)\n"," group in loop \n","data(filename='Bad300.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","937  Bad300.jpg    275     183   Bad     1     1   253   183)\n"," group in loop \n","data(filename='Bad301.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","907  Bad301.jpg    194     259   Bad    37    53   132   259)\n"," group in loop \n","data(filename='Bad303.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","805  Bad303.jpg    289     174   Bad    15    25   107    65\n","806  Bad303.jpg    289     174   Bad    74    25   129    71\n","807  Bad303.jpg    289     174   Bad   106    18   163    67\n","808  Bad303.jpg    289     174   Bad   130    17   183    70\n","809  Bad303.jpg    289     174   Bad   163    20   227    75)\n"," group in loop \n","data(filename='Bad305.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","612  Bad305.jpg    219     230   Bad    20     9   140   225\n","613  Bad305.jpg    219     230   Bad    84    10   207   224)\n"," group in loop \n","data(filename='Bad306.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","730  Bad306.jpg    259     194   Bad    26    17   167   193\n","731  Bad306.jpg    259     194   Bad    91    16   234   194)\n"," group in loop \n","data(filename='Bad307.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","839  Bad307.jpg    301     168   Bad    51    23   133   155\n","840  Bad307.jpg    301     168   Bad    90    23   179   154\n","841  Bad307.jpg    301     168   Bad   142    23   233   152\n","842  Bad307.jpg    301     168   Bad   186    23   275   150)\n"," group in loop \n","data(filename='Bad308.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","681  Bad308.jpg    300     168   Bad     1     8   294   120)\n"," group in loop \n","data(filename='Bad31.JPG', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","53  Bad31.JPG    272     338   Bad    78   115   229   316)\n"," group in loop \n","data(filename='Bad310.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","777  Bad310.jpg    255     168   Bad     5    11   255   168)\n"," group in loop \n","data(filename='Bad311.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","598  Bad311.jpg    183     223   Bad    29    18   183   217)\n"," group in loop \n","data(filename='Bad312.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","720  Bad312.jpg    246     183   Bad    28    11   124   183\n","721  Bad312.jpg    246     183   Bad    81     8   162   183\n","722  Bad312.jpg    246     183   Bad   123     8   233   183)\n"," group in loop \n","data(filename='Bad313.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","707  Bad313.jpg    275     183   Bad    97    33   188   105)\n"," group in loop \n","data(filename='Bad314.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","925  Bad314.jpg    275     183   Bad    74    12   188   108)\n"," group in loop \n","data(filename='Bad315.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","919  Bad315.jpg    263     192   Bad    96    20   187   160)\n"," group in loop \n","data(filename='Bad316.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","971  Bad316.jpg    275     183   Bad     2     5   260   183)\n"," group in loop \n","data(filename='Bad318.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","244  Bad318.jpg    300     168   Bad    31    11   283   138)\n"," group in loop \n","data(filename='Bad319.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","399  Bad319.jpg    274     184   Bad    24     1   252   182)\n"," group in loop \n","data(filename='Bad32.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","129  Bad32.JPG    612     340   Bad   266   156   342   294)\n"," group in loop \n","data(filename='Bad320.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","680  Bad320.jpg    259     194   Bad     5     3   259   194)\n"," group in loop \n","data(filename='Bad321.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","529  Bad321.jpg    276     183   Bad    70    21   276   183)\n"," group in loop \n","data(filename='Bad324.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","429  Bad324.jpg    300     168   Bad    26     3   192   168\n","430  Bad324.jpg    300     168   Bad   116     2   275   167)\n"," group in loop \n","data(filename='Bad327.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","505  Bad327.jpg    281     179   Bad    95     5   194   167)\n"," group in loop \n","data(filename='Bad328.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","922  Bad328.jpg    225     225   Bad    43    13   177   203)\n"," group in loop \n","data(filename='Bad329.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","913  Bad329.jpg    225     182   Bad     6    37   204   160)\n"," group in loop \n","data(filename='Bad33.JPG', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","69  Bad33.JPG    273     352   Bad    24    88   187   299)\n"," group in loop \n","data(filename='Bad330.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","431  Bad330.jpg    284     177   Bad     1     4   284   177)\n"," group in loop \n","data(filename='Bad331.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","396  Bad331.jpg    299     168   Bad    39    12   272   158)\n"," group in loop \n","data(filename='Bad332.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","490  Bad332.jpg    281     179   Bad    83    17   191   155)\n"," group in loop \n","data(filename='Bad333.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","513  Bad333.jpg    271     186   Bad    42     3   223   186)\n"," group in loop \n","data(filename='Bad334.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","665  Bad334.jpg    248     204   Bad   111    49   187   107\n","666  Bad334.jpg    248     204   Bad   169    45   228   102)\n"," group in loop \n","data(filename='Bad335.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","523  Bad335.jpg    259     194   Bad    22    18   156   164\n","524  Bad335.jpg    259     194   Bad   101    36   244   165)\n"," group in loop \n","data(filename='Bad336.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","443  Bad336.jpg    194     259   Bad    43    45   143   234)\n"," group in loop \n","data(filename='Bad337.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","570  Bad337.jpg    201     251   Bad    36    12   154   251)\n"," group in loop \n","data(filename='Bad338.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","753  Bad338.jpg    194     259   Bad    40    78   141   226)\n"," group in loop \n","data(filename='Bad339.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","606  Bad339.jpg    300     168   Bad    22    16   159   168\n","607  Bad339.jpg    300     168   Bad   107    21   237    78\n","608  Bad339.jpg    300     168   Bad   200    27   293   168)\n"," group in loop \n","data(filename='Bad34.JPG', object=    filename  width  height class  xmin  ymin  xmax  ymax\n","1  Bad34.JPG    627     385   Bad   257    21   478   385)\n"," group in loop \n","data(filename='Bad340.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","180  Bad340.jpg    275     183   Bad    44    70   155   183)\n"," group in loop \n","data(filename='Bad341.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","194  Bad341.jpg    260     194   Bad    98    55   183   183)\n"," group in loop \n","data(filename='Bad342.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","329  Bad342.jpg    259     194   Bad    70    34   183   185)\n"," group in loop \n","data(filename='Bad343.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","294  Bad343.jpg    259     194   Bad    82    54   152   103\n","295  Bad343.jpg    259     194   Bad   133    59   183   107)\n"," group in loop \n","data(filename='Bad346.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","80  Bad346.jpg    275     183   Bad    52    40   166   146\n","81  Bad346.jpg    275     183   Bad   106    40   231   151)\n"," group in loop \n","data(filename='Bad347.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","117  Bad347.jpg    275     183   Bad    48    20   173   153)\n"," group in loop \n","data(filename='Bad349.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1139  Bad349.jpg    284     177   Bad    57    61   225   177)\n"," group in loop \n","data(filename='Bad35.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","147  Bad35.JPG    291     324   Bad    73   100   251   306)\n"," group in loop \n","data(filename='Bad350.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","48  Bad350.jpg    275     183   Bad   129    95   230   148)\n"," group in loop \n","data(filename='Bad351.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","10  Bad351.jpg    280     180   Bad    86    36   166   171\n","11  Bad351.jpg    280     180   Bad   131    29   215   169)\n"," group in loop \n","data(filename='Bad353.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","107  Bad353.jpg    230     219   Bad    14    53   139   219\n","108  Bad353.jpg    230     219   Bad    83    53   211   219)\n"," group in loop \n","data(filename='Bad354.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","172  Bad354.jpg    214     236   Bad     8     1   212   236)\n"," group in loop \n","data(filename='Bad355.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","192  Bad355.jpg    325     155   Bad     6    22   190   155\n","193  Bad355.jpg    325     155   Bad   137    13   286   155)\n"," group in loop \n","data(filename='Bad356.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","338  Bad356.jpg    225     225   Bad    19    50    90   113\n","339  Bad356.jpg    225     225   Bad    64    42   146    93\n","340  Bad356.jpg    225     225   Bad    98    43   191   219)\n"," group in loop \n","data(filename='Bad358.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","997  Bad358.jpg    353     143   Bad   138     8   274   141)\n"," group in loop \n","data(filename='Bad359.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1017  Bad359.jpg    258     137   Bad    73    23   223   126)\n"," group in loop \n","data(filename='Bad36.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","270  Bad36.JPG    288     343   Bad    38   113   247   299)\n"," group in loop \n","data(filename='Bad37.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","143  Bad37.JPG    641     338   Bad   232    62   347   246)\n"," group in loop \n","data(filename='Bad38.JPG', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","1052  Bad38.JPG    293     351   Bad    48    52   245   341)\n"," group in loop \n","data(filename='Bad39.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","989  Bad39.JPG    552     281   Bad   256    60   352   217)\n"," group in loop \n","data(filename='Bad4.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","435  Bad4.jpg    206     245   Bad    28    11   116    86\n","436  Bad4.jpg    206     245   Bad    71    11   182   245)\n"," group in loop \n","data(filename='Bad40.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","559  Bad40.JPG    443     314   Bad   229    59   336   253)\n"," group in loop \n","data(filename='Bad42.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","562  Bad42.JPG    271     324   Bad    36    49   241   307)\n"," group in loop \n","data(filename='Bad43.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","457  Bad43.JPG    428     273   Bad   174    42   258   198)\n"," group in loop \n","data(filename='Bad44.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","376  Bad44.JPG    283     335   Bad    61   127   200   239)\n"," group in loop \n","data(filename='Bad45.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","262  Bad45.JPG    290     357   Bad    73    43   179   258)\n"," group in loop \n","data(filename='Bad47.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","483  Bad47.JPG    277     354   Bad    33    63   227   317)\n"," group in loop \n","data(filename='Bad48.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","892  Bad48.JPG    450     273   Bad   184    68   270   230)\n"," group in loop \n","data(filename='Bad49.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","953  Bad49.JPG    277     333   Bad    96    87   238   247)\n"," group in loop \n","data(filename='Bad5.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","385  Bad5.jpg    200     252   Bad    20    12   110   251\n","386  Bad5.jpg    200     252   Bad    74    12   199   232)\n"," group in loop \n","data(filename='Bad51.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","259  Bad51.jpg    259     194   Bad    17     7   216   194)\n"," group in loop \n","data(filename='Bad52.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","378  Bad52.jpg    259     194   Bad    52     3   226   193)\n"," group in loop \n","data(filename='Bad55.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","650  Bad55.jpg    259     194   Bad    78     1   182   193)\n"," group in loop \n","data(filename='Bad56.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","560  Bad56.jpg    183     275   Bad    46    38   147   238)\n"," group in loop \n","data(filename='Bad57.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","470  Bad57.jpg    195     259   Bad    27    49   122   240\n","471  Bad57.jpg    195     259   Bad    78    50   170   239)\n"," group in loop \n","data(filename='Bad58.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","627  Bad58.jpg    300     168   Bad    66    13   269   167)\n"," group in loop \n","data(filename='Bad6.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","475  Bad6.jpg    275     183   Bad    37     6   223   181)\n"," group in loop \n","data(filename='Bad60.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","872  Bad60.jpg    183     276   Bad    29    50   155   276)\n"," group in loop \n","data(filename='Bad61.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","962  Bad61.jpg    183     275   Bad     6    10   176   275)\n"," group in loop \n","data(filename='Bad62.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","823  Bad62.jpg    183     276   Bad     4    30   113   276\n","824  Bad62.jpg    183     276   Bad    69    13   181   276)\n"," group in loop \n","data(filename='Bad63.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","964  Bad63.jpg    264     191   Bad    29     1   222   191)\n"," group in loop \n","data(filename='Bad65.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","760  Bad65.jpg    275     183   Bad     2    12   241   183)\n"," group in loop \n","data(filename='Bad66.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","829  Bad66.jpg    300     168   Bad     1     1   182   168\n","830  Bad66.jpg    300     168   Bad   113     1   300   168)\n"," group in loop \n","data(filename='Bad67.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","742  Bad67.jpg    229     220   Bad     1    14   215   220)\n"," group in loop \n","data(filename='Bad68.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","541  Bad68.jpg    208     242   Bad    28    15   191   242)\n"," group in loop \n","data(filename='Bad69.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","653  Bad69.jpg    255     198   Bad     1    50   155   116\n","654  Bad69.jpg    255     198   Bad   120    48   202   102)\n"," group in loop \n","data(filename='Bad7.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","356  Bad7.jpg    299     168   Bad    16    36   116   168\n","357  Bad7.jpg    299     168   Bad    57    18   206   168\n","358  Bad7.jpg    299     168   Bad   117    18   270   168)\n"," group in loop \n","data(filename='Bad70.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","636  Bad70.jpg    275     183   Bad    11    27   180   183\n","637  Bad70.jpg    275     183   Bad   109    16   274   182)\n"," group in loop \n","data(filename='Bad71.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","763  Bad71.jpg    300     168   Bad    85     1   263   125)\n"," group in loop \n","data(filename='Bad73.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","743  Bad73.jpg    259     194   Bad    11     5   215   194)\n"," group in loop \n","data(filename='Bad74.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","890  Bad74.jpg    275     183   Bad    81    24   194   183)\n"," group in loop \n","data(filename='Bad76.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","822  Bad76.jpg    259     194   Bad    39     1   215   194)\n"," group in loop \n","data(filename='Bad77.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","963  Bad77.jpg    225     225   Bad     1     2   225   225)\n"," group in loop \n","data(filename='Bad78.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","371  Bad78.jpg    275     183   Bad    25    29   179   183\n","372  Bad78.jpg    275     183   Bad   113    21   251   183)\n"," group in loop \n","data(filename='Bad79.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","252  Bad79.jpg    275     183   Bad     1    25    63   167\n","253  Bad79.jpg    275     183   Bad    34    25   100   168\n","254  Bad79.jpg    275     183   Bad    67    31   137   177\n","255  Bad79.jpg    275     183   Bad   103    24   171   176\n","256  Bad79.jpg    275     183   Bad   135    24   207   179\n","257  Bad79.jpg    275     183   Bad   170    18   248   182\n","258  Bad79.jpg    275     183   Bad   209    19   275   183)\n"," group in loop \n","data(filename='Bad8.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","943  Bad8.jpg    299     168   Bad    45    16   299   168)\n"," group in loop \n","data(filename='Bad80.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","469  Bad80.jpg    245     205   Bad     7     4   240   205)\n"," group in loop \n","data(filename='Bad81.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","554  Bad81.jpg    181     249   Bad    13    19   159   247)\n"," group in loop \n","data(filename='Bad82.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","642  Bad82.jpg    183     275   Bad    11    25   111   239\n","643  Bad82.jpg    183     275   Bad    73    38   162   255)\n"," group in loop \n","data(filename='Bad83.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","539  Bad83.jpg    259     194   Bad     1     1   259   194)\n"," group in loop \n","data(filename='Bad85.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","361  Bad85.jpg    276     183   Bad    50    30   122   177\n","362  Bad85.jpg    276     183   Bad    89    31   153   172\n","363  Bad85.jpg    276     183   Bad   123    32   187   171\n","364  Bad85.jpg    276     183   Bad   153    31   224   172)\n"," group in loop \n","data(filename='Bad86.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","263  Bad86.jpg    194     259   Bad     1    36   110   259\n","264  Bad86.jpg    194     259   Bad    59    16   194   259)\n"," group in loop \n","data(filename='Bad88.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","956  Bad88.jpg    259     194   Bad    15     1   245   193)\n"," group in loop \n","data(filename='Bad90.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","476  Bad90.jpg    279     181   Bad     1    19   129   181\n","477  Bad90.jpg    279     181   Bad    77     6   199   181\n","478  Bad90.jpg    279     181   Bad   136     5   279   181)\n"," group in loop \n","data(filename='Bad93.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","388  Bad93.jpg    177     189   Bad     1     1   177   188)\n"," group in loop \n","data(filename='Bad94.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","456  Bad94.jpg    211     186   Bad     1    11   202   186)\n"," group in loop \n","data(filename='Bad95.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","551  Bad95.jpg    297     170   Bad    12     3   261   169)\n"," group in loop \n","data(filename='Bad96.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","645  Bad96.jpg    220     161   Bad     4    11   106   161\n","646  Bad96.jpg    220     161   Bad    56    12   159   161\n","647  Bad96.jpg    220     161   Bad   109    11   218   161)\n"," group in loop \n","data(filename='Bad97.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","543  Bad97.jpg    195     259   Bad     1     4   180   259)\n"," group in loop \n","data(filename='Badimages at 1.41.59 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1009  Badimages at 1.41.59 PM.jpg    612     490   Bad    40    21   354   325\n","1010  Badimages at 1.41.59 PM.jpg    612     490   Bad   226   122   515   377)\n"," group in loop \n","data(filename='Badimages at 1.42.29 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","786  Badimages at 1.42.29 PM.jpg    740     446   Bad    31    17   732   446)\n"," group in loop \n","data(filename='Badimages at 1.42.53 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","418  Badimages at 1.42.53 PM.jpg    840     560   Bad     2     2   421   556\n","419  Badimages at 1.42.53 PM.jpg    840     560   Bad   236     2   664   279\n","420  Badimages at 1.42.53 PM.jpg    840     560   Bad   427     1   839   555)\n"," group in loop \n","data(filename='Badimages at 1.43.45 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","587  Badimages at 1.43.45 PM.jpg    674     572   Bad    65    83   622   572)\n"," group in loop \n","data(filename='Badimages at 11.15.18 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","401  Badimages at 11.15.18 AM.jpg    896     426   Bad     1    23   257   378\n","402  Badimages at 11.15.18 AM.jpg    896     426   Bad   109    22   410   379\n","403  Badimages at 11.15.18 AM.jpg    896     426   Bad   251    62   515   378\n","404  Badimages at 11.15.18 AM.jpg    896     426   Bad   416    38   645   386\n","405  Badimages at 11.15.18 AM.jpg    896     426   Bad   515    39   811   385\n","406  Badimages at 11.15.18 AM.jpg    896     426   Bad   631    67   896   371)\n"," group in loop \n","data(filename='Badimages at 11.15.25 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","617  Badimages at 11.15.25 AM.jpg   1180     406   Bad     7     1   498   403\n","618  Badimages at 11.15.25 AM.jpg   1180     406   Bad   303     1   685   406\n","619  Badimages at 11.15.25 AM.jpg   1180     406   Bad   491     6   926   406\n","620  Badimages at 11.15.25 AM.jpg   1180     406   Bad   645    12  1172   406)\n"," group in loop \n","data(filename='Badimages at 11.15.32 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","555  Badimages at 11.15.32 AM.jpg   1026     528   Bad     5    40   488   509\n","556  Badimages at 11.15.32 AM.jpg   1026     528   Bad   168    38   648   510\n","557  Badimages at 11.15.32 AM.jpg   1026     528   Bad   461    51   826   512\n","558  Badimages at 11.15.32 AM.jpg   1026     528   Bad   653    38  1026   520)\n"," group in loop \n","data(filename='Badimages at 11.15.59 AM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","25  Badimages at 11.15.59 AM.jpg    462     764   Bad    11    16   414   753)\n"," group in loop \n","data(filename='Badimages at 11.16.09 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","159  Badimages at 11.16.09 AM.jpg    514     840   Bad    26    45   399   775)\n"," group in loop \n","data(filename='Badimages at 11.16.25 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","369  Badimages at 11.16.25 AM.jpg    448     736   Bad    22     1   408   714)\n"," group in loop \n","data(filename='Badimages at 11.16.37 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","393  Badimages at 11.16.37 AM.jpg    956     672   Bad     2     1   951   672)\n"," group in loop \n","data(filename='Badimages at 11.16.48 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","674  Badimages at 11.16.48 AM.jpg    972     694   Bad     2     4   971   680)\n"," group in loop \n","data(filename='Badimages at 11.17.06 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","883  Badimages at 11.17.06 AM.jpg    384     324   Bad     1    10   179   319\n","884  Badimages at 11.17.06 AM.jpg    384     324   Bad   202    11   380   319\n","885  Badimages at 11.17.06 AM.jpg    384     324   Bad    91    10   294   318)\n"," group in loop \n","data(filename='Badimages at 11.18.33 AM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","1085  Badimages at 11.18.33 AM.jpg    826     650   Bad    87     1   793   648)\n"," group in loop \n","data(filename='Badimages at 11.19.17 AM.jpg', object=                         filename  width  height  ... ymin  xmax  ymax\n","933  Badimages at 11.19.17 AM.jpg    478     558  ...   15   455   548\n","\n","[1 rows x 8 columns])\n"," group in loop \n","data(filename='Badimages at 11.19.29 AM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","1045  Badimages at 11.19.29 AM.jpg    890     674   Bad    13     9   890   674)\n"," group in loop \n","data(filename='Badimages at 11.27.05 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","621  Badimages at 11.27.05 AM.jpg    748     578   Bad    40     1   739   576)\n"," group in loop \n","data(filename='Badimages at 11.28.39 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","392  Badimages at 11.28.39 AM.jpg    496     488   Bad    12     1   471   483)\n"," group in loop \n","data(filename='Badimages at 3.04.53 PM.jpg', object=                       filename  width  height class  xmin  ymin  xmax  ymax\n","14  Badimages at 3.04.53 PM.jpg    828     410   Bad    56    64   538   345\n","15  Badimages at 3.04.53 PM.jpg    828     410   Bad   277    64   813   345)\n"," group in loop \n","data(filename='Badimages at 3.11.21 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1115  Badimages at 3.11.21 PM.jpg    672     546   Bad     4     4   659   355)\n"," group in loop \n","data(filename='Badimages at 3.12.37 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","502  Badimages at 3.12.37 PM.jpg    800     442   Bad    72    81   800   247)\n"," group in loop \n","data(filename='Badimages at 3.56.23 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","289  Badimages at 3.56.23 PM.jpg    660     494   Bad    84    57   660   489)\n"," group in loop \n","data(filename='Badimages at 4.33.45 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1114  Badimages at 4.33.45 PM.jpg    576     586   Bad     2    35   500   586)\n"," group in loop \n","data(filename='Badimages at 4.34.27 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","111  Badimages at 4.34.27 PM.jpg   1024     760   Bad     5     3  1024   760)\n"," group in loop \n","data(filename='Badimages at 4.34.56 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","137  Badimages at 4.34.56 PM.jpg    492     402   Bad     1    37   456   401)\n"," group in loop \n","data(filename='Badimages at 4.35.02 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1021  Badimages at 4.35.02 PM.jpg    704     624   Bad    66    20   638   624)\n"," group in loop \n","data(filename='Badimages at 4.35.44 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","437  Badimages at 4.35.44 PM.jpg    986     940   Bad   164    38   960   940)\n"," group in loop \n","data(filename='Badimages at 4.35.51 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","773  Badimages at 4.35.51 PM.jpg    876     802   Bad    44     2   784   802)\n"," group in loop \n","data(filename='Badimages at 4.35.58 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","686  Badimages at 4.35.58 PM.jpg    956     806   Bad    24    32   901   803)\n"," group in loop \n","data(filename='Badimages at 4.36.11 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","625  Badimages at 4.36.11 PM.jpg    694     618   Bad     2     8   693   618)\n"," group in loop \n","data(filename='Badimages at 4.36.17 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","999  Badimages at 4.36.17 PM.jpg   1066     730   Bad     3    55  1039   730)\n"," group in loop \n","data(filename='Badimages at 4.36.25 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","906  Badimages at 4.36.25 PM.jpg    358     524   Bad    12    18   356   524)\n"," group in loop \n","data(filename='Badimages at 4.36.31 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1165  Badimages at 4.36.31 PM.jpg    758     736   Bad    40    14   671   736)\n"," group in loop \n","data(filename='Badimages at 4.36.46 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","926  Badimages at 4.36.46 PM.jpg    672     628   Bad     2     2   670   628)\n"," group in loop \n","data(filename='Badimages at 4.36.59 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","218  Badimages at 4.36.59 PM.jpg    956     752   Bad   107     2   956   752)\n"," group in loop \n","data(filename='Badimages at 4.38.38 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","860  Badimages at 4.38.38 PM.jpg    504     585   Bad     1     4   504   585)\n"," group in loop \n","data(filename='Badimages at 4.38.59 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1079  Badimages at 4.38.59 PM.jpg    702     872   Bad     3     3   702   872)\n"," group in loop \n","data(filename='Badimages at 4.39.21 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","383  Badimages at 4.39.21 PM.jpg    606     612   Bad     3     2   606   612)\n"," group in loop \n","data(filename='Badimages at 4.40.01 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1168  Badimages at 4.40.01 PM.jpg    934     766   Bad     3     2   934   736)\n"," group in loop \n","data(filename='Badimages at 4.40.08 PM.jpg', object=                       filename  width  height class  xmin  ymin  xmax  ymax\n","41  Badimages at 4.40.08 PM.jpg    986     530   Bad     2     1   982   530)\n"," group in loop \n","data(filename='Badimages at 4.40.15 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","893  Badimages at 4.40.15 PM.jpg    898     704   Bad   128     9   898   401)\n"," group in loop \n","data(filename='Badimages at 4.40.23 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","930  Badimages at 4.40.23 PM.jpg    984     774   Bad     1     2   984   519)\n"," group in loop \n","data(filename='Badimages at 4.40.31 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","951  Badimages at 4.40.31 PM.jpg    832     742   Bad     1     8   832   638)\n"," group in loop \n","data(filename='Badimages at 4.41.05 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1055  Badimages at 4.41.05 PM.jpg    836     672   Bad    73    14   749   587)\n"," group in loop \n","data(filename='Badimages at 4.41.17 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1062  Badimages at 4.41.17 PM.jpg    902     700   Bad   155     1   902   556)\n"," group in loop \n","data(filename='Badimages at 4.41.42 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","852  Badimages at 4.41.42 PM.jpg    980     700   Bad    51    26   980   485)\n"," group in loop \n","data(filename='Badimages at 4.42.10 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","863  Badimages at 4.42.10 PM.jpg    786     516   Bad    66     1   677   513)\n"," group in loop \n","data(filename='Badimages at 4.42.22 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","818  Badimages at 4.42.22 PM.jpg    880     588   Bad     1     1   880   586)\n"," group in loop \n","data(filename='Badimages at 4.42.40 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","271  Badimages at 4.42.40 PM.jpg    968     720   Bad     2     3   968   515)\n"," group in loop \n","data(filename='Badimages at 4.42.55 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1087  Badimages at 4.42.55 PM.jpg    786     638   Bad     3    45   728   365)\n"," group in loop \n","data(filename='Badimages at 4.43.04 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1170  Badimages at 4.43.04 PM.jpg    958     628   Bad    30    14   953   437)\n"," group in loop \n","data(filename='Badimages at 4.43.10 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","626  Badimages at 4.43.10 PM.jpg    988     742   Bad     3     1   939   496)\n"," group in loop \n","data(filename='Badimages at 4.43.19 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","549  Badimages at 4.43.19 PM.jpg    698     818   Bad     3     1   697   567)\n"," group in loop \n","data(filename='Badimages at 4.46.59 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","495  Badimages at 4.46.59 PM.jpg    452     390   Bad    30    22   285   301)\n"," group in loop \n","data(filename='Badimages at 4.47.05 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1150  Badimages at 4.47.05 PM.jpg    370     348   Bad    39    14   297   348)\n"," group in loop \n","data(filename='Badimages at 4.47.54 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","616  Badimages at 4.47.54 PM.jpg    704     518   Bad    53    10   604   238)\n"," group in loop \n","data(filename='Badimages at 5.02.39 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1125  Badimages at 5.02.39 PM.jpg   1080     780   Bad    66     1  1001   746)\n"," group in loop \n","data(filename='Badimages at 5.02.49 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","694  Badimages at 5.02.49 PM.jpg    970     618   Bad    40    42   907   608)\n"," group in loop \n","data(filename='Badimages at 8.10.21 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1151  Badimages at 8.10.21 PM.jpg    404     718   Bad    17     3   290   678)\n"," group in loop \n","data(filename='Badimages at 8.11.20 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","302  Badimages at 8.11.20 PM.jpg    908     736   Bad     7     1   877   736)\n"," group in loop \n","data(filename='Badimages at 8.11.27 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1086  Badimages at 8.11.27 PM.jpg    852     614   Bad     5    11   820   614)\n"," group in loop \n","data(filename='Badimages at 8.11.32 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","276  Badimages at 8.11.32 PM.jpg    590     438   Bad     6    69   572   408)\n"," group in loop \n","data(filename='Badimages at 8.12.07 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","377  Badimages at 8.12.07 PM.jpg    788     418   Bad     1    16   776   293)\n"," group in loop \n","data(filename='Badimages at 8.12.12 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","712  Badimages at 8.12.12 PM.jpg   1004     592   Bad     9    17   978   592)\n"," group in loop \n","data(filename='Badimages at 8.12.18 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","858  Badimages at 8.12.18 PM.jpg    998     658   Bad    12     7   993   657)\n"," group in loop \n","data(filename='Badimages at 8.12.47 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","701  Badimages at 8.12.47 PM.jpg   1210     680   Bad     1     2  1203   680)\n"," group in loop \n","data(filename='Badimages at 8.13.41 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","599  Badimages at 8.13.41 PM.jpg    870     646   Bad     5     1   870   449)\n"," group in loop \n","data(filename='Badimages at 8.14.07 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","678  Badimages at 8.14.07 PM.jpg    400     498   Bad     1    23   400   497)\n"," group in loop \n","data(filename='Badimages at 8.14.25 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","181  Badimages at 8.14.25 PM.jpg    730     716   Bad     2     2   630   716)\n"," group in loop \n","data(filename='Badimages at 8.15.17 PM.jpg', object=                       filename  width  height class  xmin  ymin  xmax  ymax\n","73  Badimages at 8.15.17 PM.jpg    814     532   Bad    43    10   814   532)\n"," group in loop \n","data(filename='Badimages at 8.15.23 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","308  Badimages at 8.15.23 PM.jpg    596     528   Bad     2    16   596   528)\n"," group in loop \n","data(filename='Badimages at 8.15.53 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","968  Badimages at 8.15.53 PM.jpg    702     586   Bad     1    14   684   586)\n"," group in loop \n","data(filename='Badimages at 8.16.03 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","828  Badimages at 8.16.03 PM.jpg    802     902   Bad     1    58   802   684)\n"," group in loop \n","data(filename='Badimages at 8.16.20 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","501  Badimages at 8.16.20 PM.jpg    774     844   Bad    31    27   774   844)\n"," group in loop \n","data(filename='Badimages at 8.16.32 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","355  Badimages at 8.16.32 PM.jpg    486     526   Bad     1     1   452   526)\n"," group in loop \n","data(filename='Badimages at 8.16.38 PM.jpg', object=                       filename  width  height class  xmin  ymin  xmax  ymax\n","75  Badimages at 8.16.38 PM.jpg    858     854   Bad    61     5   858   573)\n"," group in loop \n","data(filename='Badimages at 8.17.01 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","1121  Badimages at 8.17.01 PM.jpg    316     414   Bad    27    39   291   379)\n"," group in loop \n","data(filename='Caution0.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","628  Caution0.jpg    278     181  Caution    99    65   247   165\n","629  Caution0.jpg    278     181  Caution    25    63   143   164)\n"," group in loop \n","data(filename='Caution1.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","762  Caution1.jpg    278     182  Caution    36    23   208   161)\n"," group in loop \n","data(filename='Caution10.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","942  Caution10.jpg    263     191  Caution    22     5   242   191)\n"," group in loop \n","data(filename='Caution100.jpg', object=            filename  width  height    class  xmin  ymin  xmax  ymax\n","1058  Caution100.jpg    360     410  Caution    35    16   311   371)\n"," group in loop \n","data(filename='Caution101.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","865  Caution101.jpg    776     396  Caution    47    72   724   256)\n"," group in loop \n","data(filename='Caution102.jpg', object=            filename  width  height    class  xmin  ymin  xmax  ymax\n","1011  Caution102.jpg    282     179  Caution   121     3   281   124)\n"," group in loop \n","data(filename='Caution103.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","995  Caution103.jpg    310     162  Caution    26     7   277   160)\n"," group in loop \n","data(filename='Caution104.jpg', object=            filename  width  height    class  xmin  ymin  xmax  ymax\n","1088  Caution104.jpg    259     194  Caution     7    21   237   184)\n"," group in loop \n","data(filename='Caution105.jpg', object=            filename  width  height    class  xmin  ymin  xmax  ymax\n","1077  Caution105.jpg   1100     825  Caution    16    40  1096   547)\n"," group in loop \n","data(filename='Caution106.jpg', object=            filename  width  height    class  xmin  ymin  xmax  ymax\n","1131  Caution106.jpg    275     183  Caution    24    29   196   183)\n"," group in loop \n","data(filename='Caution107.jpg', object=            filename  width  height class  xmin  ymin  xmax  ymax\n","1164  Caution107.jpg    864     570   Bad    72   111   831   502)\n"," group in loop \n","data(filename='Caution108.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","116  Caution108.jpg    271     186  Caution    17     9   257   132)\n"," group in loop \n","data(filename='Caution109.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","77  Caution109.jpg    299     168  Caution    63     5   187   168\n","78  Caution109.jpg    299     168  Caution   124     1   248   168)\n"," group in loop \n","data(filename='Caution110.jpg', object=            filename  width  height    class  xmin  ymin  xmax  ymax\n","1106  Caution110.jpg    299     168  Caution    47     5   260   168)\n"," group in loop \n","data(filename='Caution111.jpg', object=            filename  width  height    class  xmin  ymin  xmax  ymax\n","1076  Caution111.jpg    275     183  Caution    27    27   253   150)\n"," group in loop \n","data(filename='Caution112.jpg', object=            filename  width  height class  xmin  ymin  xmax  ymax\n","1129  Caution112.jpg    668     430   Bad    45    29   624   425)\n"," group in loop \n","data(filename='Caution113.jpg', object=            filename  width  height    class  xmin  ymin  xmax  ymax\n","1155  Caution113.jpg    742     556  Caution    22    11   731   554)\n"," group in loop \n","data(filename='Caution114.jpg', object=            filename  width  height    class  xmin  ymin  xmax  ymax\n","1056  Caution114.jpg    278     181  Caution    10    13   241   163)\n"," group in loop \n","data(filename='Caution115.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","864  Caution115.jpg    660     374  Caution    88    42   558   366)\n"," group in loop \n","data(filename='Caution116.jpg', object=            filename  width  height class  xmin  ymin  xmax  ymax\n","1018  Caution116.jpg   2000     954  Good  1025   104  1399   870\n","1019  Caution116.jpg   2000     954  Good  1291   154  1656   849\n","1020  Caution116.jpg   2000     954  Good   546   108  1265   901)\n"," group in loop \n","data(filename='Caution117.jpg', object=            filename  width  height    class  xmin  ymin  xmax  ymax\n","1005  Caution117.jpg    720     379  Caution   237    52   566   379)\n"," group in loop \n","data(filename='Caution118.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","298  Caution118.jpg    300     168  Caution    35    17   280   167)\n"," group in loop \n","data(filename='Caution12.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","957  Caution12.jpg    308     164  Caution    13     1   144   163\n","958  Caution12.jpg    308     164  Caution   103     1   212   164\n","959  Caution12.jpg    308     164  Caution   139     6   305   164)\n"," group in loop \n","data(filename='Caution121.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","79  Caution121.jpg    277     182  Caution    26    25   255   180)\n"," group in loop \n","data(filename='Caution122.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","17  Caution122.jpg    275     183  Caution     7    53   263   183)\n"," group in loop \n","data(filename='Caution124.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","299  Caution124.jpg    248     204  Caution    37    57   150   170\n","300  Caution124.jpg    248     204  Caution   107    61   199   169)\n"," group in loop \n","data(filename='Caution125.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","342  Caution125.jpg    300     168  Caution    34    32   123   128\n","343  Caution125.jpg    300     168  Caution    91    45   211   153\n","344  Caution125.jpg    300     168  Caution   154    48   287   168)\n"," group in loop \n","data(filename='Caution127.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","171  Caution127.jpg    516     390  Caution    50    45   443   359)\n"," group in loop \n","data(filename='Caution128.jpg', object=            filename  width  height    class  xmin  ymin  xmax  ymax\n","1059  Caution128.jpg    794     474  Caution    29    51   782   442)\n"," group in loop \n","data(filename='Caution129.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","857  Caution129.jpg    440     380  Caution    17    22   435   369)\n"," group in loop \n","data(filename='Caution13.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","817  Caution13.jpg    339     149  Caution    39     9   290   148)\n"," group in loop \n","data(filename='Caution130.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","297  Caution130.jpg    278     181  Caution    25    72   209   164)\n"," group in loop \n","data(filename='Caution131.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","345  Caution131.jpg    448     442  Caution    14    17   429   307)\n"," group in loop \n","data(filename='Caution132.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","212  Caution132.jpg    318     159  Caution    17    13   286   151)\n"," group in loop \n","data(filename='Caution133.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","175  Caution133.jpg    340     274  Caution    39    43   320   234)\n"," group in loop \n","data(filename='Caution134.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","112  Caution134.jpg    716     550  Caution   166   105   654   356\n","113  Caution134.jpg    716     550     Good   404    96   673   348\n","114  Caution134.jpg    716     550  Caution    11     1   285   455)\n"," group in loop \n","data(filename='Caution135.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","86  Caution135.jpg    300     170  Caution    46    17   300   170)\n"," group in loop \n","data(filename='Caution136.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","19  Caution136.jpg    430     358  Caution     1     1   356   335)\n"," group in loop \n","data(filename='Caution137.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","43  Caution137.jpg    496     514  Caution    11    13   494   513)\n"," group in loop \n","data(filename='Caution138.jpg', object=            filename  width  height    class  xmin  ymin  xmax  ymax\n","1111  Caution138.jpg    644     500  Caution     1     8   638   465)\n"," group in loop \n","data(filename='Caution139.jpg', object=            filename  width  height    class  xmin  ymin  xmax  ymax\n","1078  Caution139.jpg    494     332  Caution   108    52   405   330)\n"," group in loop \n","data(filename='Caution14.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","764  Caution14.jpg    275     183  Caution    38    15   243   182)\n"," group in loop \n","data(filename='Caution140.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","360  Caution140.jpg    402     294  Caution    25    27   369   294)\n"," group in loop \n","data(filename='Caution141.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","494  Caution141.jpg    418     434  Caution     2    30   365   348)\n"," group in loop \n","data(filename='Caution142.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","394  Caution142.jpg    814     510  Caution    89    57   798   503)\n"," group in loop \n","data(filename='Caution143.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","432  Caution143.jpg    642     422  Caution    70    46   537   383)\n"," group in loop \n","data(filename='Caution144.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","574  Caution144.jpg    400     300  Caution    34    33   333   297)\n"," group in loop \n","data(filename='Caution145.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","444  Caution145.jpg    654     368  Caution    58     2   652   364)\n"," group in loop \n","data(filename='Caution146.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","518  Caution146.jpg    275     183  Caution   164    63   261   180\n","519  Caution146.jpg    275     183  Caution   123    55   198   170\n","520  Caution146.jpg    275     183  Caution    92    56   153   160\n","521  Caution146.jpg    275     183  Caution    42    68   112   151\n","522  Caution146.jpg    275     183  Caution     7    70    73   149)\n"," group in loop \n","data(filename='Caution147.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","679  Caution147.jpg   1048     500  Caution     1     4  1028   472)\n"," group in loop \n","data(filename='Caution148.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","704  Caution148.jpg    390     374  Caution    24    40   328   361)\n"," group in loop \n","data(filename='Caution149.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","713  Caution149.jpg    259     195  Caution     6    23   140   158\n","714  Caution149.jpg    259     195  Caution   107    24   240   157)\n"," group in loop \n","data(filename='Caution15.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","631  Caution15.jpg    282     179  Caution     1    14   122   179\n","632  Caution15.jpg    282     179  Caution    57    33   220   179\n","633  Caution15.jpg    282     179  Caution   145    22   281   179)\n"," group in loop \n","data(filename='Caution152.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","517  Caution152.jpg    614     574  Caution     2     4   602   571)\n"," group in loop \n","data(filename='Caution153.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","676  Caution153.jpg    384     244  Caution    72    33   288   224)\n"," group in loop \n","data(filename='Caution155.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","497  Caution155.jpg    410     292  Caution    69    27   325   289)\n"," group in loop \n","data(filename='Caution156.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","389  Caution156.jpg    650     420  Caution    47    27   603   419)\n"," group in loop \n","data(filename='Caution157.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","433  Caution157.jpg    508     370  Caution    22    86   433   358)\n"," group in loop \n","data(filename='Caution158.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","812  Caution158.jpg    400     402  Caution     1    13   400   400)\n"," group in loop \n","data(filename='Caution159.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","969  Caution159.jpg    698     392  Caution   258    18   590   359)\n"," group in loop \n","data(filename='Caution16.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","745  Caution16.jpg    299     168  Caution     1     1   177   147\n","746  Caution16.jpg    299     168  Caution   123     9   297   147)\n"," group in loop \n","data(filename='Caution160.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","843  Caution160.jpg    808     408  Caution    89    36   786   404)\n"," group in loop \n","data(filename='Caution161.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","719  Caution161.jpg    492     380  Caution    39    27   464   357)\n"," group in loop \n","data(filename='Caution162.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","604  Caution162.jpg    520     364  Caution    11    95   446   274)\n"," group in loop \n","data(filename='Caution163.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","759  Caution163.jpg    820     520  Caution   126    29   791   465)\n"," group in loop \n","data(filename='Caution164.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","816  Caution164.jpg    300     168  Caution    56     3   287   167)\n"," group in loop \n","data(filename='Caution165.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","976  Caution165.jpg    414     448  Caution    15    32   369   404)\n"," group in loop \n","data(filename='Caution166.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","908  Caution166.jpg    498     386  Caution    63    50   468   377)\n"," group in loop \n","data(filename='Caution167.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","936  Caution167.jpg    876     496  Caution     1    44   872   494)\n"," group in loop \n","data(filename='Caution17.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","834  Caution17.jpg    273     185  Caution    28     7   235   184)\n"," group in loop \n","data(filename='Caution170.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","811  Caution170.jpg    546     374  Caution    21    15   532   370)\n"," group in loop \n","data(filename='Caution171.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","972  Caution171.jpg    300     168  Caution    87    20   173   168\n","973  Caution171.jpg    300     168  Caution     5     3   123   166\n","974  Caution171.jpg    300     168  Caution   204    23   293   157\n","975  Caution171.jpg    300     168  Caution   140    25   253   158)\n"," group in loop \n","data(filename='Caution172.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","905  Caution172.jpg    710     344  Caution     4    18   690   341)\n"," group in loop \n","data(filename='Caution173.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","944  Caution173.jpg    978     686  Caution    17    11   976   680)\n"," group in loop \n","data(filename='Caution174.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","844  Caution174.jpg    608     426  Caution    53    19   603   424)\n"," group in loop \n","data(filename='Caution175.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","723  Caution175.jpg    440     380  Caution    19    22   435   377)\n"," group in loop \n","data(filename='Caution176.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","609  Caution176.jpg    412     256  Caution     6    15   395   252)\n"," group in loop \n","data(filename='Caution177.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","758  Caution177.jpg    736     490  Caution    62    13   654   489)\n"," group in loop \n","data(filename='Caution178.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","572  Caution178.jpg    832     442  Caution    20    62   748   412)\n"," group in loop \n","data(filename='Caution179.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","446  Caution179.jpg    300     168  Caution   121    30   201   124)\n"," group in loop \n","data(filename='Caution18.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","652  Caution18.jpg    300     168  Caution    44     6   275   168)\n"," group in loop \n","data(filename='Caution180.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","240  Caution180.jpg    610     422  Caution    12    37   592   422)\n"," group in loop \n","data(filename='Caution182.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","489  Caution182.jpg   3080    2048  Caution   560   337  2819  1603)\n"," group in loop \n","data(filename='Caution183.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","350  Caution183.jpg    508     370  Caution    41    87   430   347)\n"," group in loop \n","data(filename='Caution184.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","677  Caution184.jpg    259     194  Caution    56    40   192   193)\n"," group in loop \n","data(filename='Caution185.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","516  Caution185.jpg    522     390  Caution    43    30   468   373)\n"," group in loop \n","data(filename='Caution186.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","449  Caution186.jpg    596     424  Caution    32    34   570   384)\n"," group in loop \n","data(filename='Caution187.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","580  Caution187.jpg    259     194  Caution     1    29   239   167)\n"," group in loop \n","data(filename='Caution188.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","778  Caution188.jpg    678     332     Good     1    15   316   318\n","779  Caution188.jpg    678     332     Good   227    18   659   330\n","780  Caution188.jpg    678     332  Caution    15    16   657   328)\n"," group in loop \n","data(filename='Caution189.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","610  Caution189.jpg    670     436  Caution    26     2   670   436)\n"," group in loop \n","data(filename='Caution190.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","667  Caution190.jpg    622     424  Caution    70    46   519   408)\n"," group in loop \n","data(filename='Caution191.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","531  Caution191.jpg    240     246  Caution    23    32   196   228)\n"," group in loop \n","data(filename='Caution192.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","442  Caution192.jpg    530     394  Caution    16    26   525   394)\n"," group in loop \n","data(filename='Caution194.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","239  Caution194.jpg    458     334  Caution    34    35   387   331)\n"," group in loop \n","data(filename='Caution196.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","491  Caution196.jpg    428     314  Caution    90    50   389   300)\n"," group in loop \n","data(filename='Caution197.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","506  Caution197.jpg    820     520  Caution    82    26   800   472)\n"," group in loop \n","data(filename='Caution198.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","935  Caution198.jpg    608     426  Caution    44    18   605   426)\n"," group in loop \n","data(filename='Caution199.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","917  Caution199.jpg    776     396  Caution    32    75   725   358)\n"," group in loop \n","data(filename='Caution2.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","825  Caution2.jpg    281     180  Caution    32    46   153   148)\n"," group in loop \n","data(filename='Caution20.JPG', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","266  Caution20.JPG    287     346  Caution    60    77   215   307)\n"," group in loop \n","data(filename='Caution200.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","638  Caution200.jpg    260     194  Caution    80    32   196   184)\n"," group in loop \n","data(filename='Caution201.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","748  Caution201.jpg    668     450  Caution    43    41   632   412)\n"," group in loop \n","data(filename='Caution203.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","747  Caution203.jpg    486     358  Caution    57     4   425   321)\n"," group in loop \n","data(filename='Caution204.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","899  Caution204.jpg    700     606  Caution    36    12   691   592)\n"," group in loop \n","data(filename='Caution205.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","952  Caution205.jpg    486     414  Caution    43    58   444   403)\n"," group in loop \n","data(filename='Caution206.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","820  Caution206.jpg    492     400  Caution    22    19   404   393)\n"," group in loop \n","data(filename='Caution207.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","955  Caution207.jpg    510     318  Caution    29    17   482   312)\n"," group in loop \n","data(filename='Caution209.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","261  Caution209.jpg    416     396  Caution     1    28   399   393)\n"," group in loop \n","data(filename='Caution210.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","901  Caution210.jpg    570     422  Caution   124    30   559   417)\n"," group in loop \n","data(filename='Caution211.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","938  Caution211.jpg    516     560  Caution     3    20   513   560)\n"," group in loop \n","data(filename='Caution212.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","826  Caution212.jpg    454     496  Caution    27    28   435   480)\n"," group in loop \n","data(filename='Caution213.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","965  Caution213.jpg    680     426  Caution    47    32   565   412)\n"," group in loop \n","data(filename='Caution215.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","749  Caution215.jpg    748     404  Caution   114    47   579   370)\n"," group in loop \n","data(filename='Caution217.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","741  Caution217.jpg    504     384  Caution    45    56   396   363)\n"," group in loop \n","data(filename='Caution218.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","561  Caution218.jpg    598     390  Caution    10    15   593   387)\n"," group in loop \n","data(filename='Caution219.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","639  Caution219.jpg    225     225  Caution    29    58   164   223)\n"," group in loop \n","data(filename='Caution22.JPG', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","482  Caution22.JPG    284     363  Caution    44    22   226   314)\n"," group in loop \n","data(filename='Caution220.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","375  Caution220.jpg    440     380  Caution    18    19   440   355)\n"," group in loop \n","data(filename='Caution221.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","251  Caution221.jpg    261     193  Caution    11     6   243   192)\n"," group in loop \n","data(filename='Caution222.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","379  Caution222.jpg    288     175  Caution     9    22   244   148)\n"," group in loop \n","data(filename='Caution223.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","472  Caution223.jpg    660     444  Caution     1     9   659   431)\n"," group in loop \n","data(filename='Caution224.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","550  Caution224.jpg    500     388  Caution    32    42   500   385)\n"," group in loop \n","data(filename='Caution225.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","651  Caution225.jpg    692     412  Caution    38    58   678   411)\n"," group in loop \n","data(filename='Caution226.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","553  Caution226.jpg    666     384  Caution    44    21   638   384)\n"," group in loop \n","data(filename='Caution227.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","463  Caution227.jpg    275     183  Caution    16     4   223   118)\n"," group in loop \n","data(filename='Caution228.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","630  Caution228.jpg    219     230  Caution     6    39   216   174)\n"," group in loop \n","data(filename='Caution229.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","761  Caution229.jpg    672     454  Caution    75     7   663   271)\n"," group in loop \n","data(filename='Caution230.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","547  Caution230.jpg    824     466  Caution    36    33   801   408)\n"," group in loop \n","data(filename='Caution234.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","373  Caution234.jpg    700     466      Bad    84    85   248   377\n","374  Caution234.jpg    700     466  Caution   188    79   489   378)\n"," group in loop \n","data(filename='Caution235.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","260  Caution235.jpg    476     386  Caution    12    23   438   381)\n"," group in loop \n","data(filename='Caution236.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","380  Caution236.jpg    812     464  Caution     2    32   812   382)\n"," group in loop \n","data(filename='Caution238.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","891  Caution238.jpg    524     478  Caution    41    63   474   478)\n"," group in loop \n","data(filename='Caution239.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","954  Caution239.jpg    354     318  Caution    22    59   268   278)\n"," group in loop \n","data(filename='Caution24.JPG', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","648  Caution24.JPG    247     295  Caution    28    25   176   254)\n"," group in loop \n","data(filename='Caution242.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","141  Caution242.jpg    608     426  Caution    42    21   606   424)\n"," group in loop \n","data(filename='Caution243.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","70  Caution243.jpg    358     366  Caution    17    36   331   364)\n"," group in loop \n","data(filename='Caution245.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","158  Caution245.jpg    275     183  Caution     7     4   272   181)\n"," group in loop \n","data(filename='Caution246.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","277  Caution246.jpg    477     268      Bad    82    49   204   268\n","278  Caution246.jpg    477     268  Caution   143    23   297   268\n","279  Caution246.jpg    477     268  Caution   214     2   399   267)\n"," group in loop \n","data(filename='Caution248.jpg', object=            filename  width  height    class  xmin  ymin  xmax  ymax\n","1051  Caution248.jpg    724     350  Caution    26    32   713   350)\n"," group in loop \n","data(filename='Caution25.JPG', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","546  Caution25.JPG    361     438  Caution    41   177   304   402)\n"," group in loop \n","data(filename='Caution250.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","238  Caution250.jpg    424     312  Caution    22    32   382   312)\n"," group in loop \n","data(filename='Caution26.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","468  Caution26.jpg    301     167  Caution     1     1   301   167)\n"," group in loop \n","data(filename='Caution27.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","564  Caution27.jpg    259     194  Caution    19    28   249   193)\n"," group in loop \n","data(filename='Caution28.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","765  Caution28.jpg    299     168  Caution     1     1   298   168)\n"," group in loop \n","data(filename='Caution29.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","634  Caution29.jpg    258     195  Caution     1     1   258   195)\n"," group in loop \n","data(filename='Caution3.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","740  Caution3.jpg    288     280  Caution    26    24   248   178)\n"," group in loop \n","data(filename='Caution30.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","649  Caution30.jpg    299     168  Caution    12     1   281   168)\n"," group in loop \n","data(filename='Caution31.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","548  Caution31.jpg    297     170  Caution    49     1   264   170)\n"," group in loop \n","data(filename='Caution32.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","467  Caution32.jpg    300     168  Caution    22     1   285   168)\n"," group in loop \n","data(filename='Caution33.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","565  Caution33.jpg    300     168  Caution     1     1   191   166\n","566  Caution33.jpg    300     168  Caution   144    21   300   165)\n"," group in loop \n","data(filename='Caution34.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","265  Caution34.jpg    259     194  Caution    27     3   240   188)\n"," group in loop \n","data(filename='Caution35.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","391  Caution35.jpg    300     168  Caution     1     1   300   167)\n"," group in loop \n","data(filename='Caution37.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","365  Caution37.jpg    275     183  Caution    12    12   274   182)\n"," group in loop \n","data(filename='Caution38.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","941  Caution38.jpg    301     167  Caution     1    10   301   165)\n"," group in loop \n","data(filename='Caution39.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","900  Caution39.jpg    300     168  Caution     2     1   300   168)\n"," group in loop \n","data(filename='Caution40.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","54  Caution40.jpg    276     183  Caution    45    32   239   183)\n"," group in loop \n","data(filename='Caution42.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","66  Caution42.jpg    259     194  Caution    40    29   244   192)\n"," group in loop \n","data(filename='Caution43.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","130  Caution43.jpg    286     176  Caution     1     4   237   167)\n"," group in loop \n","data(filename='Caution44.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","170  Caution44.jpg    294     172  Caution    28     1   247   172)\n"," group in loop \n","data(filename='Caution45.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","215  Caution45.jpg    345     146  Caution    70     1   344   144)\n"," group in loop \n","data(filename='Caution46.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","348  Caution46.jpg    275     183  Caution     1     2   272   183)\n"," group in loop \n","data(filename='Caution47.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","288  Caution47.jpg    255     197  Caution    44     1   255   197)\n"," group in loop \n","data(filename='Caution48.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","993  Caution48.jpg    311     162  Caution   182    14   227    83\n","994  Caution48.jpg    311     162     Good    46     1   211    40)\n"," group in loop \n","data(filename='Caution49.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","1031  Caution49.jpg    438     420  Caution    31   125   183   242\n","1032  Caution49.jpg    438     420  Caution   235   139   323   309\n","1033  Caution49.jpg    438     420  Caution   288   133   401   217)\n"," group in loop \n","data(filename='Caution51.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","213  Caution51.jpg    318     159  Caution    19    75   199   159\n","214  Caution51.jpg    318     159  Caution   119    77   314   159)\n"," group in loop \n","data(filename='Caution53.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","274  Caution53.jpg    640     420  Caution     1    71   415   292\n","275  Caution53.jpg    640     420  Caution   239    58   640   300)\n"," group in loop \n","data(filename='Caution55.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","7  Caution55.jpg    275     183  Caution    66    47   207   148)\n"," group in loop \n","data(filename='Caution56.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","62  Caution56.jpg    272     185  Caution    20    86   113   156\n","63  Caution56.jpg    272     185  Caution    69    89   173   155\n","64  Caution56.jpg    272     185  Caution   137    91   209   155\n","65  Caution56.jpg    272     185      Bad   204    90   255   155)\n"," group in loop \n","data(filename='Caution57.jpg', object=          filename  width  height class  xmin  ymin  xmax  ymax\n","136  Caution57.jpg    810     438   Bad    64    15   679   365)\n"," group in loop \n","data(filename='Caution59.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","1128  Caution59.jpg    776     396  Caution    35    76   719   345)\n"," group in loop \n","data(filename='Caution6.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","821  Caution6.jpg    266     190  Caution    27     6   249   190)\n"," group in loop \n","data(filename='Caution60.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","984  Caution60.jpg    456     358  Caution    94    94   375   310)\n"," group in loop \n","data(filename='Caution61.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","1049  Caution61.jpg    492     396  Caution    45    62   414   327)\n"," group in loop \n","data(filename='Caution62.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","871  Caution62.jpg    456     426  Caution    26    43   394   416)\n"," group in loop \n","data(filename='Caution63.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","1035  Caution63.jpg    310     163  Caution    46    14   172   161\n","1036  Caution63.jpg    310     163  Caution   122     6   251   162)\n"," group in loop \n","data(filename='Caution64.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","1159  Caution64.jpg    294     171  Caution    59    38   187   160\n","1160  Caution64.jpg    294     171  Caution   143    37   270   155)\n"," group in loop \n","data(filename='Caution65.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","1118  Caution65.jpg    738     418  Caution    19    95   673   367)\n"," group in loop \n","data(filename='Caution67.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","1112  Caution67.jpg    288     198  Caution    36    27   248   196)\n"," group in loop \n","data(filename='Caution68.JPG', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","55  Caution68.JPG   1795     775  Caution     5     1  1789   768)\n"," group in loop \n","data(filename='Caution69.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","8  Caution69.jpg    275     183  Caution    60    46   222   153)\n"," group in loop \n","data(filename='Caution7.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","961  Caution7.jpg    264     191  Caution    33     7   210   189)\n"," group in loop \n","data(filename='Caution70.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","1161  Caution70.jpg    318     159  Caution    49     1   266   159)\n"," group in loop \n","data(filename='Caution71.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","1122  Caution71.jpg    299     169  Caution    18     1   270   118)\n"," group in loop \n","data(filename='Caution72.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","1063  Caution72.jpg    300     168  Caution    30     1   282   126)\n"," group in loop \n","data(filename='Caution73.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","1116  Caution73.jpg    508     370  Caution     5    86   430   342)\n"," group in loop \n","data(filename='Caution74.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","987  Caution74.jpg    860     556  Caution     2     5   858   531)\n"," group in loop \n","data(filename='Caution75.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","1044  Caution75.jpg    590     454  Caution    33    19   586   439)\n"," group in loop \n","data(filename='Caution76.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","878  Caution76.jpg    870     566  Caution    75    16   865   544)\n"," group in loop \n","data(filename='Caution77.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","1040  Caution77.jpg    578     416  Caution    11     7   551   353)\n"," group in loop \n","data(filename='Caution78.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","155  Caution78.jpg    275     183  Caution    35     6   201   183)\n"," group in loop \n","data(filename='Caution79.JPG', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","226  Caution79.JPG    781     350  Caution   181    48   779   330)\n"," group in loop \n","data(filename='Caution8.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","370  Caution8.jpg    301     167  Caution    44     6   298   166)\n"," group in loop \n","data(filename='Caution80.JPG', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","131  Caution80.JPG    409     518  Caution     1    11   376   515)\n"," group in loop \n","data(filename='Caution81.JPG', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","71  Caution81.JPG    339     231  Caution    19     1   321   169)\n"," group in loop \n","data(filename='Caution82.JPG', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","2  Caution82.JPG    888     621  Caution     4    25   261   513\n","3  Caution82.JPG    888     621  Caution   256    62   498   573\n","4  Caution82.JPG    888     621  Caution   337    98   587   562\n","5  Caution82.JPG    888     621  Caution   615    85   749   565)\n"," group in loop \n","data(filename='Caution83.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","56  Caution83.jpg    275     183  Caution    43    57   148   180)\n"," group in loop \n","data(filename='Caution84.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","280  Caution84.jpg    300     168  Caution     7     4   256   167)\n"," group in loop \n","data(filename='Caution85.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","349  Caution85.jpg    255     198  Caution    31     9   201   103)\n"," group in loop \n","data(filename='Caution88.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","1038  Caution88.jpg    866     460  Caution    88     1   728   362)\n"," group in loop \n","data(filename='Caution89.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","873  Caution89.jpg    618     398     Good    92    54   381   230\n","874  Caution89.jpg    618     398     Good   333    54   600   229\n","875  Caution89.jpg    618     398  Caution    88    52   600   230)\n"," group in loop \n","data(filename='Caution90.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","269  Caution90.jpg    555     369  Caution    57    56   313   369)\n"," group in loop \n","data(filename='Caution91.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","153  Caution91.jpg   1180     666  Caution    74   197   687   666\n","154  Caution91.jpg   1180     666  Caution   485   232  1062   666)\n"," group in loop \n","data(filename='Caution92.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","227  Caution92.jpg    620     465  Caution    11    68   529   321)\n"," group in loop \n","data(filename='Caution93.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","148  Caution93.jpg    267     189  Caution    18    69   109   176\n","149  Caution93.jpg    267     189  Caution    82    72   151   172\n","150  Caution93.jpg    267     189  Caution   127    73   204   174\n","151  Caution93.jpg    267     189  Caution   179    70   266   175)\n"," group in loop \n","data(filename='Caution94.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","138  Caution94.jpg    800     449  Caution   160   100   433   424\n","139  Caution94.jpg    800     449  Caution   311   106   616   392\n","140  Caution94.jpg    800     449  Caution   490   123   800   391)\n"," group in loop \n","data(filename='Caution95.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","57  Caution95.jpg    620     413  Caution     9   111   261   369\n","58  Caution95.jpg    620     413  Caution   196   112   445   365\n","59  Caution95.jpg    620     413  Caution   379   123   601   358)\n"," group in loop \n","data(filename='Caution96.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","236  Caution96.jpg   1500     886  Caution   403    24  1153   875)\n"," group in loop \n","data(filename='Caution97.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","60  Caution97.jpg    275     183  Caution    34    17   199   180\n","61  Caution97.jpg    275     183  Caution   142    19   240   130)\n"," group in loop \n","data(filename='Caution98.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","1120  Caution98.jpg    774     718  Caution     6    14   722   713)\n"," group in loop \n","data(filename='Good1.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","241  Good1.jpg    442     292  Good    67   113   321   249)\n"," group in loop \n","data(filename='Good100.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","611  Good100.jpg    275     183  Good    16    19   242   168)\n"," group in loop \n","data(filename='Good101.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","769  Good101.jpg   1280     853  Caution    17   321   740   847\n","770  Good101.jpg   1280     853  Caution   526   318  1265   853)\n"," group in loop \n","data(filename='Good103.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","727  Good103.jpg    680     347  Good     9   113   385   338\n","728  Good103.jpg    680     347  Good   326   135   466   347\n","729  Good103.jpg    680     347  Good   424   153   656   308)\n"," group in loop \n","data(filename='Good104.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","916  Good104.jpg    342     193  Good    38    35   290   187)\n"," group in loop \n","data(filename='Good106.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","804  Good106.jpg    260     194  Caution    44    32   221   164)\n"," group in loop \n","data(filename='Good107.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","789  Good107.jpg    259     194  Good    15    73   237   160)\n"," group in loop \n","data(filename='Good109.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","428  Good109.jpg    300     168  Caution    59    26   271   164)\n"," group in loop \n","data(filename='Good11.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","996  Good11.jpg    531     303  Caution    26    25   502   267)\n"," group in loop \n","data(filename='Good110.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","918  Good110.jpg    275     183  Good    21    42   266   175)\n"," group in loop \n","data(filename='Good111.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","923  Good111.jpg    269     187  Good    18    63   251   175)\n"," group in loop \n","data(filename='Good113.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","970  Good113.jpg    300     168  Good    18    57   286   113)\n"," group in loop \n","data(filename='Good114.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","784  Good114.jpg    318     159  Good    94    28   307   138)\n"," group in loop \n","data(filename='Good115.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","783  Good115.jpg    275     183  Good    23    36   246   154)\n"," group in loop \n","data(filename='Good116.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","705  Good116.jpg    318     159  Good    23    44   169   159\n","706  Good116.jpg    318     159  Good   128    44   309   158)\n"," group in loop \n","data(filename='Good117.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","732  Good117.jpg    275     183  Good    40   108   227   154\n","733  Good117.jpg    275     183  Good   159    90   229   155\n","734  Good117.jpg    275     183  Good    40    90   192   154)\n"," group in loop \n","data(filename='Good118.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","530  Good118.jpg    275     183  Good    34    47   252   160)\n"," group in loop \n","data(filename='Good119.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","662  Good119.jpg    275     183  Caution    34   101   101   152\n","663  Good119.jpg    275     183     Good    68   101   168   170\n","664  Good119.jpg    275     183     Good   128   101   245   183)\n"," group in loop \n","data(filename='Good121.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","425  Good121.jpg    275     183  Good     1    61   127   177\n","426  Good121.jpg    275     183  Good    90    62   207   177\n","427  Good121.jpg    275     183  Good   168    62   275   169)\n"," group in loop \n","data(filename='Good122.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","507  Good122.jpg    299     168  Good     1    40   110   168\n","508  Good122.jpg    299     168  Good    82    36   222   168)\n"," group in loop \n","data(filename='Good123.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","492  Good123.jpg    275     183  Good    72    88   221   154)\n"," group in loop \n","data(filename='Good124.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","525  Good124.jpg   4032    3024  Good   457  1076  1053  2401\n","526  Good124.jpg   4032    3024  Good   469  1634  2149  2697\n","527  Good124.jpg   4032    3024  Good  2086  1134  3494  2118\n","528  Good124.jpg   4032    3024  Good  1453  1559  2336  2680)\n"," group in loop \n","data(filename='Good125.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","668  Good125.jpg   1400     933   Bad    10   200   332   409\n","669  Good125.jpg   1400     933   Bad   703   234   951   622\n","670  Good125.jpg   1400     933  Good   198   199   791   590\n","671  Good125.jpg   1400     933  Good   843   242  1382   826)\n"," group in loop \n","data(filename='Good126.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","579  Good126.jpg    640     454  Good    84    48   488   358)\n"," group in loop \n","data(filename='Good127.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","453  Good127.jpg   1024     508  Good    15   112   962   464)\n"," group in loop \n","data(filename='Good128.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","614  Good128.jpg    750     450  Good   255   147   534   434)\n"," group in loop \n","data(filename='Good129.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","766  Good129.jpg    540     405  Good    42    48   482   345)\n"," group in loop \n","data(filename='Good13.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","856  Good13.jpg    626     349  Good    96    28   536   349)\n"," group in loop \n","data(filename='Good131.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","672  Good131.jpg    966     614  Good   272   200   711   614)\n"," group in loop \n","data(filename='Good132.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","571  Good132.jpg    996     768  Good   156   287   835   653)\n"," group in loop \n","data(filename='Good133.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","450  Good133.jpg   1996    1996  Good    74   991   816  1801\n","451  Good133.jpg   1996    1996  Good   450   975  1108  1804\n","452  Good133.jpg   1996    1996  Good   932   983  1745  1741)\n"," group in loop \n","data(filename='Good134.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","397  Good134.jpg    855     544  Good   123   280   808   475)\n"," group in loop \n","data(filename='Good138.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","915  Good138.jpg    275     183  Good    42    38   215   151)\n"," group in loop \n","data(filename='Good139.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","924  Good139.jpg    366     181  Good    45    24   362   181)\n"," group in loop \n","data(filename='Good14.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1140  Good14.jpg    716     357  Good   121    42   605   355)\n"," group in loop \n","data(filename='Good140.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","12  Good140.jpg    730     325  Good   118     9   725   304)\n"," group in loop \n","data(filename='Good147.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","341  Good147.jpg    269     188  Good     4    11   262   185)\n"," group in loop \n","data(filename='Good15.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","1145  Good15.jpg    561     308  Caution   240    41   426   213)\n"," group in loop \n","data(filename='Good150.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","204  Good150.jpg    263     191  Good    28    62   152   183\n","205  Good150.jpg    263     191  Good   127    62   215   137\n","206  Good150.jpg    263     191  Good   197    54   243   154)\n"," group in loop \n","data(filename='Good151.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","173  Good151.jpg    300     168  Good   219    33   290   168\n","174  Good151.jpg    300     168  Good     2    37   275   168)\n"," group in loop \n","data(filename='Good152.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","290  Good152.jpg    300     168  Good   121    29   225   114\n","291  Good152.jpg    300     168  Good     1    33   115   168\n","292  Good152.jpg    300     168  Good    64    30   144    64)\n"," group in loop \n","data(filename='Good153.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","320  Good153.jpg    300     168  Good     1    27    57   135\n","321  Good153.jpg    300     168  Good    40    25   125   168\n","322  Good153.jpg    300     168  Good    83    23   160   166\n","323  Good153.jpg    300     168  Good   140    26   184   113\n","324  Good153.jpg    300     168  Good   161    27   200   114\n","325  Good153.jpg    300     168  Good   184    24   239    85\n","326  Good153.jpg    300     168  Good   222    24   261   100\n","327  Good153.jpg    300     168  Good   243    19   286   140\n","328  Good153.jpg    300     168  Good   253     9   295   140)\n"," group in loop \n","data(filename='Good155.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","36  Good155.jpg    310     162  Good    67    35   274   162)\n"," group in loop \n","data(filename='Good156.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","102  Good156.jpg    285     177  Good    47    40   237   142)\n"," group in loop \n","data(filename='Good157.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","88  Good157.jpg    300     168  Good    30     2   257   168)\n"," group in loop \n","data(filename='Good158.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1134  Good158.jpg    259     194  Good     1    51   167   118\n","1135  Good158.jpg    259     194  Good   150    51   247   158)\n"," group in loop \n","data(filename='Good16.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1100  Good16.jpg    642     338  Good   136   106   566   268)\n"," group in loop \n","data(filename='Good160.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1022  Good160.jpg    275     183  Good    23    61   119   179\n","1023  Good160.jpg    275     183  Good    99    70   158   149\n","1024  Good160.jpg    275     183  Good   139    70   190   137\n","1025  Good160.jpg    275     183  Good   173    75   210   126\n","1026  Good160.jpg    275     183  Good   193    75   225   120\n","1027  Good160.jpg    275     183  Good   213    75   238   115\n","1028  Good160.jpg    275     183  Good   228    75   247   112)\n"," group in loop \n","data(filename='Good161.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1001  Good161.jpg    259     194  Good     1    35    42    80\n","1002  Good161.jpg    259     194  Good     9    37   142   182\n","1003  Good161.jpg    259     194  Good    93    37   150   183\n","1004  Good161.jpg    259     194  Good   135    43   205    95)\n"," group in loop \n","data(filename='Good163.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","853  Good163.jpg    275     183  Good    28    35   133   169\n","854  Good163.jpg    275     183   Bad   207    27   266   111\n","855  Good163.jpg    275     183  Good    67    26   266   132)\n"," group in loop \n","data(filename='Good164.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1137  Good164.jpg    275     183   Bad    50    80   111   183\n","1138  Good164.jpg    275     183   Bad    89    99   170   183)\n"," group in loop \n","data(filename='Good166.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1098  Good166.jpg    259     194  Good    56    42   234   130\n","1099  Good166.jpg    259     194  Good     2    35    92    89)\n"," group in loop \n","data(filename='Good167.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1084  Good167.jpg    263     192  Good    14    68   241   169)\n"," group in loop \n","data(filename='Good168.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","9  Good168.jpg    317     159  Good    43    41   278   159)\n"," group in loop \n","data(filename='Good169.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","46  Good169.jpg    265     190  Good    18    43   255   164)\n"," group in loop \n","data(filename='Good17.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1101  Good17.jpg    279     260  Good    56    43   230   203)\n"," group in loop \n","data(filename='Good171.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1156  Good171.jpg    600     450  Good   141   228   468   422)\n"," group in loop \n","data(filename='Good172.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1089  Good172.jpg    277     182  Good     2    87    80   149\n","1090  Good172.jpg    277     182  Good    68    85   129   134\n","1091  Good172.jpg    277     182  Good   113    85   163   126\n","1092  Good172.jpg    277     182  Good   152    85   187   119\n","1093  Good172.jpg    277     182  Good   175    80   198   112\n","1094  Good172.jpg    277     182  Good   190    81   207   110\n","1095  Good172.jpg    277     182  Good   199    82   232   119\n","1096  Good172.jpg    277     182  Good   212    82   232   119)\n"," group in loop \n","data(filename='Good174.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1012  Good174.jpg    259     194  Good    21    30   103   119\n","1013  Good174.jpg    259     194  Good    76    43   180   150\n","1014  Good174.jpg    259     194  Good   149    41   215   150\n","1015  Good174.jpg    259     194  Good   200    41   256   194\n","1016  Good174.jpg    259     194  Good   150    42   257   192)\n"," group in loop \n","data(filename='Good175.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","998  Good175.jpg    275     183  Good    29    26   201   167)\n"," group in loop \n","data(filename='Good176.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","848  Good176.jpg    275     183  Good    19    34   247   167)\n"," group in loop \n","data(filename='Good177.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","851  Good177.jpg    259     194  Good    35    89   222   153)\n"," group in loop \n","data(filename='Good178.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","196  Good178.jpg    318     159  Good    42    34   137   119\n","197  Good178.jpg    318     159  Good    90    16   192    96\n","198  Good178.jpg    318     159  Good   157    13   230    74\n","199  Good178.jpg    318     159  Good   205    13   252    52\n","200  Good178.jpg    318     159  Good    90    34   261   159)\n"," group in loop \n","data(filename='Good179.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","182  Good179.jpg    275     183  Good    29    42   142    80\n","183  Good179.jpg    275     183  Good   104    42   214    81\n","184  Good179.jpg    275     183  Good    10    92   142   148\n","185  Good179.jpg    275     183  Good    96    93   244   154\n","186  Good179.jpg    275     183  Good    10    40    52   146\n","187  Good179.jpg    275     183  Good    96    42   144   155\n","188  Good179.jpg    275     183  Good   186    42   244   154)\n"," group in loop \n","data(filename='Good18.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","26  Good18.jpg    572     295  Good    62    48   426   246)\n"," group in loop \n","data(filename='Good180.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","76  Good180.jpg    275     183  Good    13    92   222   141)\n"," group in loop \n","data(filename='Good181.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","109  Good181.jpg    275     183  Good    21   111   117   179\n","110  Good181.jpg    275     183  Good    93   117   216   179)\n"," group in loop \n","data(filename='Good182.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","37  Good182.jpg    275     183  Good    68    89   207   128\n","38  Good182.jpg    275     183  Good     1   117   274   175\n","39  Good182.jpg    275     183  Good     1    89   105   178\n","40  Good182.jpg    275     183  Good   179    89   275   156)\n"," group in loop \n","data(filename='Good183.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","20  Good183.jpg    310     163  Good   126    33   206    97)\n"," group in loop \n","data(filename='Good184.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","332  Good184.jpg    275     183  Good    35    66   145   161\n","333  Good184.jpg    275     183  Good    29    75   109   147\n","334  Good184.jpg    275     183  Good    92    65   146   162\n","335  Good184.jpg    275     183  Good   119    65   181   161\n","336  Good184.jpg    275     183  Good   157    71   230   129\n","337  Good184.jpg    275     183  Good   214    68   267   117)\n"," group in loop \n","data(filename='Good185.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","283  Good185.jpg    272     185  Good    11    92    45   137\n","284  Good185.jpg    272     185  Good    24    85   108   146\n","285  Good185.jpg    272     185  Good    83    86   108   146\n","286  Good185.jpg    272     185  Good    89    78   162   152\n","287  Good185.jpg    272     185  Good   141    63   254   139)\n"," group in loop \n","data(filename='Good186.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","163  Good186.jpg    287     176  Good    27    54   130   168\n","164  Good186.jpg    287     176  Good   106    54   206   157\n","165  Good186.jpg    287     176  Good   167    62   275   160)\n"," group in loop \n","data(filename='Good187.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","207  Good187.jpg    270     187  Good    57    88   139   158\n","208  Good187.jpg    270     187  Good    15    87    74   187\n","209  Good187.jpg    270     187  Good   120    86   162   157\n","210  Good187.jpg    270     187  Good   146    90   255   187\n","211  Good187.jpg    270     187  Good   143    85   215   187)\n"," group in loop \n","data(filename='Good188.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","866  Good188.jpg    275     183  Good    39    40   147   179\n","867  Good188.jpg    275     183  Good   141    36   259   109\n","868  Good188.jpg    275     183  Good    38    36   172   183\n","869  Good188.jpg    275     183  Good    67    50   260   178)\n"," group in loop \n","data(filename='Good189.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1060  Good189.jpg   3000    2000  Good   337    67  2916  1967)\n"," group in loop \n","data(filename='Good190.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","347  Good190.jpg    300     168  Good    67    14   249   158)\n"," group in loop \n","data(filename='Good192.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","167  Good192.jpg    259     194  Good    58    43   152   126\n","168  Good192.jpg    259     194  Good   136     4   235   150)\n"," group in loop \n","data(filename='Good193.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","221  Good193.jpg    301     168  Good    38    21   229   100\n","222  Good193.jpg    301     168  Good    39    20   160    97\n","223  Good193.jpg    301     168  Good   135    23   223   109)\n"," group in loop \n","data(filename='Good194.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","82  Good194.jpg    290     174  Good    29    33   106   161\n","83  Good194.jpg    290     174  Good   138    28   215   161\n","84  Good194.jpg    290     174  Good    39    33   213   161)\n"," group in loop \n","data(filename='Good195.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","118  Good195.jpg    275     183  Good     8    38   127    88\n","119  Good195.jpg    275     183  Good    88    42   155    87\n","120  Good195.jpg    275     183  Good   138    40   275   115)\n"," group in loop \n","data(filename='Good197.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","18  Good197.jpg    275     183  Good     1    41   257   162)\n"," group in loop \n","data(filename='Good198.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1073  Good198.jpg    269     187  Good    33    28   144   182\n","1074  Good198.jpg    269     187  Good   105    27   216    97\n","1075  Good198.jpg    269     187  Good   185    61   264   130)\n"," group in loop \n","data(filename='Good199.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1097  Good199.jpg    318     159  Good    35     1   285   127)\n"," group in loop \n","data(filename='Good2.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","352  Good2.jpg    442     335  Good   120    92   310   289)\n"," group in loop \n","data(filename='Good20.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","191  Good20.jpg    589     338  Good   106   121   456   317)\n"," group in loop \n","data(filename='Good200.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1053  Good200.jpg    259     194  Good    90    54   209   194)\n"," group in loop \n","data(filename='Good202.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1046  Good202.jpg    312     162  Good   145    25   183    68\n","1047  Good202.jpg    312     162   Bad    61    40    80    79\n","1048  Good202.jpg    312     162  Good   151     7   280   159)\n"," group in loop \n","data(filename='Good203.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","981  Good203.jpg    275     183  Good   139    87   182   183\n","982  Good203.jpg    275     183  Good    70    86   162   125\n","983  Good203.jpg    275     183  Good    72   105   182   183)\n"," group in loop \n","data(filename='Good205.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1066  Good205.jpg    275     183  Good    16     7   113    75\n","1067  Good205.jpg    275     183  Good    73     7   182   183)\n"," group in loop \n","data(filename='Good207.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1157  Good207.jpg    275     183  Good   128    60   229   126\n","1158  Good207.jpg    275     183  Good    53    68   146   104)\n"," group in loop \n","data(filename='Good208.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","124  Good208.jpg    300     168  Good   111    57   161   157\n","125  Good208.jpg    300     168  Good   140    55   230   168\n","126  Good208.jpg    300     168  Good    16    16   142   166\n","127  Good208.jpg    300     168  Good    22    20   229   137)\n"," group in loop \n","data(filename='Good209.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","68  Good209.jpg    275     183  Good    59    32   242   110)\n"," group in loop \n","data(filename='Good211.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1068  Good211.jpg    300     168  Good    92     8   209   168\n","1069  Good211.jpg    300     168  Good   131     9   267   168)\n"," group in loop \n","data(filename='Good212.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1126  Good212.jpg    275     183  Good    94    48   172   182\n","1127  Good212.jpg    275     183  Good   147    97   215   134)\n"," group in loop \n","data(filename='Good214.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1037  Good214.jpg    276     183  Good    77    71   182   127)\n"," group in loop \n","data(filename='Good215.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","886  Good215.jpg   1000     750  Good   210   247   432   404\n","887  Good215.jpg   1000     750  Good   369   242   588   333\n","888  Good215.jpg   1000     750  Good   522   237   700   338\n","889  Good215.jpg   1000     750  Good   641   244   841   381)\n"," group in loop \n","data(filename='Good216.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1034  Good216.jpg    262     192  Good    92    13   207   166)\n"," group in loop \n","data(filename='Good217.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","985  Good217.jpg    275     183  Good    64    90   244   152\n","986  Good217.jpg    275     183   Bad   133   104   154   134)\n"," group in loop \n","data(filename='Good218.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","272  Good218.jpg   1024     684  Good   280   174   532   371)\n"," group in loop \n","data(filename='Good221.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","85  Good221.jpg    900     600  Good    91   228   447   599)\n"," group in loop \n","data(filename='Good222.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","6  Good222.jpg    300     168  Good     4    59   292   167)\n"," group in loop \n","data(filename='Good224.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","281  Good224.jpg    730     410  Good   102    43   457   410\n","282  Good224.jpg    730     410  Good   345    42   698   410)\n"," group in loop \n","data(filename='Good225.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","152  Good225.jpg    512     333  Good    68   123   431   311)\n"," group in loop \n","data(filename='Good226.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","228  Good226.jpg    450     300  Good    43   105   219   242\n","229  Good226.jpg    450     300  Good   182   105   278   240\n","230  Good226.jpg    450     300  Good   249   104   346   243\n","231  Good226.jpg    450     300  Good   310    93   436   244)\n"," group in loop \n","data(filename='Good227.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","156  Good227.jpg    728     489  Good    61   255   368   434\n","157  Good227.jpg    728     489  Good   319   254   643   430)\n"," group in loop \n","data(filename='Good228.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1039  Good228.jpg    640     454  Good    85    50   486   415)\n"," group in loop \n","data(filename='Good229.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","876  Good229.jpg   1200     800  Good   126    44   962   649\n","877  Good229.jpg   1200     800  Good   810    42  1200   508)\n"," group in loop \n","data(filename='Good23.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","309  Good23.jpg    254     199     Good    23    43   151   193\n","310  Good23.jpg    254     199  Caution    23    10   227   171\n","311  Good23.jpg    254     199     Good   110    12   223   199)\n"," group in loop \n","data(filename='Good232.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","217  Good232.jpg    410     292  Good    50    50   342   220)\n"," group in loop \n","data(filename='Good233.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","169  Good233.jpg    606     482  Good    22    42   581   459)\n"," group in loop \n","data(filename='Good234.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","128  Good234.jpg   1190     468  Good    31    61  1190   462)\n"," group in loop \n","data(filename='Good235.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","67  Good235.jpg    696     404  Good    85    50   628   370)\n"," group in loop \n","data(filename='Good237.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","49  Good237.jpg    624     360  Good    52    53   598   337)\n"," group in loop \n","data(filename='Good238.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1113  Good238.jpg    576     198  Good    41    33   541   198)\n"," group in loop \n","data(filename='Good239.jpg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","1071  Good239.jpg    934     604  Good    61    52   855   456)\n"," group in loop \n","data(filename='Good24.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","24  Good24.jpg    297     170  Good    54    18   259   170)\n"," group in loop \n","data(filename='Good240.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","366  Good240.jpg    866     560  Good    22    55   337   426\n","367  Good240.jpg    866     560  Good   167    95   337   252\n","368  Good240.jpg    866     560  Good   249    13   791   560)\n"," group in loop \n","data(filename='Good241.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","473  Good241.jpg    676     552  Good    27    78   607   519\n","474  Good241.jpg    676     552  Good    27    80   398   519)\n"," group in loop \n","data(filename='Good242.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","390  Good242.jpg    626     426  Good    43    78   571   251)\n"," group in loop \n","data(filename='Good243.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","245  Good243.jpg    890     518  Good    58    56   860   470)\n"," group in loop \n","data(filename='Good244.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","552  Good244.jpg    888     804  Good    11    17   870   788)\n"," group in loop \n","data(filename='Good245.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","458  Good245.jpg    400     318  Good    45    15   329   147\n","459  Good245.jpg    400     318  Good     9   148   347   310\n","460  Good245.jpg    400     318  Good     7    14   108   318\n","461  Good245.jpg    400     318  Good   268    14   348   312)\n"," group in loop \n","data(filename='Good246.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","540  Good246.jpg   1112     780  Good     4    29  1093   727)\n"," group in loop \n","data(filename='Good247.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","641  Good247.jpg    986     642  Good     5    33   965   561)\n"," group in loop \n","data(filename='Good248.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","832  Good248.jpg    282     292  Good    40    37   264   288)\n"," group in loop \n","data(filename='Good249.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","739  Good249.jpg   1102     538  Good    23     7  1073   538)\n"," group in loop \n","data(filename='Good250.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","563  Good250.jpg    638     422  Good    87    11   607   409)\n"," group in loop \n","data(filename='Good252.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","542  Good252.jpg    866     578  Good   105    30   663   351)\n"," group in loop \n","data(filename='Good26.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","105  Good26.jpg    272     185     Good    11    13   195   154\n","106  Good26.jpg    272     185  Caution   146    10   239   120)\n"," group in loop \n","data(filename='Good261.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","744  Good261.jpg    299     168  Good    21     1   267   103)\n"," group in loop \n","data(filename='Good262.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","622  Good262.jpg   1024     768  Caution    24   349   289   538\n","623  Good262.jpg   1024     768     Good   204   347   808   538\n","624  Good262.jpg   1024     768  Caution   659   318  1011   624)\n"," group in loop \n","data(filename='Good263.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","767  Good263.jpg    279     180  Good    85    68   257   177)\n"," group in loop \n","data(filename='Good265.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","966  Good265.jpg    275     183  Good     9    47   248   110)\n"," group in loop \n","data(filename='Good266.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","902  Good266.jpg    259     194  Caution    11    69    86   102\n","903  Good266.jpg    259     194  Caution    57    69   150   155\n","904  Good266.jpg    259     194     Good   126    74   249   156)\n"," group in loop \n","data(filename='Good267.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","940  Good267.jpg    287     176  Good    27    27   186    77)\n"," group in loop \n","data(filename='Good269.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","484  Good269.jpg    310     163  Good    93    35   191    97)\n"," group in loop \n","data(filename='Good27.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","89  Good27.jpg    284     177  Caution    61    30   188   163\n","90  Good27.jpg    284     177  Caution   123    22   283   177)\n"," group in loop \n","data(filename='Good270.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","819  Good270.jpg    259     194  Good     3    24   193   181)\n"," group in loop \n","data(filename='Good271.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","960  Good271.jpg    300     168  Good    20    21   280   168)\n"," group in loop \n","data(filename='Good273.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","939  Good273.jpg    411     123  Good   150     1   376   123)\n"," group in loop \n","data(filename='Good276.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","635  Good276.jpg    275     183  Good    36    46   233   167)\n"," group in loop \n","data(filename='Good279.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","464  Good279.jpg    296     170  Good    22    16   156   107\n","465  Good279.jpg    296     170  Good   128    15   208   134\n","466  Good279.jpg    296     170  Good   163    11   286   134)\n"," group in loop \n","data(filename='Good28.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","1132  Good28.jpg    324     155     Good     1     1   272   134\n","1133  Good28.jpg    324     155  Caution   167     1   324   155)\n"," group in loop \n","data(filename='Good281.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","382  Good281.jpg    275     183  Good   127    23   235   183)\n"," group in loop \n","data(filename='Good282.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","481  Good282.jpg    350     233  Good     6    28   350   233)\n"," group in loop \n","data(filename='Good283.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","381  Good283.jpg    600     398  Good    38   107   565   373)\n"," group in loop \n","data(filename='Good284.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","640  Good284.jpg    294     171  Good    89    49   217   141)\n"," group in loop \n","data(filename='Good29.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","1146  Good29.jpg    300     168     Good    63     1   231   168\n","1147  Good29.jpg    300     168  Caution   237     5   298   158\n","1148  Good29.jpg    300     168     Good   191     2   300   166)\n"," group in loop \n","data(filename='Good3.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","493  Good3.jpg    248     334  Good    35   128   235   323)\n"," group in loop \n","data(filename='Good30.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","21  Good30.jpg    285     177  Good     1    55   117   116\n","22  Good30.jpg    285     177  Good    80    55   181   116\n","23  Good30.jpg    285     177  Good   153    55   280   102)\n"," group in loop \n","data(filename='Good31.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","35  Good31.jpg    318     159  Caution    65    16   282   130)\n"," group in loop \n","data(filename='Good32.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","95  Good32.jpg    300     168  Caution    45    13    91   155\n","96  Good32.jpg    300     168     Good    53    34   146   154\n","97  Good32.jpg    300     168     Good    51    33   263   168\n","98  Good32.jpg    300     168     Good   121    37   261   168)\n"," group in loop \n","data(filename='Good34.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","203  Good34.jpg    259     194  Good    21    23   227   132)\n"," group in loop \n","data(filename='Good35.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","176  Good35.jpg    275     183  Caution    49    40   208   152)\n"," group in loop \n","data(filename='Good37.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","304  Good37.jpg    259     194     Good     1    44    79   155\n","305  Good37.jpg    259     194  Caution    58    49   113    76\n","306  Good37.jpg    259     194  Caution    90    59   200   183\n","307  Good37.jpg    259     194  Caution   161    62   255   182)\n"," group in loop \n","data(filename='Good39.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","1006  Good39.jpg    313     161  Good     7     6   288   161)\n"," group in loop \n","data(filename='Good40.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","687  Good40.jpg    236     214  Good    28    50   204   205)\n"," group in loop \n","data(filename='Good42.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","588  Good42.jpg    284     178  Caution     2    62   123   126\n","589  Good42.jpg    284     178  Caution    90    75   176   119\n","590  Good42.jpg    284     178      Bad   153    75   212   114)\n"," group in loop \n","data(filename='Good45.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","410  Good45.jpg    279     181  Good     7    40   172   178\n","411  Good45.jpg    279     181  Good   181    39   276   155\n","412  Good45.jpg    279     181  Good    68    44   255   181)\n"," group in loop \n","data(filename='Good47.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","499  Good47.jpg    282     179  Caution    25     8   259   179)\n"," group in loop \n","data(filename='Good48.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","910  Good48.jpg    275     183  Good    27    35   137   183\n","911  Good48.jpg    275     183  Good    98    33   244   180\n","912  Good48.jpg    275     183  Good    27    58   243   181)\n"," group in loop \n","data(filename='Good53.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","496  Good53.jpg    252     200  Good    15    72   233   200)\n"," group in loop \n","data(filename='Good57.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","447  Good57.jpg    303     166  Good    10    40   178   105\n","448  Good57.jpg    303     166  Good   145    41   300   126)\n"," group in loop \n","data(filename='Good59.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","785  Good59.jpg    299     168  Good    60    49   267   122)\n"," group in loop \n","data(filename='Good6.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","578  Good6.jpg    458     350  Good   110    79   416   298)\n"," group in loop \n","data(filename='Good62.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","799  Good62.jpg    288     175  Caution     5    83    93   173\n","800  Good62.jpg    288     175  Caution    76    75   144   109)\n"," group in loop \n","data(filename='Good66.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","703  Good66.jpg    293     172  Good    23    22   229   137)\n"," group in loop \n","data(filename='Good67.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","726  Good67.jpg    758     450  Good   126   111   627   411)\n"," group in loop \n","data(filename='Good69.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","682  Good69.jpg    738     502  Good    60    23   724   466)\n"," group in loop \n","data(filename='Good7.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","441  Good7.jpg    447     339  Caution   131    86   403   298)\n"," group in loop \n","data(filename='Good70.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","787  Good70.jpg    720     540  Good    57    41   720   536)\n"," group in loop \n","data(filename='Good71.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","781  Good71.jpg    574     450  Good   225   150   385   384\n","782  Good71.jpg    574     450  Good   346    67   574   441)\n"," group in loop \n","data(filename='Good72.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","695  Good72.jpg    638     486      Bad    94   128   295   485\n","696  Good72.jpg    638     486     Good   195   138   430   474\n","697  Good72.jpg    638     486  Caution   349   164   511   451\n","698  Good72.jpg    638     486     Good   424   183   568   408\n","699  Good72.jpg    638     486  Caution   528   204   594   367\n","700  Good72.jpg    638     486  Caution   573   212   635   353)\n"," group in loop \n","data(filename='Good75.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","931  Good75.jpg    656     494  Good    18    89   435   491\n","932  Good75.jpg    656     494  Good   309   100   656   487)\n"," group in loop \n","data(filename='Good76.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","801  Good76.jpg    798     530  Good   171   194   414   394\n","802  Good76.jpg    798     530  Good   339   183   536   346\n","803  Good76.jpg    798     530  Good   477   204   608   337)\n"," group in loop \n","data(filename='Good77.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","788  Good77.jpg    846     582  Good    96   112   773   582)\n"," group in loop \n","data(filename='Good78.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","398  Good78.jpg    666     424  Good   156     3   627   394)\n"," group in loop \n","data(filename='Good79.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","415  Good79.jpg    810     452  Good    88   162   390   375\n","416  Good79.jpg    810     452  Good   320   162   557   379\n","417  Good79.jpg    810     452  Good   508   136   750   380)\n"," group in loop \n","data(filename='Good80.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","582  Good80.jpg    766     430  Caution     5    17   462   422\n","583  Good80.jpg    766     430  Caution   333    35   753   430)\n"," group in loop \n","data(filename='Good83.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","690  Good83.jpg    944     570  Caution   103    33   224   511\n","691  Good83.jpg    944     570     Good   507     2   924   536\n","692  Good83.jpg    944     570     Good   126     1   742   527\n","693  Good83.jpg    944     570     Good   113   114   924   540)\n"," group in loop \n","data(filename='Good84.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","500  Good84.jpg   1200     706  Caution   148    16  1081   683)\n"," group in loop \n","data(filename='Good85.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","512  Good85.jpg    710     542  Good   154    32   679   427)\n"," group in loop \n","data(filename='Good86.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","413  Good86.jpg   1240     826   Bad   880   270  1232   826\n","414  Good86.jpg   1240     826  Good    98   276  1080   777)\n"," group in loop \n","data(filename='Good87.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","395  Good87.jpg    615     461  Good    17    79   586   448)\n"," group in loop \n","data(filename='Good88.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","798  Good88.jpg    615     410  Good    77    34   534   410)\n"," group in loop \n","data(filename='Good89.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","792  Good89.jpg   1200     630  Good     1    21  1178   596)\n"," group in loop \n","data(filename='Good9.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","768  Good9.jpg    627     335  Good   221    68   435   320)\n"," group in loop \n","data(filename='Good92.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","424  Good92.jpg    911     683  Good   141   319   618   593)\n"," group in loop \n","data(filename='Good94.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","581  Good94.jpg   1200     819  Good   113    75   744   768)\n"," group in loop \n","data(filename='Good95.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","594  Good95.jpg   1600     900  Good    23   167  1495   892\n","595  Good95.jpg   1600     900  Good   773   142  1480   883\n","596  Good95.jpg   1600     900  Good    50   207   915   892\n","597  Good95.jpg   1600     900  Good    65   250   479   900)\n"," group in loop \n","data(filename='Good96.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","514  Good96.jpg    700     421  Good   135    23   646   421)\n"," group in loop \n","data(filename='Good98.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","709  Good98.jpg    275     183  Good    17    61   142   159\n","710  Good98.jpg    275     183  Good   113    64   261   161)\n"," group in loop \n","data(filename='Goodimages at 1.41.34 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","702  Goodimages at 1.41.34 PM.jpg    674     406  Good    31    85   643   230)\n"," group in loop \n","data(filename='Goodimages at 1.42.06 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","346  Goodimages at 1.42.06 PM.jpg    610     486  Good    92    70   491   431)\n"," group in loop \n","data(filename='Goodimages at 1.42.17 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","831  Goodimages at 1.42.17 PM.jpg    442     480  Good    32    19   438   431)\n"," group in loop \n","data(filename='Goodimages at 1.43.32 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","400  Goodimages at 1.43.32 PM.jpg    422     340  Good    25    30   363   340)\n"," group in loop \n","data(filename='Goodimages at 1.45.39 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","794  Goodimages at 1.45.39 PM.jpg    680     464  Good    35    56   669   393)\n"," group in loop \n","data(filename='Goodimages at 1.55.05 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","354  Goodimages at 1.55.05 PM.jpg    664     366  Good     1    64   637   246)\n"," group in loop \n","data(filename='Goodimages at 10.50.47 AM.jpg', object=                           filename  width  height  ... ymin  xmax  ymax\n","1117  Goodimages at 10.50.47 AM.jpg    620     322  ...   61   587   313\n","\n","[1 rows x 8 columns])\n"," group in loop \n","data(filename='Goodimages at 10.54.32 AM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","303  Goodimages at 10.54.32 AM.jpg    446     348  Good    22    25   402   348)\n"," group in loop \n","data(filename='Goodimages at 10.54.57 AM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","462  Goodimages at 10.54.57 AM.jpg    292     276  Good    34    49   287   244)\n"," group in loop \n","data(filename='Goodimages at 10.56.04 AM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","897  Goodimages at 10.56.04 AM.jpg    824     776  Good    43     1   824   766)\n"," group in loop \n","data(filename='Goodimages at 11.04.53 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","44  Goodimages at 11.04.53 AM.jpg    604     380  Good    41    18   588   380)\n"," group in loop \n","data(filename='Goodimages at 11.05.08 AM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","591  Goodimages at 11.05.08 AM.jpg    518     388  Good    24    19   512   388)\n"," group in loop \n","data(filename='Goodimages at 11.31.18 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","47  Goodimages at 11.31.18 AM.jpg    634     452  Good    41    24   626   441)\n"," group in loop \n","data(filename='Goodimages at 3.02.31 PM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","1030  Goodimages at 3.02.31 PM.jpg    606     436  Good    38    21   606   436)\n"," group in loop \n","data(filename='Goodimages at 3.02.42 PM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","1166  Goodimages at 3.02.42 PM.jpg    698     326  Good    40    36   667   326)\n"," group in loop \n","data(filename='Goodimages at 3.03.57 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","445  Goodimages at 3.03.57 PM.jpg    868     484  Good    47     1   784   484)\n"," group in loop \n","data(filename='Goodimages at 3.04.10 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","122  Goodimages at 3.04.10 PM.jpg    676     492  Good    66   175   316   492\n","123  Goodimages at 3.04.10 PM.jpg    676     492  Good   286    64   659   492)\n"," group in loop \n","data(filename='Goodimages at 3.06.31 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","515  Goodimages at 3.06.31 PM.jpg    558     414  Good    72    80   537   414)\n"," group in loop \n","data(filename='Goodimages at 3.07.26 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","879  Goodimages at 3.07.26 PM.jpg    470     386  Good     5    65   412   362)\n"," group in loop \n","data(filename='Goodimages at 3.08.27 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","881  Goodimages at 3.08.27 PM.jpg    552     434  Good    33    48   501   266)\n"," group in loop \n","data(filename='Goodimages at 3.08.50 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","827  Goodimages at 3.08.50 PM.jpg    708     466  Good    72    60   684   461)\n"," group in loop \n","data(filename='Goodimages at 3.09.01 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","914  Goodimages at 3.09.01 PM.jpg    522     404  Good    61    38   499   360)\n"," group in loop \n","data(filename='Goodimages at 3.10.21 PM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","1057  Goodimages at 3.10.21 PM.jpg    682     450  Good   114   142   569   411)\n"," group in loop \n","data(filename='Goodimages at 3.11.47 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","675  Goodimages at 3.11.47 PM.jpg    826     492  Good    95    83   728   249)\n"," group in loop \n","data(filename='Goodimages at 3.12.56 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","233  Goodimages at 3.12.56 PM.jpg   1134     470  Good    46    37  1116   458)\n"," group in loop \n","data(filename='Goodimages at 3.14.53 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","870  Goodimages at 3.14.53 PM.jpg    674     326  Good    42    64   652   188)\n"," group in loop \n","data(filename='Goodimages at 3.14.59 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","833  Goodimages at 3.14.59 PM.jpg    670     272  Good    13    20   656   271)\n"," group in loop \n","data(filename='Goodimages at 3.15.05 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","195  Goodimages at 3.15.05 PM.jpg    620     416  Good     1    38   619   416)\n"," group in loop \n","data(filename='Goodimages at 3.15.10 PM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","1169  Goodimages at 3.15.10 PM.jpg    658     332  Good    13    34   585   297)\n"," group in loop \n","data(filename='Goodimages at 3.15.33 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","177  Goodimages at 3.15.33 PM.jpg    592     414  Good    80    27   573   414)\n"," group in loop \n","data(filename='Goodimages at 3.17.09 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","979  Goodimages at 3.17.09 PM.jpg    590     460  Good    65    48   520   437)\n"," group in loop \n","data(filename='Goodimages at 3.17.27 PM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","1070  Goodimages at 3.17.27 PM.jpg    600     360  Good    43    53   574   317)\n"," group in loop \n","data(filename='Goodimages at 3.32.59 PM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","1072  Goodimages at 3.32.59 PM.jpg   1088     446  Good    58    75  1060   324)\n"," group in loop \n","data(filename='Goodimages at 3.33.52 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","644  Goodimages at 3.33.52 PM.jpg    586     422  Good    81    37   566   422)\n"," group in loop \n","data(filename='Goodimages at 3.33.58 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","216  Goodimages at 3.33.58 PM.jpg    638     478  Good     4     3   638   478)\n"," group in loop \n","data(filename='Goodimages at 3.34.38 PM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","1167  Goodimages at 3.34.38 PM.jpg    452     290  Good    20    36   398   246)\n"," group in loop \n","data(filename='Goodimages at 3.34.43 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","909  Goodimages at 3.34.43 PM.jpg    486     298  Good    53    26   466   260)\n"," group in loop \n","data(filename='Goodimages at 3.39.01 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","351  Goodimages at 3.39.01 PM.jpg    604     342  Good    56    45   541   328)\n"," group in loop \n","data(filename='Goodimages at 3.40.19 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","882  Goodimages at 3.40.19 PM.jpg    920     494  Good   129    28   873   489)\n"," group in loop \n","data(filename='Goodimages at 3.56.32 PM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","1124  Goodimages at 3.56.32 PM.jpg    742     500  Good     9     1   699   500)\n"," group in loop \n","data(filename='Goodimages at 3.57.37 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","488  Goodimages at 3.57.37 PM.jpg    588     434  Good   109    61   539   406)\n"," group in loop \n","data(filename='Goodimages at 3.57.46 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","498  Goodimages at 3.57.46 PM.jpg    548     414  Good    75    57   508   409)\n"," group in loop \n","data(filename='Goodimages at 3.59.42 PM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","1136  Goodimages at 3.59.42 PM.jpg    676     338  Good     6    31   596   338)\n"," group in loop \n","data(filename='Goodimages at 4.02.42 PM.jpg', object=                          filename  width  height class  xmin  ymin  xmax  ymax\n","1149  Goodimages at 4.02.42 PM.jpg    892     460  Good    38   132   887   460)\n"," group in loop \n","data(filename='Goodimages at 4.03.10 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","567  Goodimages at 4.03.10 PM.jpg    784     476  Good    77    87   720   476)\n"," group in loop \n","data(filename='Goodimages at 4.47.21 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","735  Goodimages at 4.47.21 PM.jpg    826     370  Good    46    49   826   368)\n"," group in loop \n","data(filename='Goodimages at 4.49.57 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","772  Goodimages at 4.49.57 PM.jpg    600     400  Good    30    33   592   400)\n"," group in loop \n","data(filename='Goodimages at 4.53.56 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","859  Goodimages at 4.53.56 PM.jpg    582     310  Good     7     5   526   303)\n"," group in loop \n","data(filename='Goodimages at 8.10.05 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","736  Goodimages at 8.10.05 PM.jpg    940     766  Good    18    81   929   691)\n","Successfully created the TFRecords: /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/train_labels.record\n",".........going to save TFRecord to /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/test_labels.record\n","/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/test_labels.csv\n"," group in loop \n","data(filename='Bad111.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","178  Bad111.jpg    275     183   Bad    46     9   223   183)\n"," group in loop \n","data(filename='Bad113.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","188  Bad113.jpg    283     178   Bad   132    90   185   170)\n"," group in loop \n","data(filename='Bad123.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","174  Bad123.jpg    562     373   Bad   231    80   495   332)\n"," group in loop \n","data(filename='Bad128.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","191  Bad128.jpg    275     183   Bad   129     5   231   172)\n"," group in loop \n","data(filename='Bad134.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","161  Bad134.jpg    686     526   Bad   455   174   676   494)\n"," group in loop \n","data(filename='Bad138.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","180  Bad138.jpg    730     487   Bad   153   202   326   431)\n"," group in loop \n","data(filename='Bad143.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","58  Bad143.jpg    318     127   Bad    64     3   270   127)\n"," group in loop \n","data(filename='Bad16.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","258  Bad16.jpg    259     195   Bad    52    30   196   194)\n"," group in loop \n","data(filename='Bad161.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","257  Bad161.jpg    200     149   Bad     1     1   200   149)\n"," group in loop \n","data(filename='Bad166.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","240  Bad166.jpg    246     205   Bad     1     9   245   205)\n"," group in loop \n","data(filename='Bad170.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","206  Bad170.jpg    259     194   Bad     1    39   178   194\n","207  Bad170.jpg    259     194   Bad   108    46   259   194)\n"," group in loop \n","data(filename='Bad188.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","266  Bad188.jpg    275     183   Bad     1     1   275   183)\n"," group in loop \n","data(filename='Bad189.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","268  Bad189.jpg    307     164   Bad    15     1   307   164)\n"," group in loop \n","data(filename='Bad190.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","13  Bad190.jpg    297     170   Bad     1     1   192   122\n","14  Bad190.jpg    297     170   Bad    91     1   285   170)\n"," group in loop \n","data(filename='Bad194.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","61  Bad194.jpg    320     158   Bad    35     2   272   158)\n"," group in loop \n","data(filename='Bad205.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","244  Bad205.jpg    299     168   Bad    24     1   277   168)\n"," group in loop \n","data(filename='Bad219.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","2  Bad219.jpg    259     194   Bad     1     4   259   194)\n"," group in loop \n","data(filename='Bad223.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","72  Bad223.jpg    259     194   Bad    14    32   258   194)\n"," group in loop \n","data(filename='Bad228.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","273  Bad228.jpg    300     168   Bad     7     8   201   168\n","274  Bad228.jpg    300     168   Bad   111     9   289   168)\n"," group in loop \n","data(filename='Bad239.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","245  Bad239.jpg    273     184   Bad    11     5   273   184)\n"," group in loop \n","data(filename='Bad247.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","91  Bad247.jpg    286     176   Bad     5     2   286   176)\n"," group in loop \n","data(filename='Bad248.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","220  Bad248.jpg    259     194   Bad    26     4   246   194)\n"," group in loop \n","data(filename='Bad25.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","27  Bad25.jpg    225     225   Bad    11    10   195   224)\n"," group in loop \n","data(filename='Bad251.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","105  Bad251.jpg    275     183   Bad    18     1   232   183)\n"," group in loop \n","data(filename='Bad252.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","136  Bad252.jpg    259     194   Bad     1     1   259   194)\n"," group in loop \n","data(filename='Bad266.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","182  Bad266.jpg    275     183   Bad   137    37   245    88)\n"," group in loop \n","data(filename='Bad279.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","101  Bad279.jpg    260     194   Bad     4    39   238   194)\n"," group in loop \n","data(filename='Bad281.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","119  Bad281.jpg    225     225   Bad    20     2   207   225)\n"," group in loop \n","data(filename='Bad282.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","150  Bad282.jpg    209     241   Bad    66    24   183   237)\n"," group in loop \n","data(filename='Bad284.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","93  Bad284.jpg    258     195   Bad    53     9   147   195\n","94  Bad284.jpg    258     195   Bad    99     1   207   191)\n"," group in loop \n","data(filename='Bad286.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","102  Bad286.jpg    275     183   Bad    46    41   144   165\n","103  Bad286.jpg    275     183   Bad   100    44   184   165\n","104  Bad286.jpg    275     183   Bad   146    44   226   167)\n"," group in loop \n","data(filename='Bad287.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","65  Bad287.jpg    311     162   Bad     9     1   226   161\n","66  Bad287.jpg    311     162   Bad    98     9   302   162)\n"," group in loop \n","data(filename='Bad289.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","224  Bad289.jpg    300     168   Bad    32     5   135   163\n","225  Bad289.jpg    300     168   Bad    81     6   181   157\n","226  Bad289.jpg    300     168   Bad   137     7   220   152)\n"," group in loop \n","data(filename='Bad295.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","120  Bad295.jpg    316     160   Bad    18     1   212   115)\n"," group in loop \n","data(filename='Bad297.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","169  Bad297.jpg    249     203   Bad    25    63   111   183\n","170  Bad297.jpg    249     203   Bad    72    63   153   195)\n"," group in loop \n","data(filename='Bad3.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","157  Bad3.jpg    225     225   Bad     2    13   107   222\n","158  Bad3.jpg    225     225   Bad    55    13   156   225\n","159  Bad3.jpg    225     225   Bad   110     6   221   222)\n"," group in loop \n","data(filename='Bad302.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","230  Bad302.jpg    300     168   Bad     1     8   238   121)\n"," group in loop \n","data(filename='Bad304.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","187  Bad304.jpg    300     168   Bad     9     7   225   109)\n"," group in loop \n","data(filename='Bad309.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","143  Bad309.jpg    250     202   Bad    76    24   177    89\n","144  Bad309.jpg    250     202   Bad    60    25   120   202\n","145  Bad309.jpg    250     202   Bad   118    27   197   202\n","146  Bad309.jpg    250     202   Bad    61    99   197   202)\n"," group in loop \n","data(filename='Bad317.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","197  Bad317.jpg    308     164   Bad    87     5   224    86)\n"," group in loop \n","data(filename='Bad322.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","117  Bad322.jpg    266     190   Bad     5     6   230   118)\n"," group in loop \n","data(filename='Bad323.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","160  Bad323.jpg    203     248   Bad    11     7   184   236)\n"," group in loop \n","data(filename='Bad325.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","106  Bad325.jpg    283     178   Bad    81    15   197   178\n","107  Bad325.jpg    283     178   Bad   129    15   250   178)\n"," group in loop \n","data(filename='Bad326.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","135  Bad326.jpg    320     157   Bad   117     2   211   157)\n"," group in loop \n","data(filename='Bad344.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","22  Bad344.jpg    190     192   Bad     1    99    92   191)\n"," group in loop \n","data(filename='Bad345.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","4  Bad345.jpg    106     166   Bad    18    43   103   162)\n"," group in loop \n","data(filename='Bad352.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","38  Bad352.jpg    240     210   Bad     5    50    79   170\n","39  Bad352.jpg    240     210   Bad    47    59   117   170\n","40  Bad352.jpg    240     210   Bad    85    63   144   166\n","41  Bad352.jpg    240     210   Bad   117    63   172   166\n","42  Bad352.jpg    240     210   Bad   145    66   197   166\n","43  Bad352.jpg    240     210   Bad   173    58   237   167)\n"," group in loop \n","data(filename='Bad360.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","270  Bad360.jpg    275     183   Bad    64    54   172   139)\n"," group in loop \n","data(filename='Bad361.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","260  Bad361.jpg    256     197   Bad    39    26   171   104)\n"," group in loop \n","data(filename='Bad362.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","254  Bad362.jpg    275     183   Bad    70     1   275   138)\n"," group in loop \n","data(filename='Bad41.JPG', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","167  Bad41.JPG    274     353   Bad     6    24   224   351)\n"," group in loop \n","data(filename='Bad46.JPG', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","97  Bad46.JPG    275     355   Bad   121    48   203   173\n","98  Bad46.JPG    275     355   Bad    37    49   172   278)\n"," group in loop \n","data(filename='Bad53.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","131  Bad53.jpg    183     275   Bad    11    29   122   275\n","132  Bad53.jpg    183     275   Bad    75    24   181   262)\n"," group in loop \n","data(filename='Bad54.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","155  Bad54.jpg    271     186   Bad    13    14   271   186)\n"," group in loop \n","data(filename='Bad59.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","185  Bad59.jpg    180     229   Bad     3    47   169   229)\n"," group in loop \n","data(filename='Bad72.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","201  Bad72.jpg    276     183   Bad    44    14   168   183\n","202  Bad72.jpg    276     183   Bad   105    19   218   182)\n"," group in loop \n","data(filename='Bad84.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","129  Bad84.jpg    225     224   Bad    54     4   174   127)\n"," group in loop \n","data(filename='Bad89.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","198  Bad89.jpg    277     182   Bad    51     7   185   182)\n"," group in loop \n","data(filename='Bad9.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","210  Bad9.jpg    193     237   Bad    43    27   148   237)\n"," group in loop \n","data(filename='Bad98.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","183  Bad98.jpg    207     269   Bad    39    46   190   244)\n"," group in loop \n","data(filename='Bad99.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","205  Bad99.jpg    165     231   Bad    10    11   158   231)\n"," group in loop \n","data(filename='Badimages at 11.15.39 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","215  Badimages at 11.15.39 AM.jpg    780     592   Bad     2     3   719   590)\n"," group in loop \n","data(filename='Badimages at 11.15.52 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","231  Badimages at 11.15.52 AM.jpg    594     672   Bad    25     1   574   672)\n"," group in loop \n","data(filename='Badimages at 11.16.16 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","218  Badimages at 11.16.16 AM.jpg    808    1114   Bad    36    73   772  1099)\n"," group in loop \n","data(filename='Badimages at 11.17.21 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","164  Badimages at 11.17.21 AM.jpg    974    1284   Bad    31    17   970  1284)\n"," group in loop \n","data(filename='Badimages at 11.18.57 AM.jpg', object=                        filename  width  height  ... ymin  xmax  ymax\n","83  Badimages at 11.18.57 AM.jpg    582     338  ...   71   243   338\n","84  Badimages at 11.18.57 AM.jpg    582     338  ...   62   533   338\n","85  Badimages at 11.18.57 AM.jpg    582     338  ...   99   374   337\n","\n","[3 rows x 8 columns])\n"," group in loop \n","data(filename='Badimages at 11.19.40 AM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","186  Badimages at 11.19.40 AM.jpg   1200     894   Bad     1     1  1200   894)\n"," group in loop \n","data(filename='Badimages at 11.19.51 AM.jpg', object=                        filename  width  height  ... ymin  xmax  ymax\n","60  Badimages at 11.19.51 AM.jpg    578     472  ...   15   576   472\n","\n","[1 rows x 8 columns])\n"," group in loop \n","data(filename='Badimages at 3.06.04 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","227  Badimages at 3.06.04 PM.jpg    656     488   Bad    81     4   385   174\n","228  Badimages at 3.06.04 PM.jpg    656     488   Bad   316     6   548   118\n","229  Badimages at 3.06.04 PM.jpg    656     488   Bad   387     4   626   488)\n"," group in loop \n","data(filename='Badimages at 3.11.56 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","223  Badimages at 3.11.56 PM.jpg    286     406   Bad    37    25   245   374)\n"," group in loop \n","data(filename='Badimages at 3.13.06 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","234  Badimages at 3.13.06 PM.jpg    594     450   Bad    91    24   570   450)\n"," group in loop \n","data(filename='Badimages at 4.34.03 PM.jpg', object=                       filename  width  height class  xmin  ymin  xmax  ymax\n","36  Badimages at 4.34.03 PM.jpg    614     700   Bad     2     1   601   512)\n"," group in loop \n","data(filename='Badimages at 4.36.05 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","232  Badimages at 4.36.05 PM.jpg    677     518   Bad     1     1   677   518)\n"," group in loop \n","data(filename='Badimages at 4.37.14 PM.jpg', object=                       filename  width  height class  xmin  ymin  xmax  ymax\n","87  Badimages at 4.37.14 PM.jpg    592     792   Bad    38    32   584   792)\n"," group in loop \n","data(filename='Badimages at 4.37.31 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","203  Badimages at 4.37.31 PM.jpg    872     716   Bad    88    31   867   716)\n"," group in loop \n","data(filename='Badimages at 4.38.24 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","255  Badimages at 4.38.24 PM.jpg    462     558   Bad     1    23   457   558)\n"," group in loop \n","data(filename='Badimages at 4.40.37 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","267  Badimages at 4.40.37 PM.jpg   1006     774   Bad     3    38  1005   551)\n"," group in loop \n","data(filename='Badimages at 4.40.47 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","147  Badimages at 4.40.47 PM.jpg    992     776   Bad     3    21   992   619)\n"," group in loop \n","data(filename='Badimages at 4.40.58 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","259  Badimages at 4.40.58 PM.jpg    962     744   Bad     2    11   962   569)\n"," group in loop \n","data(filename='Badimages at 4.41.24 PM.jpg', object=                       filename  width  height class  xmin  ymin  xmax  ymax\n","88  Badimages at 4.41.24 PM.jpg    776     706   Bad   143    11   638   550)\n"," group in loop \n","data(filename='Badimages at 4.42.32 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","179  Badimages at 4.42.32 PM.jpg    928     511   Bad     8    15   928   501)\n"," group in loop \n","data(filename='Badimages at 4.42.49 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","246  Badimages at 4.42.49 PM.jpg    992     606   Bad    22     1   992   399)\n"," group in loop \n","data(filename='Badimages at 4.43.27 PM.jpg', object=                       filename  width  height class  xmin  ymin  xmax  ymax\n","21  Badimages at 4.43.27 PM.jpg    622     584   Bad     1     2   622   474)\n"," group in loop \n","data(filename='Badimages at 4.47.44 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","216  Badimages at 4.47.44 PM.jpg    470     336   Bad    67    31   470   336)\n"," group in loop \n","data(filename='Badimages at 8.09.00 PM.jpg', object=                       filename  width  height class  xmin  ymin  xmax  ymax\n","34  Badimages at 8.09.00 PM.jpg    568     404   Bad    86    35   537   404)\n"," group in loop \n","data(filename='Badimages at 8.11.46 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","250  Badimages at 8.11.46 PM.jpg    950     712   Bad    44    19   890   712)\n"," group in loop \n","data(filename='Badimages at 8.11.53 PM.jpg', object=                       filename  width  height class  xmin  ymin  xmax  ymax\n","44  Badimages at 8.11.53 PM.jpg   1012     748   Bad     1    15   985   748)\n"," group in loop \n","data(filename='Badimages at 8.12.00 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","184  Badimages at 8.12.00 PM.jpg    904     716   Bad     1     3   904   716)\n"," group in loop \n","data(filename='Badimages at 8.12.27 PM.jpg', object=                       filename  width  height class  xmin  ymin  xmax  ymax\n","89  Badimages at 8.12.27 PM.jpg    970     744   Bad     2     1   970   744)\n"," group in loop \n","data(filename='Badimages at 8.12.38 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","222  Badimages at 8.12.38 PM.jpg    944     620   Bad     1     1   943   516)\n"," group in loop \n","data(filename='Badimages at 8.13.15 PM.jpg', object=                       filename  width  height class  xmin  ymin  xmax  ymax\n","29  Badimages at 8.13.15 PM.jpg    861     663   Bad     1    16   858   663)\n"," group in loop \n","data(filename='Badimages at 8.13.33 PM.jpg', object=                       filename  width  height class  xmin  ymin  xmax  ymax\n","55  Badimages at 8.13.33 PM.jpg    982     808   Bad    17    10   982   806)\n"," group in loop \n","data(filename='Badimages at 8.13.48 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","148  Badimages at 8.13.48 PM.jpg    512     548   Bad    35    19   510   548)\n"," group in loop \n","data(filename='Caution11.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","211  Caution11.jpg    275     183  Caution    59    12   231   181)\n"," group in loop \n","data(filename='Caution119.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","90  Caution119.jpg    284     177  Caution    71    34   226   177)\n"," group in loop \n","data(filename='Caution120.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","45  Caution120.jpg    284     177  Caution    64     1   284   175)\n"," group in loop \n","data(filename='Caution123.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","24  Caution123.jpg    259     194  Caution    32    18   253   191)\n"," group in loop \n","data(filename='Caution126.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","62  Caution126.jpg    275     183  Caution     1    48   245   182)\n"," group in loop \n","data(filename='Caution150.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","156  Caution150.jpg    558     452  Caution    23    40   545   449)\n"," group in loop \n","data(filename='Caution151.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","118  Caution151.jpg    560     512  Caution    59    34   517   507)\n"," group in loop \n","data(filename='Caution154.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","92  Caution154.jpg    418     226  Caution    10    17   367   224)\n"," group in loop \n","data(filename='Caution168.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","95  Caution168.jpg    269     188  Caution   133    65   204   125)\n"," group in loop \n","data(filename='Caution169.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","137  Caution169.jpg    734     496  Caution    19    20   732   494)\n"," group in loop \n","data(filename='Caution19.JPG', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","149  Caution19.JPG    278     366  Caution    59    99   264   296)\n"," group in loop \n","data(filename='Caution195.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","109  Caution195.jpg    262     264  Caution    52    35   252   248)\n"," group in loop \n","data(filename='Caution202.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","204  Caution202.jpg    240     278  Caution    35    54   221   264)\n"," group in loop \n","data(filename='Caution208.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","99  Caution208.jpg    258     252  Caution    16    30   228   237)\n"," group in loop \n","data(filename='Caution21.JPG', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","100  Caution21.JPG    240     284  Caution    15    43   235   268)\n"," group in loop \n","data(filename='Caution214.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","166  Caution214.jpg    422     306  Caution    13    35   363   297)\n"," group in loop \n","data(filename='Caution23.JPG', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","96  Caution23.JPG    304     308  Caution    67    54   200   218)\n"," group in loop \n","data(filename='Caution231.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","168  Caution231.jpg    670     436  Caution    23     1   669   405)\n"," group in loop \n","data(filename='Caution232.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","153  Caution232.jpg    598     452  Caution    60    15   578   450)\n"," group in loop \n","data(filename='Caution233.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","121  Caution233.jpg    594     428     Good    72    48   317   407\n","122  Caution233.jpg    594     428     Good   268    36   540   400\n","123  Caution233.jpg    594     428  Caution    74    37   539   401)\n"," group in loop \n","data(filename='Caution237.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","128  Caution237.jpg    299     168  Caution   101    24   185   133)\n"," group in loop \n","data(filename='Caution240.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","64  Caution240.jpg    418     344  Caution    58    37   364   334)\n"," group in loop \n","data(filename='Caution241.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","28  Caution241.jpg    980    1044  Caution    31    66   977  1022)\n"," group in loop \n","data(filename='Caution244.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","63  Caution244.jpg    318     520  Caution     5    22   308   505)\n"," group in loop \n","data(filename='Caution247.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","54  Caution247.jpg   1082     758  Caution     6     1  1082   758)\n"," group in loop \n","data(filename='Caution249.jpg', object=           filename  width  height    class  xmin  ymin  xmax  ymax\n","233  Caution249.jpg    494     404  Caution    11    40   469   404)\n"," group in loop \n","data(filename='Caution36.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","133  Caution36.jpg    275     183  Caution     1     1   275   183)\n"," group in loop \n","data(filename='Caution4.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","209  Caution4.jpg    260     193  Caution    36    14   241   193)\n"," group in loop \n","data(filename='Caution41.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","1  Caution41.jpg    261     147  Caution    36     8   224   147)\n"," group in loop \n","data(filename='Caution5.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","221  Caution5.jpg    225     225  Caution     1    14   225   225)\n"," group in loop \n","data(filename='Caution50.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","56  Caution50.jpg    268     188  Caution    68    34   174   178)\n"," group in loop \n","data(filename='Caution52.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","49  Caution52.jpg   1200     769  Caution    93   248   385   763\n","50  Caution52.jpg   1200     769  Caution   655   177   983   738\n","51  Caution52.jpg   1200     769  Caution   757   177  1142   733\n","52  Caution52.jpg   1200     769  Caution   229   253   804   731)\n"," group in loop \n","data(filename='Caution54.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","33  Caution54.jpg   2048    1365  Caution   531   372  1699  1326)\n"," group in loop \n","data(filename='Caution58.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","271  Caution58.jpg    560     412  Caution     8    39   297   281\n","272  Caution58.jpg    560     412     Good   217    30   487   282)\n"," group in loop \n","data(filename='Caution66.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","252  Caution66.jpg    408     354  Caution    23    33   383   354)\n"," group in loop \n","data(filename='Caution86.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","0  Caution86.jpg    177     285  Caution    26    85   171   252)\n"," group in loop \n","data(filename='Caution87.jpg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","53  Caution87.jpg    262     192  Caution    24    13   195   191)\n"," group in loop \n","data(filename='Caution9.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","67  Caution9.jpg    264     191  Caution     1    14   164   191\n","68  Caution9.jpg    264     191  Caution    67    26   262   191)\n"," group in loop \n","data(filename='Caution99.jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","251  Caution99.jpg    424     418  Caution    53    43   382   409)\n"," group in loop \n","data(filename='Good10.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","243  Good10.jpg    661     370  Good   159    30   563   370)\n"," group in loop \n","data(filename='Good102.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","177  Good102.jpg   1280     720  Good   814   237  1138   546)\n"," group in loop \n","data(filename='Good105.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","219  Good105.jpg   1200     500  Good   169    55  1104   435)\n"," group in loop \n","data(filename='Good112.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","193  Good112.jpg    259     194  Good    17    76    75   148\n","194  Good112.jpg    259     194  Good    45    92   210   151\n","195  Good112.jpg    259     194  Good    98    73   209   149\n","196  Good112.jpg    259     194  Good    40    74   141   147)\n"," group in loop \n","data(filename='Good12.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","249  Good12.jpg    528     281  Good    77    91   396   228)\n"," group in loop \n","data(filename='Good120.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","108  Good120.jpg    259     194  Good    16    40   256   194)\n"," group in loop \n","data(filename='Good135.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","112  Good135.jpg    904     737  Good    21   136   291   601\n","113  Good135.jpg    904     737  Good   184   137   513   548\n","114  Good135.jpg    904     737  Good   341   124   581   554\n","115  Good135.jpg    904     737  Good   487   123   904   640)\n"," group in loop \n","data(filename='Good141.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","23  Good141.jpg    288     261  Good     1     2   264   240)\n"," group in loop \n","data(filename='Good143.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","35  Good143.jpg    302     167  Good    50     8   242   118)\n"," group in loop \n","data(filename='Good144.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","59  Good144.jpg    299     169  Good    49    55   275   159)\n"," group in loop \n","data(filename='Good146.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","73  Good146.jpg    287     175  Good     7    51    50   140\n","74  Good146.jpg    287     175  Good    38    44   108   159\n","75  Good146.jpg    287     175  Good     5    43   109   160\n","76  Good146.jpg    287     175  Good   113    47   138    70\n","77  Good146.jpg    287     175  Good    98    43   122    63\n","78  Good146.jpg    287     175  Good    70    44   187   159\n","79  Good146.jpg    287     175  Good   149    45   205   139\n","80  Good146.jpg    287     175  Good   189    45   239   124\n","81  Good146.jpg    287     175  Good   150    46   240   138\n","82  Good146.jpg    287     175  Good   213    48   275   123)\n"," group in loop \n","data(filename='Good148.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","241  Good148.jpg    275     183  Good    60    40   211   117)\n"," group in loop \n","data(filename='Good149.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","235  Good149.jpg    300     168  Good     1    45    22   111\n","236  Good149.jpg    300     168  Good     1    39    44   117\n","237  Good149.jpg    300     168  Good    21    42    81   122\n","238  Good149.jpg    300     168  Good    62    35   120   136\n","239  Good149.jpg    300     168  Good    93    35   208   168)\n"," group in loop \n","data(filename='Good154.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","6   Good154.jpg    275     183  Good     2   104    25   183\n","7   Good154.jpg    275     183  Good     3   104   101   183\n","8   Good154.jpg    275     183  Good    79   102   158   162\n","9   Good154.jpg    275     183  Good   146   103   178   146\n","10  Good154.jpg    275     183  Good   169   102   198   180\n","11  Good154.jpg    275     183  Good   179   103   217   183\n","12  Good154.jpg    275     183  Good   203   103   263   175)\n"," group in loop \n","data(filename='Good162.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","247  Good162.jpg    293     172  Good     1    13   228   172\n","248  Good162.jpg    293     172  Good   165    14   291   172)\n"," group in loop \n","data(filename='Good165.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","269  Good165.jpg    275     183  Good    32    45   257   125)\n"," group in loop \n","data(filename='Good170.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","261  Good170.jpg    259     194  Good    37    60   120   149\n","262  Good170.jpg    259     194   Bad     1    61    34   138\n","263  Good170.jpg    259     194  Good    18    61    68   149\n","264  Good170.jpg    259     194  Good    92    61   165   144\n","265  Good170.jpg    259     194  Good   145    62   216   174)\n"," group in loop \n","data(filename='Good173.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","253  Good173.jpg    300     168  Good    33    12   279   126)\n"," group in loop \n","data(filename='Good19.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","19  Good19.jpg    637     372  Caution   164    80   511   343)\n"," group in loop \n","data(filename='Good191.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","70  Good191.jpg    284     177  Good    34    43   100   112\n","71  Good191.jpg    284     177  Good    35    43   261   168)\n"," group in loop \n","data(filename='Good196.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","25  Good196.jpg    494     337  Good     1    41   270   271\n","26  Good196.jpg    494     337  Good   163     1   494   318)\n"," group in loop \n","data(filename='Good201.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","208  Good201.jpg    300     168  Good   143    71   211   161)\n"," group in loop \n","data(filename='Good21.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","57  Good21.jpg    615     325  Good    94    62   545   306)\n"," group in loop \n","data(filename='Good22.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","86  Good22.jpg    307     164  Good    54    26   264    99)\n"," group in loop \n","data(filename='Good220.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","47  Good220.jpg    277     182  Good   196    43   242   135\n","48  Good220.jpg    277     182  Good    58    44   243   177)\n"," group in loop \n","data(filename='Good223.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","30  Good223.jpg   2345    1201  Good    99   406   801   791\n","31  Good223.jpg   2345    1201  Good   552   362  1482   825\n","32  Good223.jpg   2345    1201  Good  1235   116  2345   891)\n"," group in loop \n","data(filename='Good236.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","3  Good236.jpg    670     430  Good    89    72   624   391)\n"," group in loop \n","data(filename='Good25.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","15  Good25.jpg    300     168  Caution    21    17    97   137\n","16  Good25.jpg    300     168  Caution    90    14   161   102\n","17  Good25.jpg    300     168  Caution   129    37   191   104\n","18  Good25.jpg    300     168  Caution   142    42   272   167)\n"," group in loop \n","data(filename='Good251.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","125  Good251.jpg    872     530  Good    54    14   808   484)\n"," group in loop \n","data(filename='Good264.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","199  Good264.jpg    300     168     Good    62    29   172   161\n","200  Good264.jpg    300     168  Caution    40    45    75    93)\n"," group in loop \n","data(filename='Good285.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","152  Good285.jpg    600     400  Good   104   163   464   386)\n"," group in loop \n","data(filename='Good286.jpg', object=        filename  width  height class  xmin  ymin  xmax  ymax\n","126  Good286.jpg    275     183  Good    43    50   156   160\n","127  Good286.jpg    275     183  Good   133    49   241   162)\n"," group in loop \n","data(filename='Good33.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","37  Good33.jpg    250     201  Caution    20    50   218   169)\n"," group in loop \n","data(filename='Good38.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","242  Good38.jpg    303     166  Caution    91    24   244   166)\n"," group in loop \n","data(filename='Good4.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","142  Good4.jpg    323     427  Good     4   133   273   356)\n"," group in loop \n","data(filename='Good49.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","214  Good49.jpg    275     183  Caution     1    36   269   156)\n"," group in loop \n","data(filename='Good5.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","171  Good5.jpg    609     404  Good   109   193   545   374)\n"," group in loop \n","data(filename='Good50.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","110  Good50.jpg    300     168  Good    30    22   258   168)\n"," group in loop \n","data(filename='Good51.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","116  Good51.jpg    259     194  Good     1    16   259   190)\n"," group in loop \n","data(filename='Good54.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","173  Good54.jpg    300     168  Caution     4     3   292   168)\n"," group in loop \n","data(filename='Good60.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","213  Good60.jpg    276     183  Good    32    43   257   133)\n"," group in loop \n","data(filename='Good63.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","192  Good63.jpg    273     184  Caution    34    32   240   142)\n"," group in loop \n","data(filename='Good65.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","189  Good65.jpg    272     185  Good    51    16   147   134\n","190  Good65.jpg    272     185  Good    51    16   251   185)\n"," group in loop \n","data(filename='Good68.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","172  Good68.jpg    768     516  Good    92    70   598   500)\n"," group in loop \n","data(filename='Good73.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","181  Good73.jpg    850     522  Good    65   198   837   489)\n"," group in loop \n","data(filename='Good74.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","212  Good74.jpg    650     456  Caution    94   119   609   456)\n"," group in loop \n","data(filename='Good8.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","165  Good8.jpg    628     370  Good   137    89   579   329)\n"," group in loop \n","data(filename='Good81.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","162  Good81.jpg    906     498  Good    54    31   497   479\n","163  Good81.jpg    906     498  Good   388    36   857   472)\n"," group in loop \n","data(filename='Good82.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","175  Good82.jpg    614     380  Good   121    49   377   305\n","176  Good82.jpg    614     380  Good   321    43   603   305)\n"," group in loop \n","data(filename='Good90.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","138  Good90.jpg   1200     711  Good    30    87  1149   675)\n"," group in loop \n","data(filename='Good91.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","139  Good91.jpg   1100     825  Good   171   432   457   621\n","140  Good91.jpg   1100     825  Good   395   430   704   614\n","141  Good91.jpg   1100     825  Good   639   434  1036   613)\n"," group in loop \n","data(filename='Goodimages at 1.40.48 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","111  Goodimages at 1.40.48 PM.jpg    966     558  Good    40    65   882   557)\n"," group in loop \n","data(filename='Goodimages at 1.41.44 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","46  Goodimages at 1.41.44 PM.jpg    686     454  Good   148    58   533   401)\n"," group in loop \n","data(filename='Goodimages at 1.42.10 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","130  Goodimages at 1.42.10 PM.jpg    610     446  Good    28    41   553   386)\n"," group in loop \n","data(filename='Goodimages at 3.03.35 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","256  Goodimages at 3.03.35 PM.jpg    532     344  Good    53    67   483   332)\n"," group in loop \n","data(filename='Goodimages at 3.08.34 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","134  Goodimages at 3.08.34 PM.jpg    550     260  Good    35    43   530   260)\n"," group in loop \n","data(filename='Goodimages at 3.17.20 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","69  Goodimages at 3.17.20 PM.jpg    722     384  Good    59    44   690   365)\n"," group in loop \n","data(filename='Goodimages at 3.33.44 PM.jpg', object=                        filename  width  height class  xmin  ymin  xmax  ymax\n","20  Goodimages at 3.33.44 PM.jpg    584     422  Good    62    31   532   422)\n"," group in loop \n","data(filename='Goodimages at 3.38.46 PM.jpg', object=                       filename  width  height class  xmin  ymin  xmax  ymax\n","5  Goodimages at 3.38.46 PM.jpg    566     318  Good    14     5   509   281)\n"," group in loop \n","data(filename='Goodimages at 3.59.48 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","217  Goodimages at 3.59.48 PM.jpg    748     328  Good    36    18   722   248)\n"," group in loop \n","data(filename='Goodimages at 4.03.26 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","124  Goodimages at 4.03.26 PM.jpg    640     446  Good     6    61   554   316)\n"," group in loop \n","data(filename='Goodimages at 4.05.12 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","151  Goodimages at 4.05.12 PM.jpg   1200     572  Good    34    38  1158   572)\n"," group in loop \n","data(filename='Goodimages at 8.10.47 PM.jpg', object=                         filename  width  height class  xmin  ymin  xmax  ymax\n","154  Goodimages at 8.10.47 PM.jpg    898     448  Good    60    20   867   448)\n","Successfully created the TFRecords: /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/test_labels.record\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tglxyWUHIg8r"},"source":["**Training Model**\n","\n","\n","*  using selected model retrain\n","*   Input expected is TFRecord for training and evaluation\n","\n","\n","\n","**Select model wish to retrain from object detection api set of pretrained models AND specify some basic training parameters**\n","[ ]\n"]},{"cell_type":"code","metadata":{"id":"jOpu1IvjIiuw","executionInfo":{"status":"ok","timestamp":1604598915649,"user_tz":480,"elapsed":24713,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"9d4f57f7-8720-440c-9076-1bbaa8b32f00","colab":{"base_uri":"https://localhost:8080/"}},"source":["##change chosen model to deploy different models available in the TF2 object detection zoo\n","MODELS_CONFIG = {\n","    'efficientdet-d0': {\n","        #this one\n","        'model_name': 'efficientdet_d0_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    },\n","    'efficientdet-d1': {\n","        'model_name': 'efficientdet_d1_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    },\n","    'efficientdet-d2': {\n","        'model_name': 'efficientdet_d2_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    },\n","        'efficientdet-d3': {\n","        'model_name': 'efficientdet_d3_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n","        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    },\n","      'efficientdet-d4': {\n","          #this one\n","        'model_name': 'efficientdet_d4_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d4_1024x1024_coco17_tpu-32.config',\n","        'pretrained_checkpoint': 'efficientdet_d4_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    },#this one\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n","        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n","        'batch_size': 16\n","    }\n","}\n","\n","#in this tutorial we implement the lightweight, smallest state of the art efficientdet model\n","#if you want to scale up tot larger efficientdet models you will likely need more compute!\n","\n","###change this according to your model\n","chosen_model = 'efficientdet-d0'\n","\n","num_steps = 40000 #16000 #40,000 The more steps, the longer the training. Increase if your loss function is still decreasing and validation metrics are increasing. \n","num_eval_steps = 500 #Perform evaluation after so many steps\n","\n","model_name = MODELS_CONFIG[chosen_model]['model_name']\n","pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n","base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n","batch_size = MODELS_CONFIG[chosen_model]['batch_size'] #if you can fit a large batch in memory, it may speed up your training\n","\n","\n","print(\"Model Chosen for Retraining\")\n","print(\" name \"+ model_name)\n","print(\" pretrained_checkpoint \" + pretrained_checkpoint)\n","print(\" base_pipeline_file \" + base_pipeline_file)\n","print(\" batch_size \" + str(batch_size))"],"execution_count":60,"outputs":[{"output_type":"stream","text":["Model Chosen for Retraining\n"," name efficientdet_d0_coco17_tpu-32\n"," pretrained_checkpoint efficientdet_d0_coco17_tpu-32.tar.gz\n"," base_pipeline_file ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n"," batch_size 16\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5wAB6jDN23eh"},"source":["**specify the TFRecord files for training**"]},{"cell_type":"code","metadata":{"id":"wff9mvEf2-Fh","executionInfo":{"status":"ok","timestamp":1604598953129,"user_tz":480,"elapsed":785,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"de45f764-8971-4011-ebf7-f048a661f217","colab":{"base_uri":"https://localhost:8080/"}},"source":["# See previous cell where created record files for location and name of files\n","%cd {data_dir}\n","test_record_fname =  '/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/test_labels.record'\n","train_record_fname = '/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/train_labels.record'\n","%cd {data_dir}\n","label_map_pbtxt_fname =  '/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/label_map.pbtxt'\n","\n","\n","    \n","print(\"Files used in Training\")\n","print(test_record_fname)\n","print(train_record_fname)\n","print(label_map_pbtxt_fname)"],"execution_count":62,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data\n","/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data\n","Files used in Training\n","/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/test_labels.record\n","/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/train_labels.record\n","/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/label_map.pbtxt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C7547yCZ3DKP"},"source":["**get the pretrained model and put it into a special new deploy directory**"]},{"cell_type":"code","metadata":{"id":"xpZgGPis3I_A","executionInfo":{"status":"ok","timestamp":1604599008531,"user_tz":480,"elapsed":1692,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"d72d1db7-0513-4c43-a16b-a306f9241660","colab":{"base_uri":"https://localhost:8080/"}},"source":["#DO ONLY ONCE\n","\n","#download pretrained weights\n","#create a folder under models/research/ named deploy\n","\n","deploy_path = models_research_dir + \"/deploy/\"\n","\n","%mkdir {deploy_path}\n","%cd {deploy_path}\n","\n","    \n","import tarfile\n","download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n","\n","!wget {download_tar}\n","tar = tarfile.open(pretrained_checkpoint)\n","tar.extractall()\n","tar.close()"],"execution_count":63,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/deploy\n","--2020-11-05 17:56:47--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.73.240, 2607:f8b0:4004:814::2010\n","Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.73.240|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 30736482 (29M) [application/x-tar]\n","Saving to: ‘efficientdet_d0_coco17_tpu-32.tar.gz’\n","\n","efficientdet_d0_coc 100%[===================>]  29.31M  84.4MB/s    in 0.3s    \n","\n","2020-11-05 17:56:47 (84.4 MB/s) - ‘efficientdet_d0_coco17_tpu-32.tar.gz’ saved [30736482/30736482]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Eo4eLHhZ3Tp-"},"source":["**now get the pretrained model's configuration file and put it in the deploy directory created in cell above**"]},{"cell_type":"code","metadata":{"id":"IIC0ET1z3PRk","executionInfo":{"status":"ok","timestamp":1604599011639,"user_tz":480,"elapsed":620,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"3dc3e445-05a1-43d3-b33e-528e619976b3","colab":{"base_uri":"https://localhost:8080/"}},"source":["deploy_path = models_research_dir + \"/deploy/\"\n","%cd {deploy_path}\n","download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n","!wget {download_config}"],"execution_count":64,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/deploy\n","--2020-11-05 17:56:51--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4630 (4.5K) [text/plain]\n","Saving to: ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config’\n","\n","ssd_efficientdet_d0 100%[===================>]   4.52K  --.-KB/s    in 0.001s  \n","\n","2020-11-05 17:56:51 (6.17 MB/s) - ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config’ saved [4630/4630]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eyCjqBKaHmwT"},"source":["### setup parameters to pass to training script for Object Detect API on TF2\n","\n","\n","*   pipeline_filename = the configuration file for training\n","*   fine_tune_checkpoint = checkpoint file of model will retrain that you will start from\n","*   num_classes= number of classes you will retrain to (from your label file)\n","\n"]},{"cell_type":"code","metadata":{"id":"ieVd5cQhhQhJ","executionInfo":{"status":"ok","timestamp":1604598634953,"user_tz":480,"elapsed":579,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"0dfb0d57-82f8-4fc4-c592-ecd69bb6f9d8","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd {models_dir}"],"execution_count":39,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RvyMGRfw3rFO","executionInfo":{"status":"ok","timestamp":1604599060160,"user_tz":480,"elapsed":460,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"22f3546e-acf1-4453-c8d6-358b29392b6b","colab":{"base_uri":"https://localhost:8080/"}},"source":["# at C:\\tensorflow\\models\\research\\object_detection\\utils\\label_map_util.py\n","# rather than the tf2 version installed in this jupyter notebooks\n","# environment it is launched from which is tf2\n","# because the import below in the function get_num_classes\n","#   \"from object_detection.utils import label_map_util\"\n","# is mapping to wrong object detection api\n","#prepare\n","print(\" Version of tf \" + tf.__version__)\n","deploy_path = models_research_dir + \"/deploy/\"\n","\n","#pipeline_fname = deploy_path + base_pipeline_file\n","#fine_tune_checkpoint = deploy_path + model_name + '/checkpoint/ckpt-0'\n","%cd {deploy_path}\n","pipeline_fname = str(os.getcwd()) + os.path.sep + base_pipeline_file\n","fine_tune_checkpoint = str(os.getcwd()) + os.path.sep + model_name + '/checkpoint/ckpt-0'\n","\n","\n","\n","print(\"pipeline_fname \" + pipeline_fname)\n","print(\"fine_tune_checkpoint \" + fine_tune_checkpoint)\n","\n","\n","\n","    \n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=3, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())\n","\n","#WARNING:  you must use relative path as 'My Drive' or 'Shared drives' in a path will fail to open or find\n","# the file in the get_num_classes function ....so cd to directory and call with local filename\n","# need to be in the models/research directory when execute the get_num_classes function as it needs to find object_detection\n","relative_path_to_labelfile = \"../../Data/label_map.pbtxt\"\n","print(relative_path_to_labelfile)\n","#num_classes = get_num_classes(label_map_pbtxt_fname)\n","%cd {models_research_dir}\n","print(\"--------------\")\n","%ls\n","num_classes = get_num_classes(relative_path_to_labelfile)\n","\n","\n","print(\"Number of classes= \"+ str(num_classes))\n","print(\"Label file \"+ label_map_pbtxt_fname)"],"execution_count":65,"outputs":[{"output_type":"stream","text":[" Version of tf 2.3.0\n","/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/deploy\n","pipeline_fname /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/deploy/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n","fine_tune_checkpoint /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/deploy/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\n","../../Data/label_map.pbtxt\n","/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research\n","--------------\n","\u001b[0m\u001b[01;34ma3c_blogpost\u001b[0m/        \u001b[01;34mdeep_speech\u001b[0m/            \u001b[01;34mobject_detection\u001b[0m/\n","\u001b[01;34madversarial_text\u001b[0m/    \u001b[01;34mdelf\u001b[0m/                   \u001b[01;34mobject_detection.egg-info\u001b[0m/\n","\u001b[01;34mattention_ocr\u001b[0m/       \u001b[01;34mdeploy\u001b[0m/                 \u001b[01;34mpcl_rl\u001b[0m/\n","\u001b[01;34maudioset\u001b[0m/            \u001b[01;34mdist\u001b[0m/                   README.md\n","\u001b[01;34mautoaugment\u001b[0m/         \u001b[01;34mefficient-hrl\u001b[0m/          \u001b[01;34mrebar\u001b[0m/\n","\u001b[01;34mbuild\u001b[0m/               \u001b[01;34mlfads\u001b[0m/                  \u001b[01;34msequence_projection\u001b[0m/\n","\u001b[01;34mcognitive_planning\u001b[0m/  \u001b[01;34mlstm_object_detection\u001b[0m/  setup.py\n","\u001b[01;34mcvt_text\u001b[0m/            \u001b[01;34mmarco\u001b[0m/                  \u001b[01;34mslim\u001b[0m/\n","\u001b[01;34mdeeplab\u001b[0m/             \u001b[01;34mnst_blogpost\u001b[0m/           \u001b[01;34mvid2depth\u001b[0m/\n","Number of classes= 3\n","Label file /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/label_map.pbtxt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"71opjbXFMOlP"},"source":["### Modify the configuration file to update with some training values"]},{"cell_type":"code","metadata":{"id":"y7N6Kfxu4BPM","executionInfo":{"status":"ok","timestamp":1604599070642,"user_tz":480,"elapsed":644,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"6f7342c4-f926-433f-c347-7d01d2beff2d","colab":{"base_uri":"https://localhost:8080/"}},"source":["#write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file\n","\n","import re\n","import pathlib\n","\n","%cd {deploy_path}\n","\n","    \n","print(\" path cwd \" + str(pathlib.Path.cwd()))\n","print(\"reading original configuration file name= \" + str(pipeline_fname))\n","\n","print(\"writing custom configuration file name= \" + str(os.getcwd()) + os.path.sep + \"pipeline_file.config\")\n","      \n","      \n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open('pipeline_file.config', 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    \n","    #fine-tune checkpoint type\n","    s = re.sub(\n","        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n","        \n","    f.write(s)\n","\n","\n","    # problem --can't open files with ' ' inside the pathname \n"],"execution_count":66,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/deploy\n"," path cwd /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/deploy\n","reading original configuration file name= /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/deploy/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n","writing custom configuration file name= /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/deploy/pipeline_file.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G921gcjE4FO_","executionInfo":{"status":"ok","timestamp":1604599073632,"user_tz":480,"elapsed":475,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"a6484c8a-8391-4b73-d9e5-8c5f125ec87c","colab":{"base_uri":"https://localhost:8080/"}},"source":["config_file = deploy_path + \"pipeline_file.config\"\n","print(config_file)\n","%cat {config_file}"],"execution_count":67,"outputs":[{"output_type":"stream","text":["/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/models/research//deploy/pipeline_file.config\n"," # SSD with EfficientNet-b0 + BiFPN feature extractor,\n","# shared box predictor and focal loss (a.k.a EfficientDet-d0).\n","# See EfficientDet, Tan et al, https://arxiv.org/abs/1911.09070\n","# See Lin et al, https://arxiv.org/abs/1708.02002\n","# Trained on COCO, initialized from an EfficientNet-b0 checkpoint.\n","#\n","# Train on TPU-8\n","\n","model {\n","  ssd {\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","    num_classes: 3\n","    add_background_class: false\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    encode_background_as_zeros: true\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 4.0\n","        aspect_ratios: [1.0, 2.0, 0.5]\n","        scales_per_octave: 3\n","      }\n","    }\n","    image_resizer {\n","      keep_aspect_ratio_resizer {\n","        min_dimension: 512\n","        max_dimension: 512\n","        pad_to_max_dimension: true\n","        }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        depth: 64\n","        class_prediction_bias_init: -4.6\n","        conv_hyperparams {\n","          force_use_bias: true\n","          activation: SWISH\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              stddev: 0.01\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            scale: true\n","            decay: 0.99\n","            epsilon: 0.001\n","          }\n","        }\n","        num_layers_before_predictor: 3\n","        kernel_size: 3\n","        use_depthwise: true\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_efficientnet-b0_bifpn_keras'\n","      bifpn {\n","        min_level: 3\n","        max_level: 7\n","        num_iterations: 3\n","        num_filters: 64\n","      }\n","      conv_hyperparams {\n","        force_use_bias: true\n","        activation: SWISH\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          scale: true,\n","          decay: 0.99,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          alpha: 0.25\n","          gamma: 1.5\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    normalize_loc_loss_by_codesize: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.5\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  fine_tune_checkpoint: \"/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/deploy/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\n","  fine_tune_checkpoint_version: V2\n","  fine_tune_checkpoint_type: \"detection\"\n","  batch_size: 16\n","  sync_replicas: true\n","  startup_delay_steps: 0\n","  replicas_to_aggregate: 8\n","  use_bfloat16: true\n","  num_steps: 40000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_scale_crop_and_pad_to_square {\n","      output_size: 512\n","      scale_min: 0.1\n","      scale_max: 2.0\n","    }\n","  }\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: 8e-2\n","          total_steps: 300000\n","          warmup_learning_rate: .001\n","          warmup_steps: 2500\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/train_labels.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 16;\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/test_labels.record\"\n","  }\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kXFtTqLt4QZr","executionInfo":{"status":"ok","timestamp":1604599085373,"user_tz":480,"elapsed":6991,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"fcb80442-d537-42f1-bc44-f2d5bcf70892","colab":{"base_uri":"https://localhost:8080/"}},"source":["# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize    \n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn't guaranteed\n","gpu = GPUs[0]\n","\n","def printm():\n","  process = psutil.Process(os.getpid())\n","  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n","  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","\n","printm() "],"execution_count":68,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 12.5 GB  I Proc size: 403.6 MB\n","GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total 15079MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AEbXtbKn4Wlx","executionInfo":{"status":"ok","timestamp":1604599087361,"user_tz":480,"elapsed":7034,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"fd6754d0-369e-4ace-c97f-af8851ee905f","colab":{"base_uri":"https://localhost:8080/"}},"source":["!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","try:\n","  import GPUtil as GPU\n","  GPUs = GPU.getGPUs()\n","  device='/gpu:0'\n","except:\n","  device='/cpu:0'"],"execution_count":69,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wT-MU44BuC04"},"source":["##run the trainer by calling a script for Obj Detect API on TF2 called model_main_tf2 which takes the following parameters\n","\n","\n","*   pipeline_file = configuration file used in training created in previous stem\n","*   model_dir = directory where will write results of training including checkpoints and tensorboard event file.\n","\n"]},{"cell_type":"code","metadata":{"id":"UH6yG_wNkQN6","executionInfo":{"status":"ok","timestamp":1604599253708,"user_tz":480,"elapsed":2718,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"826c9292-9c96-45b2-e3fb-5262a033806e","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install lvis"],"execution_count":73,"outputs":[{"output_type":"stream","text":["Collecting lvis\n","  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n","Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.29.21)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis) (4.1.2.30)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.3.1)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.18.5)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.15.0)\n","Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from lvis) (3.2.2)\n","Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.8.1)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.10.0)\n","Installing collected packages: lvis\n","Successfully installed lvis-0.5.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vwguCAzk4oQF","executionInfo":{"status":"ok","timestamp":1604599494115,"user_tz":480,"elapsed":239402,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"827dede2-553c-4af3-d0ac-c72d83d65993","colab":{"base_uri":"https://localhost:8080/"}},"source":["pipeline_file = deploy_path + 'pipeline_file.config'\n","#model_dir = base_dir + '/training/'\n","model_dir=\"/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/training1/\"\n","\n","print(\" options\")\n","print(\"    pipeline_config_path= \"+ pipeline_file)\n","print(\"    model_dir= \" + models_dir)\n","print(\"    alsologtostderr\")\n","print(\"    num_train_steps= \"+ str(num_steps))\n","print(\"    sample_1_of_n_eval_examples= \" + str(1))\n","print(\"    num_eval_steps= \" + str(num_eval_steps))\n","\n","training_script = object_detect_dir + \"/model_main_tf2.py\"\n","\n","#must be in the diretory that the object_detection folder is stored (models/research)\n","%cd {models_research_dir}\n","#!python /content/models/research/object_detection/model_main_tf2.py \\\n","!python {training_script} \\\n","        --pipeline_config_path={pipeline_file} \\\n","        --model_dir={model_dir} \\\n","        --alsologtostderr \\\n","        --num_train_steps={num_steps} \\\n","        --sample_1_of_n_eval_examples=1 \\\n","        --num_eval_steps={num_eval_steps}"],"execution_count":74,"outputs":[{"output_type":"stream","text":[" options\n","    pipeline_config_path= /content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/models/research/deploy/pipeline_file.config\n","    model_dir= /content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/models/\n","    alsologtostderr\n","    num_train_steps= 40000\n","    sample_1_of_n_eval_examples= 1\n","    num_eval_steps= 500\n","/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research\n","2020-11-05 18:00:55.507458: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-11-05 18:00:58.120542: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n","2020-11-05 18:00:58.153810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:00:58.154390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n","2020-11-05 18:00:58.154431: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-11-05 18:00:58.158834: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n","2020-11-05 18:00:58.160482: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n","2020-11-05 18:00:58.160816: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n","2020-11-05 18:00:58.168903: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n","2020-11-05 18:00:58.170125: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n","2020-11-05 18:00:58.173692: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n","2020-11-05 18:00:58.173809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:00:58.174398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:00:58.174900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n","2020-11-05 18:00:58.180285: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n","2020-11-05 18:00:58.180472: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x13f2bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-11-05 18:00:58.180499: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-11-05 18:00:58.285792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:00:58.286444: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x13f2a00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-11-05 18:00:58.286476: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2020-11-05 18:00:58.286695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:00:58.287266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n","2020-11-05 18:00:58.287308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-11-05 18:00:58.287365: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n","2020-11-05 18:00:58.287390: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n","2020-11-05 18:00:58.287412: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n","2020-11-05 18:00:58.287437: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n","2020-11-05 18:00:58.287456: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n","2020-11-05 18:00:58.287477: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n","2020-11-05 18:00:58.287566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:00:58.288107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:00:58.288609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n","2020-11-05 18:00:58.288663: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-11-05 18:00:58.879476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-11-05 18:00:58.879538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n","2020-11-05 18:00:58.879553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n","2020-11-05 18:00:58.879758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:00:58.880394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:00:58.880880: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-11-05 18:00:58.880921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I1105 18:00:58.883640 140093162129280 mirrored_strategy.py:341] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 40000\n","I1105 18:00:58.890878 140093162129280 config_util.py:552] Maybe overwriting train_steps: 40000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I1105 18:00:58.891072 140093162129280 config_util.py:552] Maybe overwriting use_bfloat16: False\n","I1105 18:00:58.906470 140093162129280 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I1105 18:00:58.906591 140093162129280 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 64\n","I1105 18:00:58.906665 140093162129280 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 3\n","I1105 18:00:58.915041 140093162129280 efficientnet_model.py:147] round_filter input=32 output=32\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1105 18:00:58.941959 140093162129280 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1105 18:00:58.944797 140093162129280 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1105 18:00:58.948920 140093162129280 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1105 18:00:58.951383 140093162129280 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1105 18:00:58.966795 140093162129280 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1105 18:00:58.969354 140093162129280 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1105 18:00:58.978202 140093162129280 efficientnet_model.py:147] round_filter input=32 output=32\n","I1105 18:00:58.978343 140093162129280 efficientnet_model.py:147] round_filter input=16 output=16\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1105 18:00:58.997699 140093162129280 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1105 18:00:59.000239 140093162129280 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1105 18:00:59.003839 140093162129280 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1105 18:00:59.006347 140093162129280 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1105 18:00:59.183763 140093162129280 efficientnet_model.py:147] round_filter input=16 output=16\n","I1105 18:00:59.183911 140093162129280 efficientnet_model.py:147] round_filter input=24 output=24\n","I1105 18:00:59.508346 140093162129280 efficientnet_model.py:147] round_filter input=24 output=24\n","I1105 18:00:59.508493 140093162129280 efficientnet_model.py:147] round_filter input=40 output=40\n","I1105 18:00:59.837391 140093162129280 efficientnet_model.py:147] round_filter input=40 output=40\n","I1105 18:00:59.837539 140093162129280 efficientnet_model.py:147] round_filter input=80 output=80\n","I1105 18:01:00.332890 140093162129280 efficientnet_model.py:147] round_filter input=80 output=80\n","I1105 18:01:00.333060 140093162129280 efficientnet_model.py:147] round_filter input=112 output=112\n","I1105 18:01:00.827840 140093162129280 efficientnet_model.py:147] round_filter input=112 output=112\n","I1105 18:01:00.828006 140093162129280 efficientnet_model.py:147] round_filter input=192 output=192\n","I1105 18:01:01.511446 140093162129280 efficientnet_model.py:147] round_filter input=192 output=192\n","I1105 18:01:01.511607 140093162129280 efficientnet_model.py:147] round_filter input=320 output=320\n","I1105 18:01:01.669479 140093162129280 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I1105 18:01:01.728873 140093162129280 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/train_labels.record']\n","I1105 18:01:01.906319 140093162129280 dataset_builder.py:148] Reading unweighted datasets: ['/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/train_labels.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/train_labels.record']\n","I1105 18:01:01.908302 140093162129280 dataset_builder.py:77] Reading record datasets for input file: ['/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/train_labels.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I1105 18:01:01.908450 140093162129280 dataset_builder.py:78] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W1105 18:01:01.908540 140093162129280 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","W1105 18:01:01.911468 140093162129280 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W1105 18:01:01.937016 140093162129280 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W1105 18:01:07.869076 140093162129280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/inputs.py:281: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1105 18:01:11.998823 140093162129280 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/inputs.py:281: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/model_lib_v2.py:355: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n","Instructions for updating:\n","Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","W1105 18:01:21.098777 140089592600320 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/model_lib_v2.py:355: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n","Instructions for updating:\n","Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","2020-11-05 18:01:45.364755: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n","2020-11-05 18:01:46.809978: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists\n","W1105 18:01:55.849312 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._groundtruth_lists\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor\n","W1105 18:01:55.849686 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\n","W1105 18:01:55.849778 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head\n","W1105 18:01:55.849850 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads\n","W1105 18:01:55.849916 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._sorted_head_names\n","W1105 18:01:55.849977 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._sorted_head_names\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers\n","W1105 18:01:55.850037 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads\n","W1105 18:01:55.850097 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers\n","W1105 18:01:55.850156 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers\n","W1105 18:01:55.850238 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background\n","W1105 18:01:55.850316 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.0\n","W1105 18:01:55.850374 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.1\n","W1105 18:01:55.850431 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.2\n","W1105 18:01:55.850487 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.3\n","W1105 18:01:55.850544 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.3\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.4\n","W1105 18:01:55.850607 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings\n","W1105 18:01:55.850663 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background\n","W1105 18:01:55.850720 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower\n","W1105 18:01:55.850778 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower\n","W1105 18:01:55.850843 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0\n","W1105 18:01:55.850954 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers\n","W1105 18:01:55.851016 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0\n","W1105 18:01:55.851078 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1\n","W1105 18:01:55.851136 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2\n","W1105 18:01:55.851193 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3\n","W1105 18:01:55.851265 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4\n","W1105 18:01:55.851327 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0\n","W1105 18:01:55.851384 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1\n","W1105 18:01:55.851446 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2\n","W1105 18:01:55.851504 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3\n","W1105 18:01:55.851566 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4\n","W1105 18:01:55.851624 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0\n","W1105 18:01:55.851682 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1\n","W1105 18:01:55.851739 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2\n","W1105 18:01:55.851803 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0\n","W1105 18:01:55.851860 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1\n","W1105 18:01:55.851917 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2\n","W1105 18:01:55.851973 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.depthwise_kernel\n","W1105 18:01:55.852100 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.pointwise_kernel\n","W1105 18:01:55.852169 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.bias\n","W1105 18:01:55.852241 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0\n","W1105 18:01:55.852301 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1\n","W1105 18:01:55.852360 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.2\n","W1105 18:01:55.852428 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4\n","W1105 18:01:55.852485 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.5\n","W1105 18:01:55.852542 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7\n","W1105 18:01:55.852612 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.8\n","W1105 18:01:55.852668 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1\n","W1105 18:01:55.852725 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.2\n","W1105 18:01:55.852782 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4\n","W1105 18:01:55.852840 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.5\n","W1105 18:01:55.852897 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7\n","W1105 18:01:55.852953 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.8\n","W1105 18:01:55.853009 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1\n","W1105 18:01:55.853066 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.2\n","W1105 18:01:55.853124 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4\n","W1105 18:01:55.853180 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.5\n","W1105 18:01:55.853250 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7\n","W1105 18:01:55.853308 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.8\n","W1105 18:01:55.853364 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1\n","W1105 18:01:55.853420 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.2\n","W1105 18:01:55.853477 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4\n","W1105 18:01:55.853533 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.5\n","W1105 18:01:55.853594 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7\n","W1105 18:01:55.877244 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.8\n","W1105 18:01:55.877358 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1\n","W1105 18:01:55.877441 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.2\n","W1105 18:01:55.877512 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4\n","W1105 18:01:55.877616 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.5\n","W1105 18:01:55.877693 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7\n","W1105 18:01:55.877768 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.8\n","W1105 18:01:55.877840 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1\n","W1105 18:01:55.877912 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.2\n","W1105 18:01:55.877987 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4\n","W1105 18:01:55.878063 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.5\n","W1105 18:01:55.878142 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7\n","W1105 18:01:55.878236 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.8\n","W1105 18:01:55.878319 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1\n","W1105 18:01:55.878395 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.2\n","W1105 18:01:55.878473 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4\n","W1105 18:01:55.878565 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.5\n","W1105 18:01:55.878651 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7\n","W1105 18:01:55.878731 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.8\n","W1105 18:01:55.878810 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1\n","W1105 18:01:55.878890 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.2\n","W1105 18:01:55.878969 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4\n","W1105 18:01:55.879049 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.5\n","W1105 18:01:55.879129 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7\n","W1105 18:01:55.879222 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.8\n","W1105 18:01:55.879307 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1\n","W1105 18:01:55.879386 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.2\n","W1105 18:01:55.879465 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4\n","W1105 18:01:55.879544 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.5\n","W1105 18:01:55.879634 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7\n","W1105 18:01:55.879714 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.8\n","W1105 18:01:55.879793 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1\n","W1105 18:01:55.879873 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.2\n","W1105 18:01:55.879953 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4\n","W1105 18:01:55.880040 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.5\n","W1105 18:01:55.880117 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7\n","W1105 18:01:55.880192 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.8\n","W1105 18:01:55.880288 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.depthwise_kernel\n","W1105 18:01:55.880367 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.pointwise_kernel\n","W1105 18:01:55.880445 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.bias\n","W1105 18:01:55.880521 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.depthwise_kernel\n","W1105 18:01:55.880604 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.pointwise_kernel\n","W1105 18:01:55.880678 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.bias\n","W1105 18:01:55.880754 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.depthwise_kernel\n","W1105 18:01:55.880847 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.pointwise_kernel\n","W1105 18:01:55.880926 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.bias\n","W1105 18:01:55.881007 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.depthwise_kernel\n","W1105 18:01:55.881087 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.pointwise_kernel\n","W1105 18:01:55.881168 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.bias\n","W1105 18:01:55.881266 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.depthwise_kernel\n","W1105 18:01:55.881348 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.pointwise_kernel\n","W1105 18:01:55.881429 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.bias\n","W1105 18:01:55.881507 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.depthwise_kernel\n","W1105 18:01:55.881595 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.pointwise_kernel\n","W1105 18:01:55.881674 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.bias\n","W1105 18:01:55.881768 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.depthwise_kernel\n","W1105 18:01:55.881876 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.pointwise_kernel\n","W1105 18:01:55.881964 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.bias\n","W1105 18:01:55.882047 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.axis\n","W1105 18:01:55.882128 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.gamma\n","W1105 18:01:55.882220 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.beta\n","W1105 18:01:55.882307 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_mean\n","W1105 18:01:55.882387 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_variance\n","W1105 18:01:55.882467 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.axis\n","W1105 18:01:55.882556 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.gamma\n","W1105 18:01:55.882639 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.beta\n","W1105 18:01:55.882719 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_mean\n","W1105 18:01:55.882798 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_variance\n","W1105 18:01:55.882877 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.axis\n","W1105 18:01:55.882956 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.gamma\n","W1105 18:01:55.883034 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.beta\n","W1105 18:01:55.883113 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_mean\n","W1105 18:01:55.883190 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_variance\n","W1105 18:01:55.883288 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.axis\n","W1105 18:01:55.883378 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.gamma\n","W1105 18:01:55.883454 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.beta\n","W1105 18:01:55.883555 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_mean\n","W1105 18:01:55.883637 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_variance\n","W1105 18:01:55.883716 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.axis\n","W1105 18:01:55.883804 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.gamma\n","W1105 18:01:55.883896 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.beta\n","W1105 18:01:55.883975 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_mean\n","W1105 18:01:55.884054 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_variance\n","W1105 18:01:55.884133 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.axis\n","W1105 18:01:55.884226 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.gamma\n","W1105 18:01:55.884309 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.beta\n","W1105 18:01:55.884388 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_mean\n","W1105 18:01:55.884466 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_variance\n","W1105 18:01:55.884544 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.axis\n","W1105 18:01:55.884632 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.gamma\n","W1105 18:01:55.884711 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.beta\n","W1105 18:01:55.884788 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_mean\n","W1105 18:01:55.884867 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_variance\n","W1105 18:01:55.884945 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.axis\n","W1105 18:01:55.885025 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.gamma\n","W1105 18:01:55.885104 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.beta\n","W1105 18:01:55.885182 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_mean\n","W1105 18:01:55.885278 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_variance\n","W1105 18:01:55.885358 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.axis\n","W1105 18:01:55.885438 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.gamma\n","W1105 18:01:55.885517 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.beta\n","W1105 18:01:55.885606 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_mean\n","W1105 18:01:55.885686 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_variance\n","W1105 18:01:55.885764 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.axis\n","W1105 18:01:55.885844 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.gamma\n","W1105 18:01:55.885924 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.beta\n","W1105 18:01:55.886004 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_mean\n","W1105 18:01:55.886085 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_variance\n","W1105 18:01:55.886166 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.axis\n","W1105 18:01:55.886262 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.gamma\n","W1105 18:01:55.886343 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.beta\n","W1105 18:01:55.886421 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_mean\n","W1105 18:01:55.886500 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_variance\n","W1105 18:01:55.886587 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.axis\n","W1105 18:01:55.886668 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.gamma\n","W1105 18:01:55.886746 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.beta\n","W1105 18:01:55.886824 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_mean\n","W1105 18:01:55.886904 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_variance\n","W1105 18:01:55.886982 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.axis\n","W1105 18:01:55.887062 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.gamma\n","W1105 18:01:55.887143 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.beta\n","W1105 18:01:55.887235 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_mean\n","W1105 18:01:55.887317 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_variance\n","W1105 18:01:55.887398 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.axis\n","W1105 18:01:55.887476 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.gamma\n","W1105 18:01:55.887562 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.beta\n","W1105 18:01:55.887644 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_mean\n","W1105 18:01:55.887722 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_variance\n","W1105 18:01:55.887801 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.axis\n","W1105 18:01:55.887880 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.gamma\n","W1105 18:01:55.887959 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.beta\n","W1105 18:01:55.888039 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_mean\n","W1105 18:01:55.888128 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_variance\n","W1105 18:01:55.888221 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.axis\n","W1105 18:01:55.888307 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.gamma\n","W1105 18:01:55.888388 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.beta\n","W1105 18:01:55.888469 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.moving_mean\n","W1105 18:01:55.888555 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.moving_variance\n","W1105 18:01:55.888638 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.axis\n","W1105 18:01:55.888718 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.gamma\n","W1105 18:01:55.888811 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.beta\n","W1105 18:01:55.888893 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.moving_mean\n","W1105 18:01:55.888972 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.moving_variance\n","W1105 18:01:55.889051 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.axis\n","W1105 18:01:55.889131 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.gamma\n","W1105 18:01:55.889224 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.beta\n","W1105 18:01:55.889309 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.moving_mean\n","W1105 18:01:55.889391 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.moving_variance\n","W1105 18:01:55.889470 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.axis\n","W1105 18:01:55.889556 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.gamma\n","W1105 18:01:55.889638 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.beta\n","W1105 18:01:55.889719 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.moving_mean\n","W1105 18:01:55.889798 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.moving_variance\n","W1105 18:01:55.889879 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.axis\n","W1105 18:01:55.889961 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.gamma\n","W1105 18:01:55.890041 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.beta\n","W1105 18:01:55.890120 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.moving_mean\n","W1105 18:01:55.890202 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.moving_variance\n","W1105 18:01:55.890302 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.axis\n","W1105 18:01:55.890383 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.gamma\n","W1105 18:01:55.890464 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.beta\n","W1105 18:01:55.890543 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.moving_mean\n","W1105 18:01:55.890633 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.moving_variance\n","W1105 18:01:55.890714 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.axis\n","W1105 18:01:55.890794 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.gamma\n","W1105 18:01:55.890873 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.beta\n","W1105 18:01:55.890951 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.moving_mean\n","W1105 18:01:55.891031 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.moving_variance\n","W1105 18:01:55.891110 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.axis\n","W1105 18:01:55.891190 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.gamma\n","W1105 18:01:55.891285 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.beta\n","W1105 18:01:55.891365 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.moving_mean\n","W1105 18:01:55.891442 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.moving_variance\n","W1105 18:01:55.891520 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.axis\n","W1105 18:01:55.891607 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.gamma\n","W1105 18:01:55.891687 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.beta\n","W1105 18:01:55.891767 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.moving_mean\n","W1105 18:01:55.891846 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.moving_variance\n","W1105 18:01:55.891926 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.axis\n","W1105 18:01:55.892005 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.gamma\n","W1105 18:01:55.892083 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.beta\n","W1105 18:01:55.892162 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.moving_mean\n","W1105 18:01:55.892262 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.moving_variance\n","W1105 18:01:55.892344 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.axis\n","W1105 18:01:55.892423 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.gamma\n","W1105 18:01:55.892501 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.beta\n","W1105 18:01:55.892588 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.moving_mean\n","W1105 18:01:55.892669 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.moving_variance\n","W1105 18:01:55.892749 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.axis\n","W1105 18:01:55.892827 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.gamma\n","W1105 18:01:55.892907 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.beta\n","W1105 18:01:55.892987 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.moving_mean\n","W1105 18:01:55.893068 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.moving_variance\n","W1105 18:01:55.893148 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.axis\n","W1105 18:01:55.893245 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.gamma\n","W1105 18:01:55.893328 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.beta\n","W1105 18:01:55.893409 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.moving_mean\n","W1105 18:01:55.893488 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.moving_variance\n","W1105 18:01:55.893574 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.axis\n","W1105 18:01:55.893657 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.gamma\n","W1105 18:01:55.893736 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.beta\n","W1105 18:01:55.893814 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.moving_mean\n","W1105 18:01:55.893893 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.moving_variance\n","W1105 18:01:55.893972 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.axis\n","W1105 18:01:55.894052 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.gamma\n","W1105 18:01:55.894140 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.beta\n","W1105 18:01:55.894231 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.moving_mean\n","W1105 18:01:55.894311 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.moving_variance\n","W1105 18:01:55.894390 140093162129280 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.moving_variance\n","WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n","W1105 18:01:55.894538 140093162129280 util.py:158] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n","WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n","W1105 18:02:05.826858 140089592600320 optimizer_v2.py:1275] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W1105 18:02:07.029124 140089592600320 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n","W1105 18:02:17.477499 140089592600320 optimizer_v2.py:1275] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n","INFO:tensorflow:Step 100 per-step time 1.236s loss=1.692\n","I1105 18:04:30.822487 140093162129280 model_lib_v2.py:652] Step 100 per-step time 1.236s loss=1.692\n","Traceback (most recent call last):\n","  File \"/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research//object_detection/model_main_tf2.py\", line 113, in <module>\n","    tf.compat.v1.app.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research//object_detection/model_main_tf2.py\", line 110, in main\n","    record_summaries=FLAGS.record_summaries)\n","  File \"/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/model_lib_v2.py\", line 639, in train_loop\n","    loss = _dist_train_step(train_input_iter)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n","    result = self._call(*args, **kwds)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 807, in _call\n","    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\n","    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\n","    cancellation_manager=cancellation_manager)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\n","    ctx, args, cancellation_manager=cancellation_manager))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 550, in call\n","    ctx=ctx)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n","    inputs, attrs, num_outputs)\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rLXLCzdS4wNO","executionInfo":{"status":"ok","timestamp":1604599498295,"user_tz":480,"elapsed":374,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"ca0fa9ff-91ab-49ac-8824-034d7f5c53fe","colab":{"base_uri":"https://localhost:8080/"}},"source":["#see where our model saved weights...\n","model_dir=\"/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/training1\"\n","%ls {model_dir}"],"execution_count":76,"outputs":[{"output_type":"stream","text":[" checkpoint                            'Copy of ckpt-24.data-00000-of-00001'\n"," ckpt-1.data-00000-of-00001            'Copy of ckpt-24.index'\n"," ckpt-1.index                          'Copy of ckpt-25.data-00000-of-00001'\n"," ckpt-35.index                         'Copy of ckpt-26.index'\n"," ckpt-36.index                         'Copy of ckpt-27.data-00000-of-00001'\n"," ckpt-38.index                         'Copy of ckpt-28.data-00000-of-00001'\n"," ckpt-39.data-00000-of-00001           'Copy of ckpt-28.index'\n"," ckpt-39.index                         'Copy of ckpt-29.data-00000-of-00001'\n"," ckpt-40.index                         'Copy of ckpt-29.index'\n"," ckpt-41.data-00000-of-00001           'Copy of ckpt-30.index'\n"," ckpt-41.index                         'Copy of ckpt-31.data-00000-of-00001'\n","'Copy of ckpt-10.data-00000-of-00001'  'Copy of ckpt-31.index'\n","'Copy of ckpt-10.index'                'Copy of ckpt-32.data-00000-of-00001'\n","'Copy of ckpt-11.index'                'Copy of ckpt-32.index'\n","'Copy of ckpt-12.index'                'Copy of ckpt-33.data-00000-of-00001'\n","'Copy of ckpt-14.data-00000-of-00001'  'Copy of ckpt-33.index'\n","'Copy of ckpt-14.index'                'Copy of ckpt-34.data-00000-of-00001'\n","'Copy of ckpt-15.index'                'Copy of ckpt-34.index'\n","'Copy of ckpt-20.data-00000-of-00001'  'Copy of ckpt-36.data-00000-of-00001'\n","'Copy of ckpt-20.index'                'Copy of ckpt-36.index'\n","'Copy of ckpt-21.data-00000-of-00001'  'Copy of ckpt-9.index'\n","'Copy of ckpt-21.index'                 \u001b[0m\u001b[01;34mtrain\u001b[0m/\n","'Copy of ckpt-22.index'                 \u001b[01;34mtrain_log2\u001b[0m/\n","'Copy of ckpt-23.index'                 \u001b[01;34mtrain_log3\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SRLHcFwQ4yUS"},"source":["**Save model**"]},{"cell_type":"code","metadata":{"id":"eWf21WFN41dq","executionInfo":{"status":"ok","timestamp":1604599582329,"user_tz":480,"elapsed":81422,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"cb7ca5c2-e910-4137-8c5c-867e95472025","colab":{"base_uri":"https://localhost:8080/"}},"source":["#run conversion script\n","import re\n","import numpy as np\n","deploy_path = \"/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/models/research/deploy/\"\n","pipeline_file = deploy_path + 'pipeline_file.config'\n","base_dir=\"/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0\"\n","output_directory = base_dir + '/fine_tuned_model_new'\n","models_research_dir=\"/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/models/research/\"\n","#place the model weights you would like to export here\n","last_model_path = model_dir\n","\n","\n","\n","script_file = models_research_dir + os.path.sep + \"object_detection\" + os.path.sep + \"exporter_main_v2.py\"\n","    \n","print(last_model_path)\n","print(script_file)\n","print(pipeline_file)\n","print(output_directory)\n","!python {models_research_dir}/object_detection/exporter_main_v2.py \\\n","  --trained_checkpoint_dir {last_model_path} --output_directory {output_directory} --pipeline_config_path {pipeline_file}"],"execution_count":77,"outputs":[{"output_type":"stream","text":["/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/training1\n","/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/models/research//object_detection/exporter_main_v2.py\n","/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/models/research/deploy/pipeline_file.config\n","/content/drive/'My Drive'/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model_new\n","2020-11-05 18:05:01.618350: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-11-05 18:05:03.712472: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n","2020-11-05 18:05:03.755290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:05:03.755856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n","2020-11-05 18:05:03.755895: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-11-05 18:05:03.757416: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n","2020-11-05 18:05:03.759043: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n","2020-11-05 18:05:03.759445: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n","2020-11-05 18:05:03.763343: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n","2020-11-05 18:05:03.764583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n","2020-11-05 18:05:03.769654: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n","2020-11-05 18:05:03.769777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:05:03.770362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:05:03.770884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n","2020-11-05 18:05:03.777535: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n","2020-11-05 18:05:03.777814: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1594d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-11-05 18:05:03.777868: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-11-05 18:05:03.884579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:05:03.885298: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1594f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-11-05 18:05:03.885335: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2020-11-05 18:05:03.885544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:05:03.886076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n","2020-11-05 18:05:03.886129: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-11-05 18:05:03.886178: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n","2020-11-05 18:05:03.886203: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n","2020-11-05 18:05:03.886251: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n","2020-11-05 18:05:03.886277: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n","2020-11-05 18:05:03.886300: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n","2020-11-05 18:05:03.886323: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n","2020-11-05 18:05:03.886410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:05:03.886978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:05:03.887531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n","2020-11-05 18:05:03.887586: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-11-05 18:05:04.474138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-11-05 18:05:04.474200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n","2020-11-05 18:05:04.474224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n","2020-11-05 18:05:04.474431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:05:04.475019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-11-05 18:05:04.475554: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-11-05 18:05:04.475598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","I1105 18:05:04.485583 139809166845824 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I1105 18:05:04.485799 139809166845824 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 64\n","I1105 18:05:04.485884 139809166845824 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 3\n","I1105 18:05:04.494764 139809166845824 efficientnet_model.py:147] round_filter input=32 output=32\n","I1105 18:05:04.533253 139809166845824 efficientnet_model.py:147] round_filter input=32 output=32\n","I1105 18:05:04.533365 139809166845824 efficientnet_model.py:147] round_filter input=16 output=16\n","I1105 18:05:04.602282 139809166845824 efficientnet_model.py:147] round_filter input=16 output=16\n","I1105 18:05:04.602394 139809166845824 efficientnet_model.py:147] round_filter input=24 output=24\n","I1105 18:05:04.824060 139809166845824 efficientnet_model.py:147] round_filter input=24 output=24\n","I1105 18:05:04.824261 139809166845824 efficientnet_model.py:147] round_filter input=40 output=40\n","I1105 18:05:05.015515 139809166845824 efficientnet_model.py:147] round_filter input=40 output=40\n","I1105 18:05:05.015651 139809166845824 efficientnet_model.py:147] round_filter input=80 output=80\n","I1105 18:05:05.312540 139809166845824 efficientnet_model.py:147] round_filter input=80 output=80\n","I1105 18:05:05.312687 139809166845824 efficientnet_model.py:147] round_filter input=112 output=112\n","I1105 18:05:05.672814 139809166845824 efficientnet_model.py:147] round_filter input=112 output=112\n","I1105 18:05:05.672966 139809166845824 efficientnet_model.py:147] round_filter input=192 output=192\n","I1105 18:05:06.048702 139809166845824 efficientnet_model.py:147] round_filter input=192 output=192\n","I1105 18:05:06.048858 139809166845824 efficientnet_model.py:147] round_filter input=320 output=320\n","I1105 18:05:06.133954 139809166845824 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I1105 18:05:06.170325 139809166845824 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f271eb78c50>, because it is not built.\n","W1105 18:05:25.645783 139809166845824 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f271eb78c50>, because it is not built.\n","2020-11-05 18:05:47.450684: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5470>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5438>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I1105 18:06:01.821987 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5470>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5438>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a588>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a5f8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a908>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I1105 18:06:01.822298 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a588>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a5f8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a908>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4390>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4710>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I1105 18:06:01.822516 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4390>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4710>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c240>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c2b0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c5c0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I1105 18:06:01.822689 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c240>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c2b0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c5c0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5470>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5438>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I1105 18:06:06.020305 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5470>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5438>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a588>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a5f8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a908>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I1105 18:06:06.020582 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a588>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a5f8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a908>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4390>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4710>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I1105 18:06:06.020795 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4390>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4710>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c240>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c2b0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c5c0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I1105 18:06:06.020962 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c240>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c2b0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c5c0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4390>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4710>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I1105 18:06:06.021136 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4390>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4710>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c240>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c2b0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c5c0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I1105 18:06:06.021489 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c240>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c2b0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c5c0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5470>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5438>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I1105 18:06:09.137240 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5470>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5438>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a588>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a5f8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a908>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I1105 18:06:09.137537 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a588>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a5f8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a908>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4390>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4710>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I1105 18:06:09.137752 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4390>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4710>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c240>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c2b0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c5c0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I1105 18:06:09.137913 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c240>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c2b0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c5c0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5470>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5438>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I1105 18:06:09.414218 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5470>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5438>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a588>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a5f8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a908>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I1105 18:06:09.414460 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a588>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a5f8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a908>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4390>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4710>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I1105 18:06:09.414650 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4390>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4710>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c240>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c2b0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c5c0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I1105 18:06:09.414810 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c240>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c2b0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c5c0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4390>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4710>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I1105 18:06:09.414980 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4390>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4710>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c240>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c2b0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c5c0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I1105 18:06:09.415128 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c240>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c2b0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c5c0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5470>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5438>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I1105 18:06:16.902160 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5470>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f270ffc5438>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a588>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a5f8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a908>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I1105 18:06:16.902480 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a588>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a5f8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271005a908>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4390>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4710>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I1105 18:06:16.902865 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4390>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4400>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27105f4710>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c240>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c2b0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c5c0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I1105 18:06:16.903071 139809166845824 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c240>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c2b0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f271031c5c0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Assets written to: /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model_new/saved_model/assets\n","I1105 18:06:18.344789 139809166845824 builder_impl.py:775] Assets written to: /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model_new/saved_model/assets\n","INFO:tensorflow:Writing pipeline config file to /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model_new/pipeline.config\n","I1105 18:06:19.727862 139809166845824 config_util.py:254] Writing pipeline config file to /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model_new/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ejdelKKKRlE2","executionInfo":{"status":"ok","timestamp":1603826721074,"user_tz":420,"elapsed":1069,"user":{"displayName":"Subhi asati","photoUrl":"","userId":"12937930425121675107"}},"outputId":"ac243592-563c-4396-b1e7-41b2b9878a53","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["%pwd\n","%cd ..\n","%pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"mWe0tAzboXMv"},"source":["**Fine Tuned Model evaluation** on Test Data \n","\n"]},{"cell_type":"code","metadata":{"id":"jb7Vt5tOoVWU"},"source":["from object_detection.utils import config_util\n","from object_detection.builders import model_builder\n","from object_detection.utils import label_map_util\n","#deploy_path = \"/content/drive/'My Drive'/SocialDistance/DPDM/EfficientDetD0/models/research/deploy/\"\n","pipeline_file = '/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/pipeline.config'\n","#pipeline_file = '/home/farstrider/TensorFlow/Deployments/efficientNet_16000steps_noSmallPeople/pipeline_file.config'\n","#recover our saved model\n","pipeline_config = pipeline_file\n","#generally you want to put the last ckpt from training in here\n","model_dir = '/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/training1/ckpt-41'\n","configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n","model_config = configs['model']\n","detection_model = model_builder.build(model_config=model_config, is_training=False)\n","\n","# Restore checkpoint\n","ckpt = tf.compat.v2.train.Checkpoint(\n","      model=detection_model)\n","ckpt.restore(os.path.join('/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/training1/ckpt-41'))\n","def get_model_detection_function(model):\n","  \"\"\"Get a tf.function for detection.\"\"\"\n","\n","  @tf.function\n","  def detect_fn(image):\n","    \"\"\"Detect objects in image.\"\"\"\n","\n","    image, shapes = model.preprocess(image)\n","    prediction_dict = model.predict(image, shapes)\n","    detections = model.postprocess(prediction_dict, shapes)\n","\n","    return detections, prediction_dict, tf.reshape(shapes, [-1])\n","\n","  return detect_fn\n","\n","detect_fn = get_model_detection_function(detection_model)\n","\n","#map labels for inference decoding\n","label_map_path = configs['eval_input_config'].label_map_path\n","label_map = label_map_util.load_labelmap(label_map_path)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map,\n","    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n","    use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-HTPTLNAh-GO","executionInfo":{"status":"ok","timestamp":1603826892515,"user_tz":420,"elapsed":546,"user":{"displayName":"Subhi asati","photoUrl":"","userId":"12937930425121675107"}},"outputId":"85a2db8a-6448-4b9a-eb95-db4f2afd7d04","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%pwd\n","%cd {models_research_dir}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"885LBbZ5oiq8","executionInfo":{"status":"ok","timestamp":1603827444307,"user_tz":420,"elapsed":550731,"user":{"displayName":"Subhi asati","photoUrl":"","userId":"12937930425121675107"}},"outputId":"5ae50a3e-4089-43b9-92a3-992105e810d2","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python3 '/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/model_main_tf2.py' \\\n","    --pipeline_config_path='/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/pipeline.config' \\\n","    --model_dir='/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/' \\\n","    --checkpoint_dir='/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/' \\\n","    --run_once=True \\\n","    --alsologtostderror"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-10-27 19:28:14.516554: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W1027 19:28:17.409800 140482491996032 model_lib_v2.py:925] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n","I1027 19:28:17.410074 140482491996032 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I1027 19:28:17.410182 140482491996032 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I1027 19:28:17.410275 140482491996032 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W1027 19:28:17.410399 140482491996032 model_lib_v2.py:940] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","2020-10-27 19:28:17.422552: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n","2020-10-27 19:28:17.428566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 19:28:17.429230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s\n","2020-10-27 19:28:17.429272: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-10-27 19:28:17.431204: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n","2020-10-27 19:28:17.433029: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n","2020-10-27 19:28:17.433396: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n","2020-10-27 19:28:17.435735: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n","2020-10-27 19:28:17.436777: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n","2020-10-27 19:28:17.441004: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n","2020-10-27 19:28:17.441165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 19:28:17.441869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 19:28:17.442503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n","2020-10-27 19:28:17.442852: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2020-10-27 19:28:17.448722: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000140000 Hz\n","2020-10-27 19:28:17.448946: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1454f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-10-27 19:28:17.448983: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-10-27 19:28:17.536321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 19:28:17.537083: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1455100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-10-27 19:28:17.537117: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n","2020-10-27 19:28:17.537328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 19:28:17.537987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s\n","2020-10-27 19:28:17.538035: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-10-27 19:28:17.538087: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n","2020-10-27 19:28:17.538111: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n","2020-10-27 19:28:17.538135: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n","2020-10-27 19:28:17.538157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n","2020-10-27 19:28:17.538178: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n","2020-10-27 19:28:17.538200: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n","2020-10-27 19:28:17.538278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 19:28:17.538892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 19:28:17.539516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n","2020-10-27 19:28:17.539569: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-10-27 19:28:18.222713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-10-27 19:28:18.222782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n","2020-10-27 19:28:18.222796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n","2020-10-27 19:28:18.223057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 19:28:18.223763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 19:28:18.224389: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-10-27 19:28:18.224443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14299 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n","I1027 19:28:18.235952 140482491996032 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I1027 19:28:18.236154 140482491996032 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 64\n","I1027 19:28:18.236238 140482491996032 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 3\n","I1027 19:28:18.246418 140482491996032 efficientnet_model.py:147] round_filter input=32 output=32\n","I1027 19:28:18.289326 140482491996032 efficientnet_model.py:147] round_filter input=32 output=32\n","I1027 19:28:18.289514 140482491996032 efficientnet_model.py:147] round_filter input=16 output=16\n","I1027 19:28:18.366111 140482491996032 efficientnet_model.py:147] round_filter input=16 output=16\n","I1027 19:28:18.366293 140482491996032 efficientnet_model.py:147] round_filter input=24 output=24\n","I1027 19:28:18.585692 140482491996032 efficientnet_model.py:147] round_filter input=24 output=24\n","I1027 19:28:18.585893 140482491996032 efficientnet_model.py:147] round_filter input=40 output=40\n","I1027 19:28:18.911958 140482491996032 efficientnet_model.py:147] round_filter input=40 output=40\n","I1027 19:28:18.912140 140482491996032 efficientnet_model.py:147] round_filter input=80 output=80\n","I1027 19:28:19.247019 140482491996032 efficientnet_model.py:147] round_filter input=80 output=80\n","I1027 19:28:19.247193 140482491996032 efficientnet_model.py:147] round_filter input=112 output=112\n","I1027 19:28:19.585232 140482491996032 efficientnet_model.py:147] round_filter input=112 output=112\n","I1027 19:28:19.585443 140482491996032 efficientnet_model.py:147] round_filter input=192 output=192\n","I1027 19:28:20.052218 140482491996032 efficientnet_model.py:147] round_filter input=192 output=192\n","I1027 19:28:20.052420 140482491996032 efficientnet_model.py:147] round_filter input=320 output=320\n","I1027 19:28:20.151621 140482491996032 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I1027 19:28:20.194237 140482491996032 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/test_labels.record']\n","I1027 19:28:20.273613 140482491996032 dataset_builder.py:148] Reading unweighted datasets: ['/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/test_labels.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/test_labels.record']\n","I1027 19:28:20.275774 140482491996032 dataset_builder.py:77] Reading record datasets for input file: ['/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/test_labels.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I1027 19:28:20.275982 140482491996032 dataset_builder.py:78] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W1027 19:28:20.276082 140482491996032 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","W1027 19:28:20.278427 140482491996032 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W1027 19:28:20.304145 140482491996032 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W1027 19:28:24.219494 140482491996032 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/inputs.py:262: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1027 19:28:25.735596 140482491996032 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/inputs.py:262: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Waiting for new checkpoint at /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/\n","I1027 19:28:28.545088 140482491996032 checkpoint_utils.py:125] Waiting for new checkpoint at /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/\n","INFO:tensorflow:Found new checkpoint at /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/ckpt-0\n","I1027 19:28:28.548909 140482491996032 checkpoint_utils.py:134] Found new checkpoint at /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/ckpt-0\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/model_lib_v2.py:702: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n","Instructions for updating:\n","Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","W1027 19:28:31.725059 140482491996032 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/model_lib_v2.py:702: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n","Instructions for updating:\n","Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/eval_util.py:878: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1027 19:28:54.708043 140482491996032 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/eval_util.py:878: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2020-10-27 19:29:01.704052: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n","2020-10-27 19:29:02.109147: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n","INFO:tensorflow:Finished eval step 0\n","I1027 19:29:04.399722 140482491996032 model_lib_v2.py:799] Finished eval step 0\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/utils/visualization_utils.py:617: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W1027 19:29:05.201099 140482491996032 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/utils/visualization_utils.py:617: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","INFO:tensorflow:Finished eval step 100\n","I1027 19:29:13.312013 140482491996032 model_lib_v2.py:799] Finished eval step 100\n","INFO:tensorflow:Performing evaluation on 195 images.\n","I1027 19:29:20.049197 140482491996032 coco_evaluation.py:282] Performing evaluation on 195 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I1027 19:29:20.050187 140482491996032 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.01s)\n","I1027 19:29:20.061943 140482491996032 coco_tools.py:138] DONE (t=0.01s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.73s).\n","Accumulating evaluation results...\n","DONE (t=0.19s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.522\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.396\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.220\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.392\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.442\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.664\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738\n","INFO:tensorflow:Eval metrics at step 0\n","I1027 19:29:21.009950 140482491996032 model_lib_v2.py:853] Eval metrics at step 0\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.361929\n","I1027 19:29:21.019339 140482491996032 model_lib_v2.py:856] \t+ DetectionBoxes_Precision/mAP: 0.361929\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.522479\n","I1027 19:29:21.021418 140482491996032 model_lib_v2.py:856] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.522479\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.395778\n","I1027 19:29:21.022803 140482491996032 model_lib_v2.py:856] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.395778\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.000000\n","I1027 19:29:21.024442 140482491996032 model_lib_v2.py:856] \t+ DetectionBoxes_Precision/mAP (small): 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.220115\n","I1027 19:29:21.027587 140482491996032 model_lib_v2.py:856] \t+ DetectionBoxes_Precision/mAP (medium): 0.220115\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.391830\n","I1027 19:29:21.028845 140482491996032 model_lib_v2.py:856] \t+ DetectionBoxes_Precision/mAP (large): 0.391830\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.441871\n","I1027 19:29:21.030112 140482491996032 model_lib_v2.py:856] \t+ DetectionBoxes_Recall/AR@1: 0.441871\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.663869\n","I1027 19:29:21.031432 140482491996032 model_lib_v2.py:856] \t+ DetectionBoxes_Recall/AR@10: 0.663869\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.686816\n","I1027 19:29:21.032684 140482491996032 model_lib_v2.py:856] \t+ DetectionBoxes_Recall/AR@100: 0.686816\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n","I1027 19:29:21.033808 140482491996032 model_lib_v2.py:856] \t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.426543\n","I1027 19:29:21.035065 140482491996032 model_lib_v2.py:856] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.426543\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.737521\n","I1027 19:29:21.036526 140482491996032 model_lib_v2.py:856] \t+ DetectionBoxes_Recall/AR@100 (large): 0.737521\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.172215\n","I1027 19:29:21.037559 140482491996032 model_lib_v2.py:856] \t+ Loss/localization_loss: 0.172215\n","INFO:tensorflow:\t+ Loss/classification_loss: 0.850901\n","I1027 19:29:21.038597 140482491996032 model_lib_v2.py:856] \t+ Loss/classification_loss: 0.850901\n","INFO:tensorflow:\t+ Loss/regularization_loss: 0.066348\n","I1027 19:29:21.039609 140482491996032 model_lib_v2.py:856] \t+ Loss/regularization_loss: 0.066348\n","INFO:tensorflow:\t+ Loss/total_loss: 1.089464\n","I1027 19:29:21.040673 140482491996032 model_lib_v2.py:856] \t+ Loss/total_loss: 1.089464\n","INFO:tensorflow:Waiting for new checkpoint at /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/\n","I1027 19:33:28.647585 140482491996032 checkpoint_utils.py:125] Waiting for new checkpoint at /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/\n","Traceback (most recent call last):\n","  File \"/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/model_main_tf2.py\", line 113, in <module>\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/model_main_tf2.py\", line 88, in main\n","    wait_interval=300, timeout=FLAGS.eval_timeout)\n","  File \"/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/model_lib_v2.py\", line 966, in eval_continuously\n","    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 184, in checkpoints_iterator\n","    checkpoint_dir, checkpoint_path, timeout=timeout)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 132, in wait_for_new_checkpoint\n","    time.sleep(seconds_to_sleep)\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TLzJXvyz49QS","executionInfo":{"status":"ok","timestamp":1603827508606,"user_tz":420,"elapsed":739,"user":{"displayName":"Subhi asati","photoUrl":"","userId":"12937930425121675107"}},"outputId":"557569f8-6995-45e3-d8a2-1a42937ad2ad","colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["%ls {base_dir}/\n","%pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" \u001b[0m\u001b[01;34mData\u001b[0m/                               \u001b[01;34mmodels\u001b[0m/      \u001b[01;34mtraining1\u001b[0m/\n"," \u001b[01;34mfine_tuned_model\u001b[0m/                   \u001b[01;34mRun2_copy\u001b[0m/   \u001b[01;34mtraining_copy\u001b[0m/\n"," LSBDMTrainingEfficientnetD0.ipynb   \u001b[01;34mtraining\u001b[0m/   'training steps.docx'\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research'"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"uTQ2uEED5pj9"},"source":["**Tensorboard** Evaluation\n"]},{"cell_type":"code","metadata":{"id":"76J3tb4Kk3P7","executionInfo":{"status":"ok","timestamp":1603827669875,"user_tz":420,"elapsed":620,"user":{"displayName":"Subhi asati","photoUrl":"","userId":"12937930425121675107"}},"outputId":"d0a66b7e-5010-47c8-b979-838f0e015cd2","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["logs_dir = base_dir + \"/training1/train_log*\"\n","%ls {logs_dir}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["'/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/training1/train_log1':\n","events.out.tfevents.1603739899.14698aced20b.1539.10005.v2\n","\n","'/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/training1/train_log2':\n","events.out.tfevents.1603759180.f40bddea6c1a.1654.10005.v2\n","\n","'/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/training1/train_log3':\n","events.out.tfevents.1603777153.36c49d76bead.1486.10005.v2\n","\n","'/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/training1/train_log4':\n","events.out.tfevents.1603816598.ddc3da09c971.1314.10005.v2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zP0UeckL5A7v"},"source":["# first install it\n","!pip install tensorboard\n","\n","\n","logs_dir = base_dir + \"/training1/train_log4\"\n","%ls {logs_dir}\n","\n","\n","\n","%reload_ext tensorboard\n","%tensorboard --logdir {logs_dir}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nY7VO7aY5E7S"},"source":["**Inference**\n"]},{"cell_type":"code","metadata":{"id":"Fx1tvL3NiH97","executionInfo":{"status":"ok","timestamp":1603827757766,"user_tz":420,"elapsed":694,"user":{"displayName":"Subhi asati","photoUrl":"","userId":"12937930425121675107"}},"outputId":"a2fa73a2-7b75-4abb-8e64-cd11af2d8ebe","colab":{"base_uri":"https://localhost:8080/","height":837}},"source":["!printenv\n","%pwd\n","%cd {models_dir}\n","%pwd\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CUDNN_VERSION=7.6.5.32\n","__EGL_VENDOR_LIBRARY_DIRS=/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/\n","LD_LIBRARY_PATH=/usr/lib64-nvidia\n","CLOUDSDK_PYTHON=python3\n","_=/usr/bin/printenv\n","LANG=en_US.UTF-8\n","HOSTNAME=ddc3da09c971\n","OLDPWD=/\n","CLOUDSDK_CONFIG=/content/.config\n","KMP_INIT_AT_FORK=FALSE\n","NVIDIA_VISIBLE_DEVICES=all\n","DATALAB_SETTINGS_OVERRIDES={\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\"172.28.0.2\\\"\"]}\n","TF2_BEHAVIOR=1\n","ENV=/root/.bashrc\n","PAGER=cat\n","NCCL_VERSION=2.7.8\n","TF_FORCE_GPU_ALLOW_GROWTH=true\n","JPY_PARENT_PID=24\n","NO_GCE_CHECK=True\n","PWD=/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research\n","HOME=/root\n","LAST_FORCED_REBUILD=20201013\n","CLICOLOR=1\n","DEBIAN_FRONTEND=noninteractive\n","KMP_DUPLICATE_LIB_OK=True\n","LIBRARY_PATH=/usr/local/cuda/lib64/stubs\n","GCE_METADATA_TIMEOUT=0\n","GLIBCPP_FORCE_NEW=1\n","TBE_CREDS_ADDR=172.28.0.1:8008\n","TERM=xterm-color\n","SHELL=/bin/bash\n","GCS_READ_CACHE_BLOCK_SIZE_MB=16\n","PYTHONWARNINGS=ignore:::pip._internal.cli.base_command\n","MPLBACKEND=module://ipykernel.pylab.backend_inline\n","CUDA_PKG_VERSION=10-1=10.1.243-1\n","CUDA_VERSION=10.1.243\n","NVIDIA_DRIVER_CAPABILITIES=compute,utility\n","SHLVL=2\n","PYTHONPATH=/env/python:./:./slim/:../official/:../../models\n","NVIDIA_REQUIRE_CUDA=cuda>=10.1 brand=tesla,driver>=396,driver<397 brand=tesla,driver>=410,driver<411 brand=tesla,driver>=418,driver<419\n","COLAB_GPU=1\n","GLIBCXX_FORCE_NEW=1\n","PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n","LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\n","GIT_PAGER=cat\n","/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models'"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"L-gmq-vmC9JR","executionInfo":{"status":"ok","timestamp":1604598535036,"user_tz":480,"elapsed":784,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"fccca8e0-9dbb-4c75-9cce-85827a1e4d57","colab":{"base_uri":"https://localhost:8080/"}},"source":["\n","%pwd\n","%cd {models_dir}\n"],"execution_count":34,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JC_a2NFtaO5Z","executionInfo":{"status":"error","timestamp":1604598574442,"user_tz":480,"elapsed":349,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"}},"outputId":"92ee914c-c6d7-49ea-8e5a-09fa2af1ba12","colab":{"base_uri":"https://localhost:8080/","height":368}},"source":["import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import io\n","import scipy.misc\n","import os\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","import cv2\n","\n","import tensorflow as tf\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","%matplotlib inline"],"execution_count":36,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-570850682297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mviz_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'label_map_util'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"AW1IlDPHZ2hn"},"source":["def plot_detections(image_np,\n","                    boxes,\n","                    classes,\n","                    scores,\n","                    category_index,\n","                    figsize=(12, 16),\n","                    image_name=None):\n","  \"\"\"Wrapper function to visualize detections.\n","\n","  Args:\n","    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n","    boxes: a numpy array of shape [N, 4]\n","    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n","      and match the keys in the label map.\n","    scores: a numpy array of shape [N] or None.  If scores=None, then\n","      this function assumes that the boxes to be plotted are groundtruth\n","      boxes and plot all boxes as black with no classes or scores.\n","    category_index: a dict containing category dictionaries (each holding\n","      category index `id` and category name `name`) keyed by category indices.\n","    figsize: size for the figure.\n","    image_name: a name for the image file.\n","  \"\"\"\n","  image_np_with_annotations = image_np.copy()\n","  viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_annotations,\n","      boxes,\n","      classes,\n","      scores,\n","      category_index,\n","      use_normalized_coordinates=True,\n","      min_score_thresh=0.8)\n","  if image_name:\n","    plt.imsave(image_name, image_np_with_annotations)\n","  else:\n","    plt.imshow(image_np_with_annotations)\n","\n","def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: the file path to the image\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\n","  image = Image.open(BytesIO(img_data))\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)\n","\n","def load_grayscale_image_into_numpy_array(path):\n","  # read in image as grayscale cv2 image\n","  img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n","  # convert image to rgb\n","  backtorgb = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n","  return backtorgb.astype(np.uint8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gRD7ru18Zqu_"},"source":["def load_rgb_image_into_numpy_array(path):\n","  # read in image as grayscale cv2 image\n","  img = cv2.imread(path, cv2.IMREAD_COLOR)\n","  im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","  return im_rgb\n","  #return img\n","  # convert image to rgb\n","  #backtorgb = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n","  #return backtorgb.astype(np.uint8)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vdebm5Shmwrd"},"source":["pipeline_file = '/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/pipeline.config'\n","#recover our saved model\n","pipeline_config = pipeline_file\n","#generally you want to put the last ckpt from training in here\n","model_dir = '/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/training1/ckpt-41'\n","configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n","model_config = configs['model']\n","#from object_detection.builders import model_builder\n","detection_model = model_builder.build(model_config=model_config, is_training=False)\n","\n","# Restore checkpoint\n","ckpt = tf.compat.v2.train.Checkpoint(\n","      model=detection_model)\n","ckpt.restore(os.path.join('/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/training1/ckpt-41'))\n","\n","def get_model_detection_function(model):\n","  \"\"\"Get a tf.function for detection.\"\"\"\n","\n","  @tf.function\n","  def detect_fn(image):\n","    \"\"\"Detect objects in image.\"\"\"\n","\n","    image, shapes = model.preprocess(image)\n","    prediction_dict = model.predict(image, shapes)\n","    detections = model.postprocess(prediction_dict, shapes)\n","\n","    return detections, prediction_dict, tf.reshape(shapes, [-1])\n","\n","  return detect_fn\n","\n","detect_fn = get_model_detection_function(detection_model)\n","\n","#map labels for inference decoding\n","label_map_path = configs['eval_input_config'].label_map_path\n","label_map = label_map_util.load_labelmap(label_map_path)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map,\n","    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n","    use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F1EpIi4kZH9z","executionInfo":{"status":"ok","timestamp":1603933063455,"user_tz":420,"elapsed":231672,"user":{"displayName":"Subhi asati","photoUrl":"","userId":"12937930425121675107"}},"outputId":"e0571e8c-c09e-4c70-f44b-66ac99af0cb9","colab":{"base_uri":"https://localhost:8080/"}},"source":["import cv2\n","import glob\n","import os\n","from PIL import Image\n","\n","# wherever your test images now live \n","TEST_IMAGE_PATHS = glob.glob('/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/TestData_LBSDM/images/*.jpg')\n","textFile= '/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/TestData_LBSDM/TestImagesTensorOutput_results3.txt'\n","file = open(textFile, \"w\")\n","for image_path in TEST_IMAGE_PATHS:\n","    # load image into np array\n","    image_np = load_rgb_image_into_numpy_array(image_path)\n","    # convert to input tensor ?\n","    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n","    # run detect_fun on input tensor\n","    detections, predictions_dict, shapes = detect_fn(input_tensor)\n","    # start labels at 1 instead of 0?\n","    label_id_offset = 1\n","    # make a copy of np image\n","    image_np_with_detections = image_np.copy()\n","    # add bounding boxes and labels to image\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","          image_np_with_detections,\n","          detections['detection_boxes'][0].numpy(),\n","          (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n","          detections['detection_scores'][0].numpy(),\n","          category_index,\n","          use_normalized_coordinates=True,\n","          max_boxes_to_draw=200,\n","          min_score_thresh=.5,\n","          agnostic_mode=False,\n","    )\n","    # get the output path for writing results (i'm tacking on bb_ to the names so i can easily identify them as\n","    # having been annotated)\n","    output_path = os.path.join(os.path.dirname(image_path), \"results_3\", \"bb_\" + os.path.basename(image_path))\n","    # convert to a PIL Image for writing\n","    save_image = Image.fromarray(image_np_with_detections)\n","    # write to file\n","    save_image.save(output_path)\n","    s3 = os.path.basename(image_path)+\" tensor array:\" + str(detections['detection_multiclass_scores'][0][:10])+'\\n'\n","    file.write(s3)\n","    s4=\"     Prediction boxes =\"+str(detections['detection_boxes'][0][:10]) + \"\\n\"\n","    file.write(s4) \n","file.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 245 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 245 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 246 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 246 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 247 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 247 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 248 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 248 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 249 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 249 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:10 out of the last 250 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:10 out of the last 250 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).step\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).step\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.boxes\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.boxes\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.classes\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.classes\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.confidences\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.confidences\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.is_crowd\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.is_crowd\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.group_of\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.group_of\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.groundtruth_area\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.groundtruth_area\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.groundtruth_labeled_classes\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists.groundtruth_labeled_classes\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-0.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-0.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-2.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-2.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-3.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-3.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-3.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-3.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-4.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-4.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-4.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-4.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-5.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-5.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-5.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-5.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-6.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-6.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-7.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-7.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-7.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-7.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-8.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-8.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-9.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-9.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-9.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-9.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-10.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-10.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-11.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-11.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-11.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-11.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-12.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-12.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-12.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-12.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-13.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-13.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-13.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-13.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-14.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-14.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-15.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-15.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-15.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-15.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-16.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-16.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-17.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-17.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-17.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-17.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-18.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-18.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-19.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-19.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-19.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-19.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-20.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-20.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-20.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-20.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-21.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-21.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-21.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-21.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-22.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-22.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-23.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-23.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-23.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-23.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-24.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-24.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-25.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-25.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-25.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-25.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-26.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-26.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-27.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-27.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-27.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-27.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-28.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-28.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-28.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-28.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-29.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-29.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-29.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-29.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-30.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-30.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-31.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-31.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-31.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-31.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-32.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-32.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-33.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-33.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-33.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-33.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-34.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-34.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-35.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-35.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-35.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-35.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-36.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-36.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-36.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-36.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-37.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-37.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-37.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-37.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-38.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-38.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-39.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-39.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-39.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-39.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-40.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-40.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-41.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-41.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-41.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-41.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-42.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-42.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-43.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-43.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-43.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-43.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-44.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-44.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-44.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-44.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-45.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-45.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-45.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-45.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-46.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-46.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-47.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-47.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-47.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-47.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-48.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-48.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-49.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-49.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-49.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-49.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-50.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-50.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-51.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-51.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-51.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-51.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-52.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-52.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-52.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-52.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-53.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-53.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-53.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-53.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-54.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-54.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-55.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-55.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-55.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-55.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-56.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-56.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-57.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-57.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-57.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-57.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-58.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-58.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-59.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-59.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-59.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-59.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-60.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-60.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-60.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-60.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-61.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-61.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-61.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-61.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-62.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-62.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-63.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-63.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-63.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-63.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-64.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-64.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-65.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-65.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-65.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-65.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-66.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-66.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-67.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-67.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-67.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-67.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-68.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-68.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-68.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-68.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-69.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-69.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-69.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-69.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-70.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-70.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-71.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-71.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-71.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-71.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-72.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-72.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-73.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-73.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-73.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-73.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-74.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-74.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-75.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-75.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-75.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-75.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-76.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-76.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-76.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-76.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-77.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-77.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-77.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-77.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-78.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-78.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-79.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-79.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-79.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-79.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-80.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-80.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-81.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-81.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-81.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-81.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-82.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-82.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-83.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-83.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-83.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-83.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-84.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-84.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-84.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-84.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-85.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-85.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-85.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-85.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-86.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-86.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-87.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-87.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-87.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-87.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-88.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-88.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-89.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-89.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-89.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-89.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-90.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-90.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-91.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-91.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-91.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-91.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-92.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-92.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-92.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-92.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-93.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-93.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-93.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-93.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-94.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-94.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-95.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-95.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-95.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-95.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-96.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-96.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-97.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-97.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-97.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-97.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-98.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-98.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-99.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-99.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-99.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-99.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-100.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-100.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-100.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-100.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-101.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-101.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-101.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-101.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-102.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-102.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-103.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-103.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-103.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-103.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-104.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-104.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-105.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-105.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-105.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-105.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-106.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-106.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-107.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-107.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-107.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-107.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-108.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-108.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-108.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-108.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-109.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-109.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-109.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-109.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-110.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-110.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-111.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-111.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-111.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-111.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-112.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-112.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-113.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-113.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-113.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-113.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-114.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-114.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-115.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-115.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-115.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-115.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-116.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-116.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-116.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-116.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-117.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-117.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-117.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-117.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-118.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-118.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-119.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-119.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-119.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-119.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-120.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-120.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-121.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-121.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-121.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-121.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-122.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-122.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-123.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-123.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-123.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-123.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-124.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-124.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-124.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-124.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-125.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-125.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-125.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-125.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-126.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-126.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-127.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-127.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-127.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._efficientnet.layer_with_weights-127.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor.classification_backbone.layer_with_weights-128.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor.classification_backbone.layer_with_weights-128.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor.classification_backbone.layer_with_weights-130.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor.classification_backbone.layer_with_weights-130.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor.classification_backbone.layer_with_weights-130.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor.classification_backbone.layer_with_weights-130.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.2.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.2.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.3.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.3.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.4.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.4.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.5.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.5.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.6.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.6.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.7.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.7.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.8.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.8.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.9.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.9.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.10.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.10.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.11.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.11.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.12.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.12.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.13.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.13.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.14.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.14.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.15.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.15.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.16.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.16.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.17.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.17.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.18.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.18.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.19.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.19.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.20.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.20.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.21.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.21.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.22.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.22.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.23.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.23.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.24.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.24.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.25.bifpn_combine_weights\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_combine_op.25.bifpn_combine_weights\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.2.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.2.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.2.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.2.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.2.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.2.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.2.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.2.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.2.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.2.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.3.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.3.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.3.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.3.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.3.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.3.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.3.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.3.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.3.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.3.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.4.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.4.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.4.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.4.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.4.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.4.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.4.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.4.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.4.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.4.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.5.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.5.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.5.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.5.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.5.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.5.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.5.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.5.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.5.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.5.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.6.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.6.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.6.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.6.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.6.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.6.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.6.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.6.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.6.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.6.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.7.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.7.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.7.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.7.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.7.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.7.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.7.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.7.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.7.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.7.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.8.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.8.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.8.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.8.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.8.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.8.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.8.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.8.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.8.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.8.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.9.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.9.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.9.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.9.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.9.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.9.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.9.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.9.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.9.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.9.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.10.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.10.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.10.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.10.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.10.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.10.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.10.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.10.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.10.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.10.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.11.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.11.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.11.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.11.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.11.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.11.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.11.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.11.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.11.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.11.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.12.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.12.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.12.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.12.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.12.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.12.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.12.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.12.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.12.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.12.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.13.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.13.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.13.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.13.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.13.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.13.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.13.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.13.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.13.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.13.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.14.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.14.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.14.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.14.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.14.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.14.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.14.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.14.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.14.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.14.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.15.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.15.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.15.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.15.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.15.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.15.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.15.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.15.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.15.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.15.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.16.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.16.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.16.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.16.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.16.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.16.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.16.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.16.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.16.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.16.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.17.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.17.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.17.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.17.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.17.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.17.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.17.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.17.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.17.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.17.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.18.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.18.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.18.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.18.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.18.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.18.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.18.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.18.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.18.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.18.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.19.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.19.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.19.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.19.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.19.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.19.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.19.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.19.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.19.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.19.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.20.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.20.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.20.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.20.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.20.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.20.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.20.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.20.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.20.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.20.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.21.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.21.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.21.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.21.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.21.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.21.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.21.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.21.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.21.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.21.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.22.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.22.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.22.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.22.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.22.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.22.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.22.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.22.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.22.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.22.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.23.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.23.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.23.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.23.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.23.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.23.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.23.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.23.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.23.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.23.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.24.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.24.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.24.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.24.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.24.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.24.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.24.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.24.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.24.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.24.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.25.1.depthwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.25.1.depthwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.25.1.pointwise_kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.25.1.pointwise_kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.25.1.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.25.1.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.25.2.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.25.2.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.25.2.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_post_combine_block.25.2.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.0.0.1.0.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.0.0.1.0.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.0.0.1.0.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.0.0.1.0.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.0.0.1.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.0.0.1.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.0.0.1.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.0.0.1.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.3.0.1.0.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.3.0.1.0.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.3.0.1.0.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.3.0.1.0.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.3.0.1.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.3.0.1.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.3.0.1.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.3.0.1.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.4.0.1.0.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.4.0.1.0.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.4.0.1.0.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.4.0.1.0.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.4.0.1.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.4.0.1.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.4.0.1.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.4.0.1.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.5.0.1.0.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.5.0.1.0.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.5.0.1.0.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.5.0.1.0.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.5.0.1.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.5.0.1.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.5.0.1.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.5.0.1.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.6.0.1.0.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.6.0.1.0.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.6.0.1.0.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.6.0.1.0.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.6.0.1.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.6.0.1.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.6.0.1.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.6.0.1.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.7.0.1.0.kernel\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.7.0.1.0.kernel\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.7.0.1.0.bias\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.7.0.1.0.bias\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.7.0.1.1.gamma\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.7.0.1.1.gamma\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.7.0.1.1.beta\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'momentum' for (root).model._feature_extractor._bifpn_stage.node_input_blocks.7.0.1.1.beta\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 5 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 5 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 6 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 6 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 7 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 7 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 8 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 8 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 9 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 9 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:10 out of the last 10 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:10 out of the last 10 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:10 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:10 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:10 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:10 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 14 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 14 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 16 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 16 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 14 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 14 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbdabfe38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"M75G-8SRNwvO","executionInfo":{"elapsed":2670,"status":"ok","timestamp":1601321791819,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"},"user_tz":420},"outputId":"900d733a-b296-49c6-f8e9-5638d0965d96","colab":{"base_uri":"https://localhost:8080/","height":545}},"source":["#it takes a little longer on the first run and then runs at normal speed. \n","import random\n","import cv2\n","import glob\n","\n","TEST_IMAGE_PATHS = glob.glob('/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/output1/*.jpg')\n","image_path = random.choice(TEST_IMAGE_PATHS)\n","image_np = load_grayscale_image_into_numpy_array(image_path)\n","\n","# Things to try:\n","# Flip horizontally\n","# image_np = np.fliplr(image_np).copy()\n","\n","# Convert image to grayscale\n","# image_np = np.tile(\n","#     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n","\n","input_tensor = tf.convert_to_tensor(\n","    np.expand_dims(image_np, 0), dtype=tf.float32)\n","detections, predictions_dict, shapes = detect_fn(input_tensor)\n","\n","label_id_offset = 1\n","image_np_with_detections = image_np.copy()\n","\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_detections,\n","      detections['detection_boxes'][0].numpy(),\n","      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n","      detections['detection_scores'][0].numpy(),\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=200,\n","      min_score_thresh=.5,\n","      agnostic_mode=False,\n",")\n","\n","plt.figure(figsize=(12,16))\n","plt.imshow(image_np_with_detections)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x1152 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"qizvqwB4P3eq","executionInfo":{"elapsed":804,"status":"ok","timestamp":1601322508788,"user":{"displayName":"Subhangi Asati","photoUrl":"","userId":"07645530506409628939"},"user_tz":420},"outputId":"09b76753-13f2-494a-dd00-9788b29de78d","colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["%ls /content/drive/My\\ Drive/SocialDistance/LSBDMEfficientNetD0/training/\n","from google.colab import files\n","files.download(\"/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/training/\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["checkpoint                   ckpt-38.index\n","ckpt-35.data-00000-of-00001  ckpt-39.data-00000-of-00001\n","ckpt-35.index                ckpt-39.index\n","ckpt-36.data-00000-of-00001  ckpt-40.data-00000-of-00001\n","ckpt-36.index                ckpt-40.index\n","ckpt-37.data-00000-of-00001  ckpt-41.data-00000-of-00001\n","ckpt-37.index                ckpt-41.index\n","ckpt-38.data-00000-of-00001  \u001b[0m\u001b[01;34mtrain\u001b[0m/\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_998953aa-8657-40a9-841d-70a3b402c63c\", \"\", 4096)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"wxKiFXEZ6UIi"},"source":["**Evaluation on Validation Images**"]},{"cell_type":"code","metadata":{"id":"n3oYYFf4pHLM","executionInfo":{"status":"ok","timestamp":1603828829123,"user_tz":420,"elapsed":48341,"user":{"displayName":"Subhi asati","photoUrl":"","userId":"12937930425121675107"}},"outputId":"69e45d68-8c52-430c-f504-05d0e3b19419","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%cd /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/TestData_LBSDM\n","#%pwd\n","# %ls {data_dir}\n","\n","#%cd /content/drive/Shared drives/RetrainTF2DataAndModels/DetectionWeaponsExample_CodeLabBased/data\n","\n","# images extension\n","images_extension = 'jpg'\n","\n","# takes the path of a directory that contains xml files and converts\n","#  them to one csv file.\n","\n","# returns a csv file that contains: image name, width, height, class, xmin, ymin, xmax, ymax.\n","# note: if the xml file contains more than one box/label, it will create more than one row for \n","#the same image. each row contains the info for an individual box. \n","def xml_to_csv(path):\n","  classes_names = []\n","  xml_list = []\n","\n","  for xml_file in glob.glob(path + '/*.xml'):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    for member in root.findall('object'):\n","      classes_names.append(member[0].text)\n","      value = (root.find('filename').text ,\n","               int(root.find('size')[0].text),\n","               int(root.find('size')[1].text),\n","               member[0].text,\n","               int(member[4][0].text),\n","               int(member[4][1].text),\n","               int(member[4][2].text),\n","               int(member[4][3].text))\n","      xml_list.append(value)\n","  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","  xml_df = pd.DataFrame(xml_list, columns=column_name) \n","  classes_names = list(set(classes_names))\n","  classes_names.sort()\n","  return xml_df, classes_names\n","\n","# for both the train_labels and test_labels csv files, it runs the xml_to_csv() above.\n","for label_path in ['annotations']:\n","  image_path = os.path.join(os.getcwd(), label_path)\n","  xml_df, classes = xml_to_csv(label_path)\n","  xml_df.to_csv(f'{label_path}.csv', index=None)\n","  print(f'Successfully converted {label_path} xml to csv.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/TestData_LBSDM\n","Successfully converted annotations xml to csv.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PO9ojWOooWuN","executionInfo":{"status":"ok","timestamp":1603828902278,"user_tz":420,"elapsed":3887,"user":{"displayName":"Subhi asati","photoUrl":"","userId":"12937930425121675107"}},"outputId":"b44eadee-416c-4d22-e472-f6cc166b01e6","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%cd /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research\n","\n","from object_detection.utils import dataset_util\n","\n","\n","#DATA_BASE_PATH = '/content/drive/My Drive/DetectionWeaponsExample_CodeLabBased/data/'\n","#images_dir = '/content/drive/My Drive/DetectionWeaponsExample_CodeLabBased/data/images/'\n","DATA_BASE_PATH = '/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/TestData_LBSDM/'\n","images_dir = '/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/TestData_LBSDM/images/'\n","# problem with the data_dir not evaluating the 'My Drive' into My Drive\n","#DATA_BASE_PATH = data_dir + '/'\n","#image_dir = data_dir +'/images/'\n","# DATA_BASE_PATH = \"/content/drive/Shared drives/RetrainTF2DataAndModels/DetectionWeaponsExample_CodeLabBased/data\"\n","# images_dir = \"/content/drive/Shared drives/RetrainTF2DataAndModels/DetectionWeaponsExample_CodeLabBased/data/images\"\n","# print(\"Data base path \" + DATA_BASE_PATH)\n","\n","print(\"Images path \" + images_dir)\n","\n","#do a list to see if the record file already exists\n","#this will falue when no 'My Drive' and using only My Drive\n","#%ls {DATA_BASE_PATH}\n","\n","#FIX- THIS IS HARDCODED method for converting the class label to its id instead!!!\n","def class_text_to_int(row_label):\n","    if row_label == 'Good':\n","        return 1\n","    elif row_label == 'Caution':\n","        return 2\n","    elif row_label == 'Bad':\n","        return 3\n","    else:\n","        None\n","\n","#some kind of parsing function that create a special DataSet for parsing each image in a loop\n","def split(df, group):\n","\t\tdata = namedtuple('data', ['filename', 'object'])\n","\t\tgb = df.groupby(group)\n","\t\treturn [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n","\n","#This is a function that reads in image from a file (using tf.io package) and its bounding box information and creates\n","# and instance of tf.train.Example that can be used to add to a TFRecord\n","def create_tf_example(group, path):\n","\t\twith tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n","\t\t\t\tencoded_jpg = fid.read()\n","    #open up io stream to file containing image\n","\t\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n","    #open up Image file pointer using the stream previously opened\n","\t\timage = Image.open(encoded_jpg_io)\n","    #retrieve size of image from the data in the Image file pointer (stored in the jpg file)\n","\t\twidth, height = image.size\n","    \n","    \n","\t\tfilename = group.filename.encode('utf8')\n","\t\timage_format = b'jpg'\n","    #setup array to represent all the bounding boxes for this image\n","    # bounding box i upper left point = (xmins[i],ymins[i])  lower right point =(xmaxs[i], ymaxs[i])\n","    # class label of ith' box stored in classes_text[i]\n","    # also as building out this array add to classes[] any unique new classes found\n","\t\txmins = []\n","\t\txmaxs = []\n","\t\tymins = []\n","\t\tymaxs = []\n","\t\tclasses_text = []\n","\t\tclasses = []\n","\n","    #cycle through the rows in the label csv file pased and add in the bounding box info into arrays\n","    #    and corresponding class label.\n","\t\tfor index, row in group.object.iterrows():\n","\t\t\t\txmins.append(row['xmin'] / width)\n","\t\t\t\txmaxs.append(row['xmax'] / width)\n","\t\t\t\tymins.append(row['ymin'] / height)\n","\t\t\t\tymaxs.append(row['ymax'] / height)\n","\t\t\t\tclasses_text.append(row['class'].encode('utf8'))\n","\t\t\t\tclasses.append(class_text_to_int(row['class']))\n","\n","    #build out a tf.train.Example using all the read in information for this image and its bounding boxes\n","    # this will be used later to create a TFRecord\n","    # see https://www.tensorflow.org/tutorials/load_data/tfrecord  for information about tf.train.Example and TFRecord format\n","    # as you can see includes for each image: \n","    #              height, width, filename, the actual image pixel values, image format, \n","    #              and bounding boxes (as arrays of xmin,ymin and xmax,ymax representing the lower-left and upper-right points) \n","\t\ttf_example = tf.train.Example(features=tf.train.Features(feature={\n","\t\t\t\t'image/height': dataset_util.int64_feature(height),\n","\t\t\t\t'image/width': dataset_util.int64_feature(width),\n","\t\t\t\t'image/filename': dataset_util.bytes_feature(filename),\n","\t\t\t\t'image/source_id': dataset_util.bytes_feature(filename),\n","\t\t\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","\t\t\t\t'image/format': dataset_util.bytes_feature(image_format),\n","\t\t\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","\t\t\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","\t\t\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","\t\t\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","\t\t\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","\t\t\t\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n","\t\t}))\n","\t\treturn tf_example\n","\n","#go through the train_labels.csv and afterwards test_lables.csv and create TFRecord files for each\n","#  pd is associated with loaded python Pandas module imported and used to read csv files\n","for csv in ['annotations']:\n","  #use TFrecordWriter to write records to a TFRecord file as specified in path\n","  #see https://www.tensorflow.org/api_docs/python/tf/io/TFRecordWriter\n","  label_file = DATA_BASE_PATH + csv + '.record'\n","  print(\".........going to save TFRecord to \" + label_file)\n"," # label_file = \"/\"\n","  \n","  writer = tf.io.TFRecordWriter(DATA_BASE_PATH + csv + '.record')\n","  #writer = tf.io.TFRecordWriter(dummy2)\n","  path = os.path.join(images_dir)\n","\n","  #read in all the rows in the csv file using pandas module into a pandas DataFrame datastructure\n","  #see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n","  #see https://pandas.pydata.org/pandas-docs/stable/reference/frame.html \n","  # need file to open = \"/gdrive/My Drive/iLab/Covid_ID/Retraining/DetectionWeaponsExample/data/\" + csv + \".csv\"\n","  print(DATA_BASE_PATH + csv + '.csv')\n","  examples = pd.read_csv(DATA_BASE_PATH + csv + '.csv')\n","  \n","\n","  #For each image group it with its bounding boxes\n","  grouped = split(examples, 'filename')\n","\n","  #for each image and its bounding boxes create an instance of tf.train.Example that is\n","  #  written out into a file that is the created TFRecord file\n","  # see https://www.tensorflow.org/tutorials/load_data/tfrecord \n","  # for information about tf.train.Example and TFRecord format\n","  for group in grouped:\n","      print(\" group in loop \")\n","      print(group)\n","      tf_example = create_tf_example(group, path)\n","      writer.write(tf_example.SerializeToString())\n","    \n","  writer.close()\n","  output_path = os.path.join(os.getcwd(), DATA_BASE_PATH + csv + '.record')\n","  print('Successfully created the TFRecords: {}'.format(DATA_BASE_PATH +csv + '.record'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research\n","Images path /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/TestData_LBSDM/images/\n",".........going to save TFRecord to /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/TestData_LBSDM/annotations.record\n","/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/TestData_LBSDM/annotations.csv\n"," group in loop \n","data(filename='2.jpg', object=  filename  width  height class  xmin  ymin  xmax  ymax\n","0    2.jpg    600     437  Good     1   138   176   387\n","1    2.jpg    600     437  Good   120   137   317   216\n","2    2.jpg    600     437  Good   270   134   442   257\n","3    2.jpg    600     437  Good   200   205   570   346\n","4    2.jpg    600     437  Good   399   134   570   345\n","5    2.jpg    600     437  Good   194   139   314   304)\n"," group in loop \n","data(filename='C13.jpg', object=    filename  width  height    class  xmin  ymin  xmax  ymax\n","195  C13.jpg    992     619  Caution   184   172   605   404\n","196  C13.jpg    992     619     Good   352    44   629   366\n","197  C13.jpg    992     619      Bad   633   140   777   314\n","198  C13.jpg    992     619      Bad     9   163   186   338\n","199  C13.jpg    992     619  Caution   707    14   962   272)\n"," group in loop \n","data(filename='D145_299_290_1200.jpg', object=                 filename  width  height    class  xmin  ymin  xmax  ymax\n","15  D145_299_290_1200.jpg   1200     801      Bad   288   197   540   709\n","16  D145_299_290_1200.jpg   1200     801     Good   415   181   843   801\n","17  D145_299_290_1200.jpg   1200     801  Caution   649   179  1154   695)\n"," group in loop \n","data(filename='GettyImages-1208074277-645x645.jpg', object=                              filename  width  height  ... ymin  xmax  ymax\n","20  GettyImages-1208074277-645x645.jpg    645     645  ...  163   459   608\n","21  GettyImages-1208074277-645x645.jpg    645     645  ...  151   550   427\n","22  GettyImages-1208074277-645x645.jpg    645     645  ...  150   588   336\n","23  GettyImages-1208074277-645x645.jpg    645     645  ...  131   644   259\n","\n","[4 rows x 8 columns])\n"," group in loop \n","data(filename='c1.jpg', object=    filename  width  height    class  xmin  ymin  xmax  ymax\n","192   c1.jpg    512     341  Caution   179    59   500   255)\n"," group in loop \n","data(filename='c10.jpg', object=    filename  width  height    class  xmin  ymin  xmax  ymax\n","101  c10.jpg   1024     683  Caution   415   156   765   451\n","102  c10.jpg   1024     683      Bad   592   115   995   466\n","103  c10.jpg   1024     683      Bad   210    84   523   448)\n"," group in loop \n","data(filename='c11.jpg', object=    filename  width  height    class  xmin  ymin  xmax  ymax\n","111  c11.jpg   2560    1706  Caution  1111   612  2140  1313\n","112  c11.jpg   2560    1706     Good   965   233  2247   676\n","113  c11.jpg   2560    1706      Bad  1054    78  1663   388)\n"," group in loop \n","data(filename='c12.jpg', object=    filename  width  height    class  xmin  ymin  xmax  ymax\n","193  c12.jpg   1200     799  Caution   546   189  1180   711\n","194  c12.jpg   1200     799     Good     3     3   779   781)\n"," group in loop \n","data(filename='c14.jpg', object=    filename  width  height    class  xmin  ymin  xmax  ymax\n","200  c14.jpg   1200     800  Caution    93   151   988   773)\n"," group in loop \n","data(filename='c15.jpg', object=    filename  width  height    class  xmin  ymin  xmax  ymax\n","201  c15.jpg    612     408  Caution   203   118   413   375\n","202  c15.jpg    612     408      Bad   394   117   536   223\n","203  c15.jpg    612     408      Bad    30    84   214   269)\n"," group in loop \n","data(filename='c2.jpg', object=    filename  width  height    class  xmin  ymin  xmax  ymax\n","204   c2.jpg    800     531  Caution    91    80   433   342\n","205   c2.jpg    800     531  Caution   282    68   715   425)\n"," group in loop \n","data(filename='c3.jpg', object=    filename  width  height    class  xmin  ymin  xmax  ymax\n","206   c3.jpg    720     473  Caution    50    35   650   420\n","207   c3.jpg    720     473     Good   425    26   640   407\n","208   c3.jpg    720     473     Good    35    98   374   353)\n"," group in loop \n","data(filename='c4.jpg', object=    filename  width  height    class  xmin  ymin  xmax  ymax\n","209   c4.jpg    542     288  Caution   180    24   388   214\n","210   c4.jpg    542     288  Caution   300    30   531   229\n","211   c4.jpg    542     288  Caution    23     9   274   257)\n"," group in loop \n","data(filename='caution.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","14  caution.jpg   1000     657  Caution   402    76   687   592)\n"," group in loop \n","data(filename='caution1.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","6  caution1.jpg    640     427  Caution    56   167   442   389)\n"," group in loop \n","data(filename='caution2.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","7  caution2.jpg    952     637  Caution   256   236   879   472)\n"," group in loop \n","data(filename='caution3.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","8  caution3.jpg   1200     630  Caution   240    36   732   545\n","9  caution3.jpg   1200     630  Caution   549   159  1112   510)\n"," group in loop \n","data(filename='caution4.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","10  caution4.jpg   1184    1466  Caution   268   141   872   943)\n"," group in loop \n","data(filename='caution5.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","11  caution5.jpg    672     498  Caution     5   178   496   498)\n"," group in loop \n","data(filename='caution6.jpeg', object=         filename  width  height    class  xmin  ymin  xmax  ymax\n","12  caution6.jpeg    800     494  Caution   164    16   537   480)\n"," group in loop \n","data(filename='caution7.jpg', object=        filename  width  height    class  xmin  ymin  xmax  ymax\n","13  caution7.jpg   1027     547  Caution   174    10   932   546)\n"," group in loop \n","data(filename='download.jpeg', object=         filename  width  height class  xmin  ymin  xmax  ymax\n","18  download.jpeg    275     183   Bad    41    47   127    94\n","19  download.jpeg    275     183  Good    92    47   264   176)\n"," group in loop \n","data(filename='good.jpg', object=    filename  width  height class  xmin  ymin  xmax  ymax\n","32  good.jpg   1152     648  Good    74    12   635   637)\n"," group in loop \n","data(filename='good2.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","24  good2.jpg   1024     512  Good    56    35   988   512)\n"," group in loop \n","data(filename='good3.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","25  good3.jpg   1500    1000  Good   129   131  1339   990)\n"," group in loop \n","data(filename='good4.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","26  good4.jpg    626     352  Good    83    58   537   352)\n"," group in loop \n","data(filename='good6.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","27  good6.jpg    943     615  Good   191    73   779   565)\n"," group in loop \n","data(filename='good7.png', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","28  good7.png    800     496  Good     5    18   799   496)\n"," group in loop \n","data(filename='good8.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","29  good8.jpg    660     440  Good    38    61   330   339\n","30  good8.jpg    660     440  Good   256    62   431   338\n","31  good8.jpg    660     440  Good   384    77   603   323)\n"," group in loop \n","data(filename='images (1).jpg', object=          filename  width  height class  xmin  ymin  xmax  ymax\n","33  images (1).jpg    225     225  Good     1     6   160   225)\n"," group in loop \n","data(filename='images (2).jpg', object=          filename  width  height    class  xmin  ymin  xmax  ymax\n","34  images (2).jpg    259     194  Caution    48    56   151   184)\n"," group in loop \n","data(filename='images.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","35  images.jpg    376     134  Caution    40     9   161   133)\n"," group in loop \n","data(filename='img1.jpg', object=    filename  width  height    class  xmin  ymin  xmax  ymax\n","39  img1.jpg    300     168      Bad    48    89   126   167\n","40  img1.jpg    300     168  Caution    91   100   179   168)\n"," group in loop \n","data(filename='img10.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","143  img10.jpg    209     182  Caution    39     9   138   173\n","144  img10.jpg    209     182  Caution    89    10   191    47\n","145  img10.jpg    209     182  Caution     5    29    67   139)\n"," group in loop \n","data(filename='img11.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","146  img11.jpg    310     163  Good   106    23   284    94)\n"," group in loop \n","data(filename='img12.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","147  img12.jpg    275     183  Good    29    36   106   117\n","148  img12.jpg    275     183  Good    81    36   148   117\n","149  img12.jpg    275     183  Good   128    25   255   177)\n"," group in loop \n","data(filename='img13.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","123  img13.jpg    300     168  Caution    74     1   231    88)\n"," group in loop \n","data(filename='img15.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","150  img15.jpg    259     194  Good    18    94    68   128\n","151  img15.jpg    259     194  Good    52    91    96   136\n","152  img15.jpg    259     194  Good    83    91   155   148\n","153  img15.jpg    259     194  Good   135    87   259   179)\n"," group in loop \n","data(filename='img16.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","154  img16.jpg    259     194  Caution    85    76   259   168\n","155  img16.jpg    259     194     Good    98    53   256    79)\n"," group in loop \n","data(filename='img17.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","94  img17.jpg    275     183   Bad    15    68    77   183\n","95  img17.jpg    275     183   Bad    76    62   142   183\n","96  img17.jpg    275     183   Bad   104    58   199   183\n","97  img17.jpg    275     183   Bad   141    48   233   183\n","98  img17.jpg    275     183   Bad   198    48   275   183)\n"," group in loop \n","data(filename='img18.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","124  img18.jpg    318     159  Caution    48    53   260   131)\n"," group in loop \n","data(filename='img19.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","125  img19.jpg    275     183  Caution    50    54   232   125)\n"," group in loop \n","data(filename='img2.jpg', object=    filename  width  height class  xmin  ymin  xmax  ymax\n","44  img2.jpg    318     159   Bad    37    77   158   138\n","45  img2.jpg    318     159   Bad    98    77   224   134\n","46  img2.jpg    318     159   Bad   163    55   312   135)\n"," group in loop \n","data(filename='img20.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","156  img20.jpg    299     169  Good    56    31   236    98)\n"," group in loop \n","data(filename='img21.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","157  img21.jpg    259     194  Good    44    84   223   175)\n"," group in loop \n","data(filename='img22.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","126  img22.jpg    275     183  Caution    63    42   217   176)\n"," group in loop \n","data(filename='img23.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","158  img23.jpg    273     184     Good    41    27   199    61\n","159  img23.jpg    273     184  Caution    39    28   128   103\n","160  img23.jpg    273     184  Caution   157     1   259    74\n","161  img23.jpg    273     184     Good    42   105   227   184\n","162  img23.jpg    273     184  Caution    42    60   133   165)\n"," group in loop \n","data(filename='img24.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","163  img24.jpg    299     168  Good    89    75   255   150\n","164  img24.jpg    299     168   Bad   205    52   268   148\n","165  img24.jpg    299     168  Good    41    44   135    75)\n"," group in loop \n","data(filename='img25.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","166  img25.jpg    259     194  Good     6    29   220   132)\n"," group in loop \n","data(filename='img26.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","167  img26.jpg    300     168  Good    99    41   164    95\n","168  img26.jpg    300     168  Good     8    22    81   109\n","169  img26.jpg    300     168  Good   144    31   208   136)\n"," group in loop \n","data(filename='img27.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","99  img27.jpg    367     137   Bad    98    23   298   137)\n"," group in loop \n","data(filename='img28.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","170  img28.jpg    275     184     Good     1    60   109   180\n","171  img28.jpg    275     184     Good    71    60   199   155\n","172  img28.jpg    275     184     Good   173    68   250   144\n","173  img28.jpg    275     184  Caution   207    42   249   128)\n"," group in loop \n","data(filename='img29.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","100  img29.jpg    275     183  Caution    72    11   208   177)\n"," group in loop \n","data(filename='img3.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","141  img3.jpg    299     168  Good    49   106   180   152\n","142  img3.jpg    299     168  Good   163   106   226   131)\n"," group in loop \n","data(filename='img30.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","174  img30.jpg    300     168  Caution    94     8   122    78\n","175  img30.jpg    300     168     Good    33    50   120    78\n","176  img30.jpg    300     168     Good    15    82   189   133\n","177  img30.jpg    300     168     Good   157    56   283   132)\n"," group in loop \n","data(filename='img31.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","104  img31.jpg    275     183   Bad    95    48   186   180\n","105  img31.jpg    275     183   Bad    66    46   131    99)\n"," group in loop \n","data(filename='img32.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","178  img32.jpg    300     168  Caution    15    68    55   109\n","179  img32.jpg    300     168     Good    42    67    85   108\n","180  img32.jpg    300     168     Good    71    67   119   102\n","181  img32.jpg    300     168  Caution   108    73   143   102\n","182  img32.jpg    300     168     Good   132    72   182   100\n","183  img32.jpg    300     168     Good   172    71   216   102\n","184  img32.jpg    300     168     Good   200    62   279    99)\n"," group in loop \n","data(filename='img33.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","127  img33.jpg    318     159  Caution   145    23   237   151)\n"," group in loop \n","data(filename='img34.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","128  img34.jpg    275     183  Caution    14    21   185   139\n","129  img34.jpg    275     183      Bad   197    19   263   124)\n"," group in loop \n","data(filename='img35.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","185  img35.jpg    300     168     Good    21    31   191   168\n","186  img35.jpg    300     168  Caution   148    31   259   168)\n"," group in loop \n","data(filename='img36.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","106  img36.jpg    278     182   Bad    14    19   238   182)\n"," group in loop \n","data(filename='img37.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","107  img37.jpg    275     183   Bad    38    29   161   183\n","108  img37.jpg    275     183   Bad   100    44   229   183)\n"," group in loop \n","data(filename='img38.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","109  img38.jpg    300     168   Bad    94    57   176   162)\n"," group in loop \n","data(filename='img39.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","187  img39.jpg    275     183  Good    26    35    98    87\n","188  img39.jpg    275     183  Good     1    66   106   137\n","189  img39.jpg    275     183  Good   135    30   209    72\n","190  img39.jpg    275     183  Good   156    72   275   139\n","191  img39.jpg    275     183  Good   150    72   191   181)\n"," group in loop \n","data(filename='img4.jpg', object=    filename  width  height class  xmin  ymin  xmax  ymax\n","54  img4.jpg    413     122   Bad    20    37   127   122\n","55  img4.jpg    413     122   Bad    78    20   189   122\n","56  img4.jpg    413     122   Bad   127    20   252   122\n","57  img4.jpg    413     122   Bad   184    20   300   122\n","58  img4.jpg    413     122   Bad   252    35   337   122\n","59  img4.jpg    413     122   Bad   296    22   391   122)\n"," group in loop \n","data(filename='img40.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","130  img40.jpg    267     189  Caution    29     1   236   189)\n"," group in loop \n","data(filename='img41.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","110  img41.jpg    275     183   Bad    38    40   118   166)\n"," group in loop \n","data(filename='img42.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","114  img42.jpg    330     153   Bad    28    19   119   153\n","115  img42.jpg    330     153   Bad    77    15   165   153\n","116  img42.jpg    330     153   Bad   119    15   208   153\n","117  img42.jpg    330     153   Bad   166    27   255   153\n","118  img42.jpg    330     153   Bad   208    16   300   153)\n"," group in loop \n","data(filename='img44.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","131  img44.jpg    275     183  Good    49    89   141   144\n","132  img44.jpg    275     183   Bad   116    89   178   133)\n"," group in loop \n","data(filename='img45.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","133  img45.jpg    275     183  Caution    62    18   197   159)\n"," group in loop \n","data(filename='img46.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","119  img46.jpg    275     183   Bad     1    34   239   183)\n"," group in loop \n","data(filename='img47.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","134  img47.jpg    259     194     Good    28    13   165   194\n","135  img47.jpg    259     194  Caution   128    18   216   177\n","136  img47.jpg    259     194  Caution   174    23   235   158)\n"," group in loop \n","data(filename='img48.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","137  img48.jpg    259     195  Caution    94   118   158   151)\n"," group in loop \n","data(filename='img49.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","138  img49.jpg    275     183  Caution    72    15   166   130\n","139  img49.jpg    275     183  Caution   133    15   220   183)\n"," group in loop \n","data(filename='img5.jpg', object=    filename  width  height class  xmin  ymin  xmax  ymax\n","70  img5.jpg    300     168   Bad    18    39   133   168\n","71  img5.jpg    300     168   Bad    78    39   194   168\n","72  img5.jpg    300     168   Bad   134    65   271   168\n","73  img5.jpg    300     168   Bad   188    18   272   168\n","74  img5.jpg    300     168   Bad   134     1   246    66\n","75  img5.jpg    300     168   Bad    74     1   193    43\n","76  img5.jpg    300     168   Bad   133     1   194   168\n","77  img5.jpg    300     168   Bad    76     5   136   168)\n"," group in loop \n","data(filename='img50.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","140  img50.jpg    259     194  Caution    35    26   167   134)\n"," group in loop \n","data(filename='img6.jpg', object=    filename  width  height class  xmin  ymin  xmax  ymax\n","82  img6.jpg    275     183   Bad    69    56   233   183)\n"," group in loop \n","data(filename='img7.jpg', object=    filename  width  height class  xmin  ymin  xmax  ymax\n","87  img7.jpg    300     168   Bad     1    25    67   152\n","88  img7.jpg    300     168   Bad    30    31   109   153\n","89  img7.jpg    300     168   Bad    69    29   160   154\n","90  img7.jpg    300     168   Bad   119    28   222   153\n","91  img7.jpg    300     168   Bad   160    29   253   150\n","92  img7.jpg    300     168   Bad   220    22   300   152)\n"," group in loop \n","data(filename='img8.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","120  img8.jpg    275     183  Good    62     2   247    87\n","121  img8.jpg    275     183   Bad     3    50    98    92)\n"," group in loop \n","data(filename='img9.jpg', object=     filename  width  height    class  xmin  ymin  xmax  ymax\n","122  img9.jpg    267     189  Caution   156    23   244    89)\n"," group in loop \n","data(filename='low_12.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","41  low_12.jpg    430     300   Bad    96    62   331   300)\n"," group in loop \n","data(filename='low_173.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","51  low_173.jpg   1617    2048   Bad    58   104  1516  2037)\n"," group in loop \n","data(filename='low_174.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","52  low_174.jpg   1365    2048   Bad    58   169  1196  1966)\n"," group in loop \n","data(filename='low_175.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","53  low_175.jpg   1280     854  Caution    20    61  1229   854)\n"," group in loop \n","data(filename='low_182.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","60  low_182.jpg    306     600   Bad     7     5   292   503)\n"," group in loop \n","data(filename='low_185.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","61  low_185.jpg    634    1062   Bad    10    15   584   935)\n"," group in loop \n","data(filename='low_25.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","42  low_25.jpg    400     600      Bad    74    28   350   591\n","43  low_25.jpg    400     600  Caution    26    31   221   410)\n"," group in loop \n","data(filename='low_3.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","36  low_3.jpg    480     720   Bad    95    65   415   678)\n"," group in loop \n","data(filename='low_5.jpg', object=     filename  width  height class  xmin  ymin  xmax  ymax\n","37  low_5.jpg   1200     800   Bad   405   244   745   788\n","38  low_5.jpg   1200     800  Good   293   242   578   796)\n"," group in loop \n","data(filename='low_562.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","62  low_562.jpg    503     512  Caution    90    53   414   300)\n"," group in loop \n","data(filename='low_575.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","63  low_575.jpg   1200    1800  Caution   345    13  1190  1097)\n"," group in loop \n","data(filename='low_73.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","47  low_73.jpg    680    1081   Bad   112   262   611   955)\n"," group in loop \n","data(filename='low_804.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","64  low_804.jpg   3689    2616  Good   770   702  1917  2249\n","65  low_804.jpg   3689    2616  Good  1606  1060  2712  1931\n","66  low_804.jpg   3689    2616   Bad   688   690  3053  2572)\n"," group in loop \n","data(filename='low_806.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","67  low_806.jpg    634     677   Bad   109     8   582   574)\n"," group in loop \n","data(filename='low_807.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","68  low_807.jpg   1200    1200   Bad    78   219   693  1088\n","69  low_807.jpg   1200    1200   Bad   374    38  1139  1109)\n"," group in loop \n","data(filename='low_83.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","48  low_83.jpg   1280    1920   Bad    80   193  1198  1802)\n"," group in loop \n","data(filename='low_830.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","78  low_830.jpg    700     400   Bad   117    84   292   385\n","79  low_830.jpg    700     400   Bad   219    87   369   392\n","80  low_830.jpg    700     400   Bad   303   103   473   377\n","81  low_830.jpg    700     400   Bad   380    87   565   375)\n"," group in loop \n","data(filename='low_890.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","83  low_890.jpg   2880    1620  Good    23     9  1866  1542)\n"," group in loop \n","data(filename='low_891.jpg', object=       filename  width  height class  xmin  ymin  xmax  ymax\n","84  low_891.jpg   1695    1096   Bad   518   199  1389  1010)\n"," group in loop \n","data(filename='low_93.jpg', object=      filename  width  height    class  xmin  ymin  xmax  ymax\n","49  low_93.jpg    800    1125  Caution    76   130   755  1016)\n"," group in loop \n","data(filename='low_94.jpg', object=      filename  width  height class  xmin  ymin  xmax  ymax\n","50  low_94.jpg    600     900   Bad    49   133   479   808)\n"," group in loop \n","data(filename='skynews-train-rail-leeds_5089329.jpg', object=                                filename  width  height  ... ymin  xmax  ymax\n","85  skynews-train-rail-leeds_5089329.jpg   1600     900  ...  201  1383   860\n","86  skynews-train-rail-leeds_5089329.jpg   1600     900  ...  211  1398   732\n","\n","[2 rows x 8 columns])\n"," group in loop \n","data(filename='unnamed.jpg', object=       filename  width  height    class  xmin  ymin  xmax  ymax\n","93  unnamed.jpg    512     388  Caution   118   103   417   375)\n","Successfully created the TFRecords: /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/TestData_LBSDM/annotations.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f9ri-4ubQCZe","outputId":"8a6bafe1-22a6-4f35-b4a8-13a18ddc6c79","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python3 '/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/model_main_tf2.py' \\\n","    --pipeline_config_path='/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/pipeline.config' \\\n","    --model_dir='/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/' \\\n","    --checkpoint_dir='/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/' \\\n","    --run_once=True \\\n","    --alsologtostderror"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-10-27 20:02:19.143130: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W1027 20:02:25.978456 140220997416832 model_lib_v2.py:925] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n","I1027 20:02:25.978715 140220997416832 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I1027 20:02:25.978823 140220997416832 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I1027 20:02:25.978957 140220997416832 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W1027 20:02:25.979539 140220997416832 model_lib_v2.py:940] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","2020-10-27 20:02:26.010134: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n","2020-10-27 20:02:26.029140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 20:02:26.029753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s\n","2020-10-27 20:02:26.029799: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-10-27 20:02:26.044457: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n","2020-10-27 20:02:26.051617: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n","2020-10-27 20:02:26.058080: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n","2020-10-27 20:02:26.071744: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n","2020-10-27 20:02:26.076330: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n","2020-10-27 20:02:26.109175: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n","2020-10-27 20:02:26.109374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 20:02:26.110047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 20:02:26.110623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n","2020-10-27 20:02:26.111014: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2020-10-27 20:02:26.150788: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000140000 Hz\n","2020-10-27 20:02:26.153274: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2c36f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-10-27 20:02:26.153321: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-10-27 20:02:26.274825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 20:02:26.275590: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2c37100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-10-27 20:02:26.275627: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n","2020-10-27 20:02:26.275872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 20:02:26.276491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s\n","2020-10-27 20:02:26.276543: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-10-27 20:02:26.276597: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n","2020-10-27 20:02:26.276622: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n","2020-10-27 20:02:26.276646: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n","2020-10-27 20:02:26.276668: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n","2020-10-27 20:02:26.276690: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n","2020-10-27 20:02:26.276725: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n","2020-10-27 20:02:26.276811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 20:02:26.277479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 20:02:26.278014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n","2020-10-27 20:02:26.278068: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-10-27 20:02:27.057778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-10-27 20:02:27.057859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n","2020-10-27 20:02:27.057874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n","2020-10-27 20:02:27.058180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 20:02:27.058876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-10-27 20:02:27.059463: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-10-27 20:02:27.059521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12272 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n","I1027 20:02:27.079866 140220997416832 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I1027 20:02:27.080109 140220997416832 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 64\n","I1027 20:02:27.080200 140220997416832 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 3\n","I1027 20:02:27.090682 140220997416832 efficientnet_model.py:147] round_filter input=32 output=32\n","I1027 20:02:27.139272 140220997416832 efficientnet_model.py:147] round_filter input=32 output=32\n","I1027 20:02:27.139461 140220997416832 efficientnet_model.py:147] round_filter input=16 output=16\n","I1027 20:02:27.227245 140220997416832 efficientnet_model.py:147] round_filter input=16 output=16\n","I1027 20:02:27.227439 140220997416832 efficientnet_model.py:147] round_filter input=24 output=24\n","I1027 20:02:27.457623 140220997416832 efficientnet_model.py:147] round_filter input=24 output=24\n","I1027 20:02:27.457820 140220997416832 efficientnet_model.py:147] round_filter input=40 output=40\n","I1027 20:02:27.800049 140220997416832 efficientnet_model.py:147] round_filter input=40 output=40\n","I1027 20:02:27.800238 140220997416832 efficientnet_model.py:147] round_filter input=80 output=80\n","I1027 20:02:28.143949 140220997416832 efficientnet_model.py:147] round_filter input=80 output=80\n","I1027 20:02:28.144140 140220997416832 efficientnet_model.py:147] round_filter input=112 output=112\n","I1027 20:02:28.500666 140220997416832 efficientnet_model.py:147] round_filter input=112 output=112\n","I1027 20:02:28.500854 140220997416832 efficientnet_model.py:147] round_filter input=192 output=192\n","I1027 20:02:28.962080 140220997416832 efficientnet_model.py:147] round_filter input=192 output=192\n","I1027 20:02:28.962293 140220997416832 efficientnet_model.py:147] round_filter input=320 output=320\n","I1027 20:02:29.069464 140220997416832 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I1027 20:02:29.114163 140220997416832 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/test_labels.record']\n","I1027 20:02:29.204132 140220997416832 dataset_builder.py:148] Reading unweighted datasets: ['/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/test_labels.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/test_labels.record']\n","I1027 20:02:29.206011 140220997416832 dataset_builder.py:77] Reading record datasets for input file: ['/content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/Data/test_labels.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I1027 20:02:29.206238 140220997416832 dataset_builder.py:78] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W1027 20:02:29.206376 140220997416832 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","W1027 20:02:29.221596 140220997416832 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W1027 20:02:29.265005 140220997416832 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W1027 20:02:33.246721 140220997416832 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/inputs.py:262: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1027 20:02:34.793896 140220997416832 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/inputs.py:262: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Waiting for new checkpoint at /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/\n","I1027 20:02:37.647599 140220997416832 checkpoint_utils.py:125] Waiting for new checkpoint at /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/\n","INFO:tensorflow:Found new checkpoint at /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/ckpt-0\n","I1027 20:02:37.653820 140220997416832 checkpoint_utils.py:134] Found new checkpoint at /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/ckpt-0\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/model_lib_v2.py:702: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n","Instructions for updating:\n","Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","W1027 20:02:41.439263 140220997416832 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/model_lib_v2.py:702: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n","Instructions for updating:\n","Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/eval_util.py:878: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1027 20:03:04.155603 140220997416832 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/eval_util.py:878: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2020-10-27 20:03:11.404252: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n","2020-10-27 20:03:11.912451: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n","INFO:tensorflow:Finished eval step 0\n","I1027 20:03:15.181851 140220997416832 model_lib_v2.py:799] Finished eval step 0\n","WARNING:tensorflow:From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/utils/visualization_utils.py:617: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W1027 20:03:15.367737 140220997416832 deprecation.py:323] From /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/models/research/object_detection/utils/visualization_utils.py:617: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","2020-10-27 20:03:20.283194: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 15007392 exceeds 10% of free system memory.\n","2020-10-27 20:03:20.355904: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 15007392 exceeds 10% of free system memory.\n","INFO:tensorflow:Finished eval step 100\n","I1027 20:03:23.806043 140220997416832 model_lib_v2.py:799] Finished eval step 100\n","2020-10-27 20:03:24.855566: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33546240 exceeds 10% of free system memory.\n","2020-10-27 20:03:27.232704: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33796140 exceeds 10% of free system memory.\n","2020-10-27 20:03:27.334238: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33796140 exceeds 10% of free system memory.\n","INFO:tensorflow:Performing evaluation on 195 images.\n","I1027 20:03:30.635397 140220997416832 coco_evaluation.py:282] Performing evaluation on 195 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I1027 20:03:30.636482 140220997416832 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.01s)\n","I1027 20:03:30.648666 140220997416832 coco_tools.py:138] DONE (t=0.01s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.75s).\n","Accumulating evaluation results...\n","DONE (t=0.21s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.522\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.396\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.220\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.392\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.442\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.664\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738\n","INFO:tensorflow:Eval metrics at step 0\n","I1027 20:03:31.636517 140220997416832 model_lib_v2.py:853] Eval metrics at step 0\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.361929\n","I1027 20:03:31.652706 140220997416832 model_lib_v2.py:856] \t+ DetectionBoxes_Precision/mAP: 0.361929\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.522479\n","I1027 20:03:31.654491 140220997416832 model_lib_v2.py:856] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.522479\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.395778\n","I1027 20:03:31.655848 140220997416832 model_lib_v2.py:856] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.395778\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.000000\n","I1027 20:03:31.657175 140220997416832 model_lib_v2.py:856] \t+ DetectionBoxes_Precision/mAP (small): 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.220115\n","I1027 20:03:31.658608 140220997416832 model_lib_v2.py:856] \t+ DetectionBoxes_Precision/mAP (medium): 0.220115\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.391830\n","I1027 20:03:31.660003 140220997416832 model_lib_v2.py:856] \t+ DetectionBoxes_Precision/mAP (large): 0.391830\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.441871\n","I1027 20:03:31.661349 140220997416832 model_lib_v2.py:856] \t+ DetectionBoxes_Recall/AR@1: 0.441871\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.663869\n","I1027 20:03:31.662634 140220997416832 model_lib_v2.py:856] \t+ DetectionBoxes_Recall/AR@10: 0.663869\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.686816\n","I1027 20:03:31.664000 140220997416832 model_lib_v2.py:856] \t+ DetectionBoxes_Recall/AR@100: 0.686816\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n","I1027 20:03:31.665154 140220997416832 model_lib_v2.py:856] \t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.426543\n","I1027 20:03:31.666560 140220997416832 model_lib_v2.py:856] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.426543\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.737521\n","I1027 20:03:31.668085 140220997416832 model_lib_v2.py:856] \t+ DetectionBoxes_Recall/AR@100 (large): 0.737521\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.172215\n","I1027 20:03:31.669210 140220997416832 model_lib_v2.py:856] \t+ Loss/localization_loss: 0.172215\n","INFO:tensorflow:\t+ Loss/classification_loss: 0.850901\n","I1027 20:03:31.670283 140220997416832 model_lib_v2.py:856] \t+ Loss/classification_loss: 0.850901\n","INFO:tensorflow:\t+ Loss/regularization_loss: 0.066348\n","I1027 20:03:31.671427 140220997416832 model_lib_v2.py:856] \t+ Loss/regularization_loss: 0.066348\n","INFO:tensorflow:\t+ Loss/total_loss: 1.089464\n","I1027 20:03:31.672534 140220997416832 model_lib_v2.py:856] \t+ Loss/total_loss: 1.089464\n","INFO:tensorflow:Waiting for new checkpoint at /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/\n","I1027 20:07:37.748182 140220997416832 checkpoint_utils.py:125] Waiting for new checkpoint at /content/drive/My Drive/SocialDistance/LSBDMEfficientNetD0/fine_tuned_model/checkpoint/\n"],"name":"stdout"}]}]}